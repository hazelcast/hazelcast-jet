[[logging-and-debugging]]
= Monitor Execution and Diagnose Problems

== Configure Logging

Jet, like Hazelcast IMDG, does not depend on a specific logging
framework and has built-in adapters for a variety of logging frameworks.
You can also write a new adapter to integrate with loggers Jet doesn't
natively support. To use one of the built-in adapters, set the
`hazelcast.logging.type` property to one of the following:

* `jdk`: java.util.logging (default)
* `log4j`: Apache Log4j
* `log4j2`: Apache Log4j 2
* `slf4j`: SLF4J
* `none`: Turn off logging

For example, to configure Jet to use Log4j, you can do one of the
following:

[source]
----
include::{javasource}/LogDebug.java[tag=s1]
----

or

[source]
----
include::{javasource}/LogDebug.java[tag=s2]
----

For more detailed information about how to configure logging, please
refer to the {hz-refman}#logging-configuration[IMDG reference manual].

== Inspect Output of Individual Stages

While debugging your pipeline you'll want to see the output of an
individual stage. You can achieve it by using the
{jet-javadoc}/pipeline/GeneralStage.html#peek--[`peek()`] stage. For example:

[source]
----
include::{javasource}/LogDebug.java[tag=s3]
----

<1> Logs all the word tokens emitted by the filtering stage

If you run it like this:

[source]
----
include::{javasource}/LogDebug.java[tag=s4]
----

this is how your output may look:

....
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#1
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: quick
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#2
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: brown
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#0
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: the
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#4
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: dog
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#3
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: lazy
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#0
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: jumped
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#2
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: the
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#1
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: over
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#3
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: fox
....

The logger name of
`com.hazelcast.jet.impl.processor.PeekWrappedP.filter#1` consists of the
following parts:

* `com.hazelcast.jet.impl.processor.PeekWrappedP`: the type of the
processor writing the log message
* `filter`: the name of the vertex the processor belongs to
* `#0`: index of the processor within the vertex. The index is unique
cluster-wide.

For more information about logging when using the Core API, see the
<<inspecting-processor-input-and-output, Best Practices>> section.

[[metrics-monitoring]]
== Monitor Metrics

Jet exposes various metrics to facilitate monitoring of cluster state and
running jobs. The set of available metrics is fixed for now, but they
should cover a wide rage of needs and support for custom user metrics is
planned for future versions.

Each metric provided by Jet has a specific name which conceptually
identifies what it's being used to measure. Besides their name metrics
also have a description made up by tags, but those are more like
attributes which describe a specific instance of the metric and are not
directly part of the semantics of the metric.

Each metric instance provided belongs to a particular Jet cluster member, so
different cluster members can have their own versions of the same metric
with different values.

Also important to note that metric collection from
different cluster members can take place at different moments in time.

There are two broad categories of metrics, as follows. For clarity we will
group them based on significant tags which define their granularity.

=== Cluster metrics ===

[cols="3,2"]
|===
|Names|Main tags

| **blockingWorkerCount**: The number of non-cooperative workers employed.
| **none** +
Each Jet cluster member will have one instance of this metric.



| **iterationCount**: The total number of iterations the driver of tasklets in cooperative
thread N makes. It should increase by at least 250 iterations/s. Lower
value means some of the cooperative processors blocks for too long.

 **taskletCount**:The number of assigned tasklets to cooperative thread N.
| **cooperativeWorker=<N>** +
Each Jet cluster member will have N instances of this metric, where
N is the number of cooperative threads it employs for task execution.
|===

=== Job specific metrics ===

All job specific metrics have their `{jet-javadoc}/core/metrics/MetricTags.html#JOB[job=<jobId>]`,
`{jet-javadoc}/core/metrics/MetricTags.html#EXECUTION[exec=<executionId>]` and
`{jet-javadoc}/core/metrics/MetricTags.html#VERTEX[vertex=<vertexName>]` tags set. This means
that all these metrics will have at least one instance for each vertex of each current job
execution.

Additionally, if the vertex sourcing them is a data source or data sink, then the
`{jet-javadoc}/core/metrics/MetricTags.html#SOURCE[source]` or
`{jet-javadoc}/core/metrics/MetricTags.html#SINK[sink]` tags will also be set to `true`.

[cols="3,2"]
|===
|Names|Main tags

|**distributedBytesIn**: Total number of bytes received from remote
members. +
**distributedBytesOut**: Total number of bytes sent to remote members. +
**distributedItemsIn**: Total number of items received from remote
members. +
**distributedItemsOut**: Total number of items sent to remote members.

Values in this section are 0 for non-distributed edges, they only
account for data actually transmitted over the network between members.
This numbers include watermarks, snapshot barriers etc.
|**ordinal=<N>** +
Each Jet member will have an instance of these metrics
for each ordinal of each vertex of each job execution.

|**topObservedWm**: This value is equal to the highest _coalescedWm_ on
any input edge of this processor. +
**coalescedWm**: The highest watermark received from _all_ inputs that
was sent to the processor to handle. +
**lastForwardedWm**: Last watermark emitted by the processor to output. +
**lastForwardedWmLatency**: The difference between _lastForwardedWn_
and the system time at the moment when metrics were collected.

**queuesCapacity**: The total capacity of input queues. +
**queuesSize**: The total number of items waiting in input queues.

All input queues for all edges to the processor are summed in the above
two metrics. If size is close to capacity, backpressure is applied and
this processor is a bottleneck. Only input edges with equal priority are
summed. If the processor has input edges with different priority, only
edges with the highest priority will be reflected, after those are
exhausted edges with the next lower priority will be reflected and so
on.
|**proc=<N>, ordinal=<not specified>** +
Each Jet member will have one instances of these metrics for each each processor
instance N,where N denotes the global processor index. Processor is the
parallel worker doing the work of the vertex.

|**topObservedWm**: The highest received watermark from _any_ input on
edge _N_. +
**coalescedWm**: The highest watermark received from _all_ upstream
processors on edge _N_. +

**emittedCount**: The number of emitted items. This number includes
watermarks, snapshot barriers etc. Unlike _distributedItemsOut_, it
includes items emitted items to local processors. +
**receivedCount**: The number of received items. This number does not
include watermarks, snapshot barriers etc. It's the number of items the
_Processor.process_ method will receive. +
**receivedBatches**: The number of received batches.
_Processor.process_ receives a batch of items at a time, this is the
number of such batches. By dividing _receivedCount_ by
_receivedBatches_, you get the average batch size. It will be 1 under
low load.
|**proc=<N>, ordinal=<M>** +
Each Jet member will have one instance of these metrics for each edge _M_ (input or
output) of each processor _N_. _N_ is the global processor index and _M_ is either
the ordinal of the edge or has the value _snapshot_ for output items
written to state snapshot.
|===

=== Hazelcast IMDG Metrics
Since Jet is built on top of Hazelcast IMDG the metrics exposed by IMDG are also
available. For further information on the IMDG metrics please consult the
{hz-refman}[Hazelcast IMDG Reference Manual].

=== Exposing metrics ===
The main method Jet has for exposing metrics to the outside world is the
JVM's standard JMX interface. Since Jet 3.2 there is also an alternative to JMX
for monitoring metrics, via the `Job API`, albeit only the job-specific ones.

==== Over JMX ====
Jet exposes all of its metrics using the JVM's standard JMX interface. You can use
tools such as Java Mission Control or JConsole to display them. All
Jet-related beans are stored under
`com.hazelcast.jet/Metrics/<instanceName>/` node and the various tags they
have form further sub-nodes in the resulting tree structure.

IMDG metrics are stored under the `com.hazelcast/Metrics/<instanceName>/` node.

==== Via Job API ====
Since version 3.2 Jet also exposes job related metrics via its client API.
`{jet-javadoc}/Job.html[Job]` objects have a `{jet-javadoc}/Job.html#getMetrics--[getMetrics()]`
method now, which returns `{jet-javadoc}/core/metrics/JobMetrics.html[JobMetrics]` instances
and those contain the latest known metric values for their source jobs.

This functionality has been developed primarily for giving access to metrics of
finished jobs, but can in fact be used for jobs with any {jet-javadoc}/core/JobStatus.html[status].

When exposing metrics in this way the relationship between metric instance and source Jet member
is made explicit by adding the `{jet-javadoc}/core/metrics/MetricTags.html#MEMBER[member]` and
`{jet-javadoc}/core/metrics/MetricTags.html#ADDRESS[address]` tags to them.

While the job is running the metric values are updated periodically (according to a
{jet-javadoc}/config/MetricsConfig.html#setCollectionIntervalSeconds-int-[configured collection interval]),
assuming that both
{jet-javadoc}/config/MetricsConfig.html#setEnabled-boolean-[generic metrics functionality] and
{jet-javadoc}/config/JobConfig.html#setMetricsEnabled-boolean-[job metrics] are enabled.
Otherwise empty metrics will be returned.

Keep in mind that the collections may occur at different times on each member,
metrics from various members aren't from the same instant.

When a job is restarted (or resumed after being previously suspended) the metrics
are reset too, their values will reflect only updates from the latest execution of the job.

Once a job stops executing (successfully, after a failure, cancellation,
or temporarily while suspended) the metrics will have their most
recent values (i.e. the last metric values from the moment before the
job completed), assuming that
{jet-javadoc}/config/JobConfig.html#setStoreMetricsAfterJobCompletion-boolean-[metrics storage]
was enabled. Otherwise empty metrics will be returned.

For details on how to use and filter the metric values provided consult
the {jet-javadoc}/core/metrics/JobMetrics.html[JobMetrics API docs]. A simple example for
computing the number of data items emitted by a certain vertex (let's call it `filter`),
excluding saved snapshots, would look like this:

[source]
----
include::{javasource}/integration/Metrics.java[tag=s2]
----

=== Configuration

The metrics collection is enabled by default. You can configure it
using the `hazelcast-jet.xml` file:

[source,xml,subs="attributes+"]
----
<metrics enabled="true" jmxEnabled="true">
    <!-- The number of seconds the metrics will be retained on
         the instance -->
    <retention-seconds>5</retention-seconds>

    <!-- The metrics collection interval in seconds -->
    <collection-interval-seconds>5</collection-interval-seconds>

    <!-- whether metrics should be collected for data structures.
         Metrics collection can have some overhead if there is a
         large number of data structures -->
    <metrics-for-data-structures>false</metrics-for-data-structures>
</metrics>
----

or using `{jet-javadoc}/config/JetConfig.html[JetConfig]` object:

[source]
----
include::{javasource}/integration/Metrics.java[tag=s1]
----
See {jet-javadoc}/config/MetricsConfig.html[MetricsConfig API docs] for available methods.
