[[logging-and-debugging]]
= Monitor Execution and Diagnose Problems

== Configure Logging

Jet, like Hazelcast IMDG, does not depend on a specific logging
framework and has built-in adapters for a variety of logging frameworks.
You can also write a new adapter to integrate with loggers Jet doesn't
natively support. To use one of the built-in adapters, set the
`hazelcast.logging.type` property to one of the following:

* `jdk`: java.util.logging (default)
* `log4j`: Apache Log4j
* `log4j2`: Apache Log4j 2
* `slf4j`: SLF4J
* `none`: Turn off logging

For example, to configure Jet to use Log4j, you can do one of the
following:

[source]
----
include::{javasource}/LogDebug.java[tag=s1]
----

or

[source]
----
include::{javasource}/LogDebug.java[tag=s2]
----

For more detailed information about how to configure logging, please
refer to the {hz-refman}#logging-configuration[IMDG reference manual].

== Inspect Output of Individual Stages

While debugging your pipeline you'll want to see the output of an
individual stage. You can achieve it by using the
{jet-javadoc}/pipeline/GeneralStage.html#peek--[`peek()`] stage. For example:

[source]
----
include::{javasource}/LogDebug.java[tag=s3]
----

<1> Logs all the word tokens emitted by the filtering stage

If you run it like this:

[source]
----
include::{javasource}/LogDebug.java[tag=s4]
----

this is how your output may look:

....
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#1
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: quick
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#2
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: brown
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#0
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: the
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#4
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: dog
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#3
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: lazy
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#0
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: jumped
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#2
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: the
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#1
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: over
Mar 20, 2018 2:43:24 PM com.hazelcast.jet.impl.processor.PeekWrappedP.filter#3
INFO: [192.168.5.12]:5702 [jet] [0.7-SNAPSHOT] Output to ordinal 0: fox
....

The logger name of
`com.hazelcast.jet.impl.processor.PeekWrappedP.filter#1` consists of the
following parts:

* `com.hazelcast.jet.impl.processor.PeekWrappedP`: the type of the
processor writing the log message
* `filter`: the name of the vertex the processor belongs to
* `#0`: index of the processor within the vertex. The index is unique
cluster-wide.

For more information about logging when using the Core API, see the
<<inspecting-processor-input-and-output, Best Practices>> section.

[[metrics-monitoring]]
== Monitor Metrics

Jet exposes various metrics to facilitate monitoring of the cluster
state and of running jobs.

Metrics have associated tags which describe which object the metric
applies to. The tags for job metrics typically indicate the specific
vertex and processor the metric belongs to.

Each metric instance provided belongs to a particular Jet cluster member, so
different cluster members can have their own versions of the same metric
with different values.

The metric collection runs in regular intervals on each member, but note
that the metric collection on different cluster members happens at
different moments in time. So if you try to correlate metrics from
different members, they can be from different moments of time.

There are two broad categories of Jet metrics. For clarity we will group
them based on significant tags which define their granularity.

Last but not least let's not forget about the fact that each Jet member is
also an IMDG member, so Jet also exposes all the metrics available in IMDG.

Let's look at these 3 broad categories of metrics in detail.

[[imdg-metrics]]
=== IMDG Metrics ===
There is a wide range of metrics and statistics provided by IMDG:

* statistics of distributed data structures (see
{hz-refman}#getting-member-statistics[IMDG Reference Manual])
* executor statistics (see {hz-refman}#executor-statistics[IMDG Reference Manual])
* partition related statistics (state, migration, replication)
* garbage collection statistics
* memory statistics for the JVM which current IMDG member belongs to (total
physical/free OS memory, max/committed/used/free heap memory and
max/committed/used/free native memory)
* network traffic related statistics (traffic and queue sizes)
* class loading related statistics
* thread count information (current, peak and daemon thread counts)

[[cluster-metrics]]
=== Jet Cluster metrics ===

[cols="3,2"]
|===
|Names|Extra tags

| **blockingWorkerCount**: Number of non-cooperative workers employed.

**jobs.submitted**: Number of computational jobs submitted. +
**jobs.completedSuccessfully**: Number of computational jobs successfully completed. +
**jobs.completedWithFailure**: Number of computational jobs that have failed. +
**jobs.executionStarted**: Number of computational job executions started.
Each job can execute multiple times, for example when it's restarted or suspended and then resumed. +
**jobs.executionTerminated**: Number of computational job executions finished.
Each job can execute multiple times, for example when it's restarted or suspended and then resumed.
| **none** +
Each Jet cluster member will have one instance of this metric.

| **iterationCount**: The total number of iterations the driver of tasklets in cooperative
thread N made. It should increase by at least 250 iterations/s. Lower
value means some of the cooperative processors block for too long.
Somewhat lower value is normal if there are many tasklets assigned to
the processor. Lower value affects the latency. +
 **taskletCount**: The number of assigned tasklets to cooperative thread N.
| **cooperativeWorker=<N>** +
N is the number of the cooperative thread.
|===

[[job-metrics]]
=== Jet Job metrics ===

All job specific metrics have their `{jet-javadoc}/core/metrics/MetricTags.html#JOB[job=<jobId>]` and
`{jet-javadoc}/core/metrics/MetricTags.html#EXECUTION[exec=<executionId>]` tags set and most also
have the `{jet-javadoc}/core/metrics/MetricTags.html#VERTEX[vertex=<vertexName>]` tag set (with
very few exceptions). This means that most of these metrics will have at least one instance for each
vertex of each current job execution.

Additionally, if the vertex sourcing them is a data source or data sink, then the
`{jet-javadoc}/core/metrics/MetricTags.html#SOURCE[source]` or
`{jet-javadoc}/core/metrics/MetricTags.html#SINK[sink]` tags will also be set to `true`.

[cols="3,2"]
|===
|Names|Extra tags

|**executionStartTime**: Start time of the current execution of the job. +
**executionCompletionTime**: Completion time of the current execution of the job. +

Both contain epoch time in milliseconds.
|** no extra tags, they are even missing `vertex`** +
There will be a single instance of these metrics for each job execution.

|**snapshotBytes**: Total number of bytes written out in the last snapshot. +
**snapshotKeys**: Total number of keys written out in the last snapshot.
|**no extra tags** +
There will be a single instance of these metrics for each vertex.

|**distributedBytesIn**: Total number of bytes received from remote
members. +
**distributedBytesOut**: Total number of bytes sent to remote members. +
**distributedItemsIn**: Total number of items received from remote
members. +
**distributedItemsOut**: Total number of items sent to remote members.

These values are only present for distributed edges, they only account
for data actually transmitted over the network between members. This
numbers include watermarks, snapshot barriers etc.
|**ordinal=<N>** +
Each Jet member will have an instance of these metrics
for each ordinal of each vertex of each job execution.

|**topObservedWm**: This value is equal to the highest _coalescedWm_ on
any input edge of this processor. +
**coalescedWm**: The highest watermark received from _all_ inputs that
was sent to the processor to handle. +
**lastForwardedWm**: Last watermark emitted by the processor to output. +
**lastForwardedWmLatency**: The difference between _lastForwardedWn_
and the system time at the moment when metrics were collected.

**queuesCapacity**: The total capacity of input queues. +
**queuesSize**: The total number of items waiting in input queues.

All input queues for all edges to the processor are summed in the above
two metrics. If size is close to capacity, backpressure is applied and
this processor is a bottleneck. Only input edges with equal priority are
summed. If the processor has input edges with different priority, only
edges with the highest priority will be reflected, after those are
exhausted edges with the next lower priority will be reflected and so
on.
|**proc=<N>, ordinal=<not specified>** +
Each Jet member will have one instances of these metrics for each processor
instance _N_, the _N_ denotes the global processor index. Processor is the
parallel worker doing the work of the vertex.

|**topObservedWm**: The highest received watermark from _any_ input on
edge _N_. +
**coalescedWm**: The highest watermark received from _all_ upstream
processors on edge _N_. +

**emittedCount**: The number of emitted items. This number includes
watermarks, snapshot barriers etc. Unlike _distributedItemsOut_, it
includes items emitted items to local processors. +
**receivedCount**: The number of received items. This number does not
include watermarks, snapshot barriers etc. It's the number of items the
_Processor.process_ method will receive. +
**receivedBatches**: The number of received batches.
_Processor.process_ receives a batch of items at a time, this is the
number of such batches. By dividing _receivedCount_ by
_receivedBatches_, you get the average batch size. It will be 1 under
low load.
|**proc=<N>, ordinal=<M>** +
Each Jet member will have one instance of these metrics for each edge _M_ (input or
output) of each processor _N_. _N_ is the global processor index and _M_ is either
the ordinal of the edge or has the value _snapshot_ for output items
written to state snapshot.

|**numInFlightOps**: The number of pending (in flight) operations when using
asynchronous mapping processors. +
See
`{jet-javadoc}/core/processor/Processors.html#mapUsingServiceAsyncP-com.hazelcast.jet.pipeline.ServiceFactory-com.hazelcast.function.FunctionEx-com.hazelcast.function.BiFunctionEx-[
Processors.mapUsingServiceAsyncP]`.

** totalKeys **: The number of active keys being tracked by a session window
processor. +
** totalWindows **: The number of active windows being tracked by a session window
processor. +
 See
`{jet-javadoc}/core/processor/Processors.html#aggregateToSessionWindowP-long-long-java.util.List-java.util.List-com.hazelcast.jet.aggregate.AggregateOperation-com.hazelcast.jet.core.function.KeyedWindowResultFunction-[
Processors.aggregateToSessionWindowP]`.

** totalFrames **: The number of active frames being tracked by a sliding window
processor. +
** totalKeysInFrames **: The number of grouping keys associated with the current
active frames of a sliding window processor. +
 See
`{jet-javadoc}/core/processor/Processors.html#aggregateToSlidingWindowP-java.util.List-java.util.List-com.hazelcast.jet.core.TimestampKind-com.hazelcast.jet.core.SlidingWindowPolicy-long-com.hazelcast.jet.aggregate.AggregateOperation-com.hazelcast.jet.core.function.KeyedWindowResultFunction-[
Processors.aggregateToSlidingWindowP]`.

** lateEventsDropped **: The number of late events dropped by various
processor, due to the watermark already having passed their windows. +
|**proc=<N>, procType=<set>** +
Processor specific metrics, only certain types of processors have them. The
__procType__ tag can be used to identify the exact type of processor sourcing
them. +
Like all processor metrics, each Jet member will have one instances of
these metrics for each processor instance _N_, the _N_ denotes the global
processor index.
|===

[[user-metrics]]
=== User-defined metrics ===

User-defined metrics are actually a subset of job metrics. What
distinguishes them from regular job-specific metrics is exactly what
their name implies: they are not built-in, but defined when processing
pipelines are written.

Since user-defined metrics are also job metrics, they will have all the tags
job metrics have. They also have an extra tag, called `user` which is
of type `boolean` and is set to `true`.

NOTE: Due to the extra tag user-defined metrics have it's not possible
for them to overwrite a built-in metric, even if they have the exact same
name.

Let's see how one would go about defining such metrics. For example if
you would like to monitor your filtering step you could write code like
this:

[source]
----
include::{javasource}/LogDebug.java[tag=s5]
----

The handler for manipulating user-defined metrics is the
`{jet-javadoc}/core/metrics/Metric.html[Metric]` class, instances can be
obtained via the utility class
`{jet-javadoc}/core/metrics/Metrics.html[Metrics]`). The `Metric`
interface allows to both store simple measured values (like queue
length, load-factor and such) and to incrementally count things (like
number of certain events).

When obtaining `Metric` instances from the `Metrics` utility class it's
possible to specify the desired
`{jet-javadoc}/core/metrics/Unit.html[measurement unit]`
of the metrics. The unit can be used by UI tools to format the value, it's
ignored by Jet. If you request a metric multiple times with different unit,
the unit of the first request will be used to register the metric, others
will be ignored.

User-defined metrics can be used anywhere in pipeline definitions where
custom code can be added. This means (just to name the most important ones):
filtering, mapping and flat-mapping functions, various constituent
functions of aggregations (accumulate, create, combine, deduct, export &
finish), key extraction function when grouping, in custom sources, sinks
and processors and so on.

They can also be used both with the high-level <<pipeline-api, Pipeline
API>> and the low-level <<expert-zone, Core API>>.

NOTE: User-defined metrics are accessible only when the user code is
running on *internal Jet worker threads*. All the functions created when
defining a pipeline execute on those threads, but they can submit work to
other threads. For example, following code will throw an exception:

[source]
----
include::{javasource}/LogDebug.java[tag=s6]
----

The way to fix it would be:
[source]
----
include::{javasource}/LogDebug.java[tag=s7]
----

Take note that the fix not only moves the code for obtaining the
`Metric` instance outside of the block executing on the ForkJoinPool, it
also creates a "thread-safe" type of metric.

[[exposing-metrics]]
=== Exposing metrics ===

The main method Jet has for exposing the metrics to the outside world is
the JVM's standard JMX interface. Since Jet 3.2 there is also an
alternative to JMX for monitoring metrics, via the `Job API`, albeit
only the job-specific ones.

==== Over JMX ====

Jet exposes all of its metrics using the JVM's standard JMX interface.
You can use tools such as _Java Mission Control_ or _JConsole_ to
display them. All Jet-related beans are stored under
`com.hazelcast.jet/Metrics/<instanceName>/` node and the various tags
they have form further sub-nodes in the resulting tree structure.

IMDG metrics are stored under the
`com.hazelcast/Metrics/<instanceName>/` node.

==== Via Job API ====

The `Job` class has a
`{jet-javadoc}/Job.html#getMetrics--[getMetrics()]` method which returns
a `{jet-javadoc}/core/metrics/JobMetrics.html[JobMetrics]` instance. It
contains the latest known metric values for the job.

This functionality has been developed primarily to give access to
metrics of finished jobs, but can in fact be used for jobs in any
{jet-javadoc}/core/JobStatus.html[state].

While the job is running, the metric values are updated periodically
(according to a
{jet-javadoc}/config/MetricsConfig.html#setCollectionIntervalSeconds-int-[configured
collection interval]), assuming that both
{jet-javadoc}/config/MetricsConfig.html#setEnabled-boolean-[generic
metrics functionality] and
{jet-javadoc}/config/JobConfig.html#setMetricsEnabled-boolean-[job
metrics] are enabled. Otherwise, empty metrics will be returned.

When a job is restarted (or resumed after being previously suspended),
the metrics are reset; their values will reflect only updates from the
latest execution of the job.

Once a job stops executing (successfully, after a failure, cancellation,
or temporarily while suspended) the metrics will have values taken at
the moment just before the job completed), assuming that
{jet-javadoc}/config/JobConfig.html#setStoreMetricsAfterJobCompletion-boolean-[metrics storing]
was enabled. Otherwise, empty metrics will be returned.

For details on how to use and filter the metric values consult the
{jet-javadoc}/core/metrics/JobMetrics.html[JobMetrics API docs]. A
simple example for computing the number of data items emitted by a
certain vertex (let's call it `vertexA`), excluding items emitted to the
snapshot, would look like this:

[source]
----
include::{javasource}/integration/Metrics.java[tag=s2]
----

[[configuration]]
=== Configuration

The metrics collection is enabled by default. You can configure it
using the `hazelcast-jet.xml` file:

[source,xml,subs="attributes+"]
----
<metrics enabled="true" jmxEnabled="true">
    <!-- The number of seconds the metrics will be retained on
         the instance -->
    <retention-seconds>5</retention-seconds>

    <!-- The metrics collection interval in seconds -->
    <collection-interval-seconds>5</collection-interval-seconds>

    <!-- whether metrics should be collected for data structures.
         Metrics collection can have some overhead if there is a
         large number of data structures -->
    <metrics-for-data-structures>false</metrics-for-data-structures>
</metrics>
----

or using `{jet-javadoc}/config/JetConfig.html[JetConfig]` object:

[source]
----
include::{javasource}/integration/Metrics.java[tag=s1]
----
See {jet-javadoc}/config/MetricsConfig.html[MetricsConfig API docs] for available methods.
