<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Blog · Hazelcast Jet</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Open-Source Distributed Stream Processing"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Blog · Hazelcast Jet"/><meta property="og:type" content="website"/><meta property="og:url" content="https://jet-start.sh/"/><meta property="og:description" content="Open-Source Distributed Stream Processing"/><meta property="og:image" content="https://jet-start.sh/img/Hazelcast-Jet-Logo-Blue_Dark.jpg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://jet-start.sh/img/Hazelcast-Jet-Logo-Blue_Dark.jpg"/><link rel="shortcut icon" href="/img/favicon.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://jet-start.sh/blog/atom.xml" title="Hazelcast Jet Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://jet-start.sh/blog/feed.xml" title="Hazelcast Jet Blog RSS Feed"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-158279495-1', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,500,600"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600,700,800"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/code-block-buttons.js"></script><script type="text/javascript" src="https://plausible.io/js/plausible.js" async="" defer="" data-domain="jet-start.sh"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/prism.css"/><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="blog"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/logo-dark.svg" alt="Hazelcast Jet"/></a><a href="/versions"><h3>4.5.2</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/get-started/intro" target="_self">Docs</a></li><li class=""><a href="/download" target="_self">Download</a></li><li class=""><a href="/demos" target="_self">Demos</a></li><li class=""><a href="https://github.com/hazelcast/hazelcast-jet" target="_self">GitHub</a></li><li class=""><a href="https://slack.hazelcast.com/" target="_self">Community</a></li><li class="siteNavGroupActive siteNavItemActive"><a href="/blog/" target="_self">Blog</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>All posts</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">All posts</h3><ul class=""><li class="navListItem"><a class="navItem" href="/blog/2021/04/21/jet-45-is-released">Jet 4.5 Released</a></li><li class="navListItem"><a class="navItem" href="/blog/2021/03/17/billion-events-per-second">Billion Events Per Second with Millisecond Latency: Streaming Analytics at Giga-Scale</a></li><li class="navListItem"><a class="navItem" href="/blog/2021/02/03/jet-44-is-released">Jet 4.4 Released</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/10/23/jet-43-is-released">Jet 4.3 Released</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/10/06/enabling-full-text-search">Enabling Full-text Search with Change Data Capture in a Legacy Application</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/09/18/cdc-meets-stream-processing">Change Data Capture meets Stream Processing</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/08/05/gc-tuning-for-jet">Sub-10 ms Latency in Java: Concurrent GC with Green Threads</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/07/16/designing-evergreen-cache-cdc">Designing an Evergreen Cache with Change Data Capture</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/07/14/jet-42-is-released">Jet 4.2 is Released</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/06/23/jdk-gc-benchmarks-rematch">Performance of Modern Java on Data-Heavy Workloads: The Low-Latency Rematch</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/06/09/jdk-gc-benchmarks-part2">Performance of Modern Java on Data-Heavy Workloads: Batch Processing</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/06/09/jdk-gc-benchmarks-part1">Performance of Modern Java on Data-Heavy Workloads: Real-Time Streaming</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/05/25/grcp">Processing 10M queries / second on a single node using Jet and gRPC</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/05/18/spark-jet">How Hazelcast Jet Compares to Apache Spark</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/04/29/jet-41-is-released">Jet 4.1 is Released</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/04/01/upgrading-to-jet-40">Upgrading to Jet 4.0</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/03/30/ml-inference">Machine Learning Inference at Scale</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/03/02/jet-40-is-released">Jet 4.0 is Released</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/02/20/transactional-processors">Transactional connectors in Hazelcast Jet</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/01/28/new-website">Announcing New Documentation Website</a></li><li class="navListItem"><a class="navItem" href="/blog/2019/11/12/stream-deduplication">Stream Deduplication with Hazelcast Jet</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer postContainer blogContainer"><div class="wrapper"><div class="posts"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2021/04/21/jet-45-is-released">Jet 4.5 Released</a></h1><p class="post-meta">April 21, 2021</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener">Marko Topolnik</a></p><div class="authorPhoto"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener"><img src="https://pbs.twimg.com/profile_images/922726943614783488/Pb5DDGWF_400x400.jpg" alt="Marko Topolnik"/></a></div></div></header><article class="post-content"><div><span><p>Today we're releasing Hazelcast Jet 4.5, the second release this year!
We're bringing Jet closer to IMDG, unifying their SQL syntax and
features. Our goal is to have a single SQL dialect that seamlessly uses
the features of both Jet and IMDG.</p>
<p>This version of Jet is built on Hazelcast IMDG 4.2, <a href="https://hazelcast.com/blog/hazelcast-imdg-4-2-ga-is-released">check
out</a>
what's new there.</p>
<h2><a class="anchor" aria-hidden="true" id="improved-sql-experience"></a><a href="#improved-sql-experience" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Improved SQL Experience</h2>
<p>There used to be an important inconvenience when using IMap from outside
Java — in order to populate it, you first had to create a Java
class for its value, or at best a portable <code>ClassDefinition</code>, which is
declarative but a part of server configuration. In either case you had
to restart the Hazelcast cluster before you could use the new record
type.</p>
<p>This is no longer needed: you can now use <code>CREATE MAPPING</code> and Jet SQL
will automatically translate it to the equivalent <code>ClassDefinition</code>.
This move finally closes the loop and makes the Hazelcast SQL experience
entirely independent of Java. See
<a href="https://jet-start.sh/docs/sql/imap-connector#portable-serialization">Portable Serialization</a>
for more information.</p>
<h2><a class="anchor" aria-hidden="true" id="full-release-notes"></a><a href="#full-release-notes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Full Release Notes</h2>
<p>Hazelcast Jet 4.5 is based on IMDG version 4.2. Check out its Release
Notes <a href="https://docs.hazelcast.org/docs/rn/index.html#4-2">here</a> and,
for the Enterprise Edition,
<a href="https://docs.hazelcast.org/docs/ern/index.html#4-2">here</a>.</p>
<p>Members of the open source community that appear in these release notes:</p>
<ul>
<li>@hhromic</li>
</ul>
<p>Thank you for your valuable contributions!</p>
<h3><a class="anchor" aria-hidden="true" id="new-features"></a><a href="#new-features" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>New Features</h3>
<ul>
<li>[sql] Dynamic <code>ClassDefinition</code> removes the need to restart the
cluster in order to use a new record type in IMap (#2895)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="enhancements"></a><a href="#enhancements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Enhancements</h3>
<ul>
<li>[jdbc] @hhromic made the batch size limit configurable in the JDBC
sink processor (#2888)</li>
<li>[sql] Optimized the memory footprint of SQL aggregations (#2877)</li>
<li>[sql] Now you can use expressions in SQL generator functions (#2944)</li>
<li>[core] Pulling the data from an IMap/ICache could cause OOME due to
creating too many partition iterators at the same time (#3009)</li>
<li>[core] Removed misleading logging of errors that occur due to
the job being cancelled (#2974)</li>
<li>[pipeline-api] Significantly improved the performance of the <code>pickAny</code>
aggregate operation in sliding windows (it lacked the <em>deduct</em>
primitive) (#2917)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="fixes"></a><a href="#fixes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fixes</h3>
<ul>
<li>[core] Jet's integration with the Java Logging Framework caused it to
inadvertently close <code>System.out</code> from a  shutdown hook. This would
then break other shutdown hooks. (#2649)</li>
<li>[core] @hhromic fixed <code>DAG.toDotString()</code> to show the correct queue
sizes (#2887)</li>
<li>[sql] The <code>CREATE MAPPING</code> syntax had a fluke where you could use both
<code>OR REPLACE</code> and <code>IF NOT EXISTS</code> in the same statement (#2921)</li>
<li>[cdc] Implement processed offset feedback in CDC sources (#2854)</li>
<li>[extensions] Updated AWS SDK version to 1.11.976. (#2989)</li>
<li>[extensions] Updated Guava version to 30.1. (#2990)</li>
<li>[extensions] Updated Parquet version to 1.12.0 (#3012)</li>
<li>[extensions] Updated Avro to 1.10.2 (#2950)</li>
<li>[extensions] Updated Jetty version to 9.4.38.v20210224 (#2993)</li>
<li>[extensions] Updated wildfly-openssl to 1 (#2993)</li>
<li>[extensions] Updated ElasticSearch-6 to 6.8.14 (#2993)</li>
<li>[extensions] Updated ElasticSearch-7 to 7.10.0 (#2993)</li>
<li>[extensions] Updated Kafka version to 2.2.2 (#2993)</li>
<li>[extensions] Updated MySql Connector to 8.0.20 (#2993)</li>
<li>[extensions] Updated Apache Http Client to 4.5.13 (#2993)</li>
<li>[extensions] Updated Netty to 4.1.61.Final (#3023)</li>
<li>[extensions] Updated Snakeyaml version to 1.26 [SEC-71] (#3024)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="breaking-changes"></a><a href="#breaking-changes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Breaking Changes</h3>
<p>The <code>DAG.toDotString(int defaultParallelism)</code> method signature is now
<code>DAG.toDotString(int defaultLocalParallelism, int defaultQueueSize)</code>.
Callers must now supply the queue size that will be shown if not
overriden on the edge.</p>
<p><em>If you enjoyed reading this post, check out Jet at
<a href="https://github.com/hazelcast/hazelcast-jet">GitHub</a> and give us a
star!</em></p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2021/03/17/billion-events-per-second">Billion Events Per Second with Millisecond Latency: Streaming Analytics at Giga-Scale</a></h1><p class="post-meta">March 17, 2021</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener">Marko Topolnik</a></p><div class="authorPhoto"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener"><img src="https://pbs.twimg.com/profile_images/922726943614783488/Pb5DDGWF_400x400.jpg" alt="Marko Topolnik"/></a></div></div></header><article class="post-content"><div><span><p>This post is a part of a series:</p>
<ul>
<li><a href="/blog/2020/06/09/jdk-gc-benchmarks-part1">Part 1 (Intro and high-throughput streaming
benchmark)</a></li>
<li><a href="/blog/2020/06/09/jdk-gc-benchmarks-part2">Part 2 (batch workload benchmark)</a></li>
<li><a href="/blog/2020/06/23/jdk-gc-benchmarks-rematch">Part 3 (low-latency benchmark)</a></li>
<li><a href="/blog/2020/08/05/gc-tuning-for-jet">Part 4 (concurrent GC with green threads)</a></li>
<li>Part 5 (you are here)</li>
</ul>
<p>We're preparing a scientific paper on Hazelcast Jet, describing its
architecture based on symmetric, data-local, non-blocking distributed
event processing. As a part of this effort, we implemented the
vendor-neutral <a href="http://datalab.cs.pdx.edu/niagara/NEXMark/">NEXMark</a>
benchmark suite, consisting of 8 streaming queries that aim to capture
typical kinds of questions you're likely to ask about your real-time
data.</p>
<p>The queries deal with a domain model of auctions, sellers, and bids. For
example, Query 5 asks: &quot;Which auctions have achieved the highest price
in the last period?&quot;</p>
<p>In contrast to our previous benchmarks, which focused on single-node
performance (especially GC-induced latency spikes), this time we focus
on horizontal scalability: how do Jet's latency and throughput behave as
you add more and more nodes?</p>
<p>In a cluster of 45 nodes and 720 vCPUs, Jet reached <strong>1 billion
events per second</strong> at a 99% latency of <strong>26 milliseconds</strong>.</p>
<h2><a class="anchor" aria-hidden="true" id="our-setup"></a><a href="#our-setup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Our Setup</h2>
<p>We used the same configuration as in our earlier benchmarks:</p>
<ul>
<li>EC2 instance type
<a href="https://aws.amazon.com/ec2/instance-types/c5/">c5.4xlarge</a> (16 vCPUs)</li>
<li>Oracle OpenJDK 15.0.1 with a single GC parameter:
<code>-XX:MaxGCPauseMillis</code></li>
<li>Hazelcast 4.3</li>
<li>Jet's thread pool size: 12 or 14</li>
</ul>
<p>In our <a href="/blog/2020/08/05/gc-tuning-for-jet">previous experience</a>, we
found you don't need any low-level GC tuning parameters to get great
latency results on the JVM, but you do have to use a recent JDK. We let
the JVM use its default G1 collector and configured it with our desired
GC pause target. Also, note that we size Jet's thread pool a bit below
the system capacity: up to 14 threads on 16-vCPU machines. This
important trick allows the GC to work in the background without
interfering with Jet's real-time computations.</p>
<p>As for the measuring methodology, it is the same as before. Events come
from a generator that lives inside the same JVM as Jet. Every event has
a predetermined moment of occurrence, and it is the generator's duty to
emit it as soon as possible once that time has arrived. Any latency in
emitting the event counts towards the reported latency.</p>
<p>On the output side, we stop the latency clock as soon we observe some
data item corresponding to the newest result. We compare the system time
at that point with the moment at which the query result would ideally
become known. For example, if the query involves a time window, then
the moment at which the window &quot;closes&quot;, is that ideal moment.</p>
<p>We don't require Jet to send the results to any outside system, because
we want our results to focus on Jet's performance alone. The code we
used in the benchmark is available on
<a href="https://github.com/hazelcast/big-data-benchmark/tree/master/nexmark-jet/src/main/java/com/hazelcast/jet/benchmark/nexmark">GitHub</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="benchmark-1-9999th-percentile-latency-with-20-ms-time-resolution"></a><a href="#benchmark-1-9999th-percentile-latency-with-20-ms-time-resolution" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Benchmark 1: 99.99th Percentile Latency with 20 ms Time Resolution</h2>
<p>For the first benchmark we asked this question: using a time resolution
of 50 result updates per second and an input rate of 1 million events
per second, what is the 99.99% latency at different cluster sizes?</p>
<p>The main point of this benchmark is probing deep into the rare system
events that may cause latency spikes, however the original definitions
of NEXMark queries ask for a very low update frequency (once per
minute). At this rate it would take 100 minutes to get barely enough
data to report the 99th percentile latency, and a whole week to get the
99.99th percentile. Therefore we changed this to 50 times per second
(20-millisecond update period).</p>
<p>Having to report another complete set of results (10,000 data points)
every 20 milliseconds, Jet doesn't have time to recover from any hiccup
greater than a few milliseconds. For this reason we configured the GC
pause target to 5 milliseconds (<code>-XX:MaxGCPauseMillis=5</code>).</p>
<p>NEXMark doesn't define the number of distinct keys involved in the
queries, we set it to 10,000 for this benchmark.</p>
<p>We used the setting of 12 Jet threads per node, mostly because that's
what we used in the previous benchmarks. We got these results:</p>
<p><img src="/blog/assets/2021-03-17-latency-vs-scaling.png" alt="99.99% latency of NEXMark queries at 1M event/second vs. cluster
size"></p>
<p>The overall worst case was Query 5 in the largest cluster (20 nodes),
and it came out as 16 milliseconds.</p>
<h2><a class="anchor" aria-hidden="true" id="benchmark-2-99th-percentile-latency-at-a-billion-events-per-second"></a><a href="#benchmark-2-99th-percentile-latency-at-a-billion-events-per-second" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Benchmark 2: 99th Percentile Latency at a Billion Events per Second</h2>
<p>Our second question was this: How much hardware would Jet need to reach
a throughput of a billion events per second, while maintaining its
millisecond-level latency?</p>
<p>To test this, we selected the NEXMark query that seemed the toughest on
Jet given the results from Benchmark 1. This is Query 5, which showed
a 99.99% latency 16 milliseconds in a 20-node cluster.</p>
<p>Since this time we'll create much more pressure on the input side,
aiming for the highest possible throughput, we relaxed the timings a
bit. We ask for two updates per second (a new result set every 500
milliseconds), and accordingly had to adjust our percentile to 99% in
order to make it practical. We also relaxed the GC timing, setting
<code>-XX:MaxGCPauseMillis=50</code>.</p>
<p>We started with just a single node, finding the maximum event rate Jet
can keep up with. The definition of &quot;keeping up&quot; is that the latency
stays bounded during the test and doesn't constantly increase. We
repeated the process at increasing cluster sizes, until reaching our
goal of one billion. Here is what we found:</p>
<p><img src="/blog/assets/2021-03-17-query5-thruput.png" alt="Query 5 throughput vs. threads used"></p>
<p>First of all, Jet was able to handle <strong>25 million events per second on a
single node</strong> and, even more impressively, this number kept scaling
linearly all the way to our target, which it reached at a size of 40
nodes.</p>
<p>During the process we realized we could let Jet use more threads without
impacting the latency, and since we wanted to minimize the number of EC2
instances, we let it use 14 threads. This still leaves 2 vCPUs to the
background GC work and other system needs. If you look carefully, you
can see the curve in the chart bending slightly upwards at the 20-node
mark, this is an artifact of the 40-node measurements being taken with
Jet using 8.6% more threads per node (14 vs. 12).</p>
<p>The criterion for maximum throughput is just keeping up with the input,
allowing the latency to temporarily reach higher values as long as it
settles back down. In order to gauge Jet's stable latency at various
scales, we did another round of tests at 80% of the maximum throughput
determined for each cluster size. This gave us the following latency
chart:</p>
<p><img src="/blog/assets/2021-03-17-query5-latency.png" alt="Jet throughput vs. threads used"></p>
<p>We can see that, although it's increasing, the latency stays pretty flat
across a range of sizes well exceeding the capacity you'd probably need
from Jet in real life.</p>
<p>Finally, we started from the setup that supported a billion events per
second (40 nodes) and continued adding nodes until we got a stable low
latency. This was our result: <strong>45 nodes, 26 milliseconds</strong>.</p>
<p><em>If you enjoyed reading this post, check out Jet at
<a href="https://github.com/hazelcast/hazelcast-jet">GitHub</a> and give us a
star!</em></p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2021/02/03/jet-44-is-released">Jet 4.4 Released</a></h1><p class="post-meta">February 3, 2021</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener">Marko Topolnik</a></p><div class="authorPhoto"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener"><img src="https://pbs.twimg.com/profile_images/922726943614783488/Pb5DDGWF_400x400.jpg" alt="Marko Topolnik"/></a></div></div></header><article class="post-content"><div><span><p>Today we're releasing Hazelcast Jet 4.4 and we have some exciting new
features!</p>
<h2><a class="anchor" aria-hidden="true" id="jet-sql"></a><a href="#jet-sql" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Jet SQL</h2>
<p>Hazelcast Jet 4.4 brings you the first beta version of our SQL
interface. You can now log into Jet from the command line and issue
queries against the data sources you specify. They can be both data at
rest (<em>batch</em> sources) and live feeds (<em>streaming</em> sources).</p>
<p>If you have Docker at hand, here's something you can try out right now!
(For examples that don't require Docker, go to the
<a href="/docs/sql/intro">docs</a>.)</p>
<pre><code class="hljs css language-bash">docker pull hazelcast/hazelcast-jet
docker network create jet-network
docker run --name jet --network jet-network -v <span class="hljs-string">"<span class="hljs-variable">$(pwd)</span>"</span>:/csv-dir --rm hazelcast/hazelcast-jet
</code></pre>
<p>Wait for a message like this in the output:</p>
<pre><code class="hljs css language-text">2021-01-15 17:50:18,645 [ INFO] [main] [c.h.c.LifecycleService]:
    [172.17.0.2]:5701 is STARTED
</code></pre>
<p>Now start another terminal window and enter the SQL shell:</p>
<pre><code class="hljs css language-text">$ docker run --network jet-network -it --rm hazelcast/hazelcast-jet jet --targets jet sql
Connected to Hazelcast Jet 4.4 at [172.17.0.2]:5701 (+0 more)
Type 'help' for instructions
sql〉
</code></pre>
<p>You are now ready to write some SQL. Try these:</p>
<pre><code class="hljs css language-sql">sql〉 <span class="hljs-keyword">SELECT</span> * <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">TABLE</span>(generate_series(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>));
+<span class="hljs-comment">------------+</span>
|           v|
+<span class="hljs-comment">------------+</span>
|           1|
|           2|
|           3|
+<span class="hljs-comment">------------+</span>
3 row(s) selected
sql〉 <span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">key</span>, <span class="hljs-keyword">sum</span>(<span class="hljs-keyword">key</span>) <span class="hljs-keyword">as</span> total <span class="hljs-keyword">FROM</span> (
          <span class="hljs-keyword">SELECT</span> v/<span class="hljs-number">2</span> <span class="hljs-keyword">as</span> <span class="hljs-keyword">key</span> <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">TABLE</span>(generate_series(<span class="hljs-number">0</span>, <span class="hljs-number">7</span>))
      ) <span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> <span class="hljs-keyword">key</span>;
+<span class="hljs-comment">--------------------+--------------------+</span>
|                 key|               total|
+<span class="hljs-comment">--------------------+--------------------+</span>
|                   0|                   0|
|                   1|                   2|
|                   2|                   4|
|                   3|                   6|
+<span class="hljs-comment">--------------------+--------------------+</span>
4 row(s) selected
</code></pre>
<p>Here are two more examples with streaming SQL. Streaming queries never
complete, so use <code>Ctrl+C</code> to cancel them after a while:</p>
<pre><code class="hljs css language-sql">sql〉 <span class="hljs-keyword">SELECT</span> * <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">TABLE</span>(generate_stream(<span class="hljs-number">10</span>));
+<span class="hljs-comment">--------------------+</span>
|                   v|
+<span class="hljs-comment">--------------------+</span>
|                   0|
|                   1|
|                   2|
^C
Query cancelled.
sql〉 <span class="hljs-keyword">SELECT</span> * <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">TABLE</span>(generate_stream(<span class="hljs-number">100</span>)) <span class="hljs-keyword">WHERE</span> v / <span class="hljs-number">10</span> * <span class="hljs-number">10</span> = v;
+<span class="hljs-comment">--------------------+</span>
|                   v|
+<span class="hljs-comment">--------------------+</span>
|                   0|
|                  10|
|                  20|
^C
Query cancelled.
sql〉
</code></pre>
<p>For more examples with CSV files, Kafka and IMap, go to the
<a href="/docs/sql/intro">docs</a>.</p>
<p>We're currently very focused on bringing more features to our SQL, so
stay tuned!</p>
<h2><a class="anchor" aria-hidden="true" id="file-connector"></a><a href="#file-connector" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>File Connector</h2>
<p>The <a href="/docs/api/sources-sinks">Unified File Connector API</a> gives you a
simple way to read files, unified across different storage systems.
Using the same API you can read files from the local filesystem, Hadoop
FS, Amazon S3, Google Cloud Storage, and Azure Blob Storage. At the same
time, the connector supports a variety of encoding formats: text files,
CSV, JSON, Avro, etc., equally for all storage systems.</p>
<p>Here's how the Java syntax looks:</p>
<pre><code class="hljs css language-java"><span class="token class-name">BatchSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> source <span class="token operator">=</span> <span class="token class-name">FileSources</span>
    <span class="token punctuation">.</span><span class="token function">files</span><span class="token punctuation">(</span><span class="token string">"/path/to/my/directory"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>You specify the storage system type with the URI schema, for example to
access S3:</p>
<pre><code class="hljs css language-java"><span class="token class-name">BatchSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> source <span class="token operator">=</span> <span class="token class-name">FileSources</span>
    <span class="token punctuation">.</span><span class="token function">files</span><span class="token punctuation">(</span><span class="token string">"s3a://bucket-id/path/to/my/directory"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>And this is how you tell it to use the Avro encoding:</p>
<pre><code class="hljs css language-java"><span class="token class-name">BatchSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">User</span><span class="token punctuation">></span></span> source <span class="token operator">=</span> <span class="token class-name">FileSources</span>
    <span class="token punctuation">.</span><span class="token function">files</span><span class="token punctuation">(</span><span class="token string">"s3a://bucket-id/path/to/my/directory"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token class-name">FileFormat</span><span class="token punctuation">.</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">User</span><span class="token punctuation">></span></span><span class="token function">avro</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Read more in the <a href="/docs/api/sources-sinks">Programming Guide</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="kinesis-connector"></a><a href="#kinesis-connector" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Kinesis Connector</h2>
<p><a href="https://aws.amazon.com/kinesis/data-streams/">Amazon Kinesis Data
Streams</a> (KDS) is a
durable, scalable real-time data streaming service native to the AWS
environment, and fully managed by it. You can use it as both a source
and a sink in a Hazelcast Jet pipeline:</p>
<pre><code class="hljs css language-java"><span class="token class-name">StreamSource</span><span class="token operator">&lt;</span><span class="token class-name">Map<span class="token punctuation">.</span>Entry</span><span class="token operator">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">>></span> source <span class="token operator">=</span> <span class="token class-name">KinesisSources</span>
        <span class="token punctuation">.</span><span class="token function">kinesis</span><span class="token punctuation">(</span><span class="token string">"Tweets"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">withInitialShardIteratorRule</span><span class="token punctuation">(</span><span class="token string">".*"</span><span class="token punctuation">,</span> <span class="token string">"LATEST"</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Sink</span><span class="token operator">&lt;</span><span class="token class-name">Entry</span><span class="token operator">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">>></span> sink <span class="token operator">=</span> <span class="token class-name">KinesisSinks</span>
        <span class="token punctuation">.</span><span class="token function">kinesis</span><span class="token punctuation">(</span><span class="token string">"Tweets"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Pipeline</span> p <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span>source<span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>e <span class="token operator">-></span> <span class="token function">entry</span><span class="token punctuation">(</span>e<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>e<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"-processed"</span><span class="token punctuation">)</span>
         <span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span>UTF_8<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span>sink<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Check out our <a href="/docs/tutorials/kinesis">tutorial</a> for a full example.</p>
<h2><a class="anchor" aria-hidden="true" id="enforce-strict-event-order"></a><a href="#enforce-strict-event-order" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Enforce Strict Event Order</h2>
<p>Hazelcast Jet's primary focus is to leverage all opportunities to
improve the throughput and latency of its computation. One example is
using logic that isn't sensitive to the exact event order. Jet can use
this freedom to optimally load-balance the data across parallel tasks.
This works great for stateless transforms like <code>map</code> and <code>filter</code> as
well as aggregate operations specifically written in terms of
commutative and associative functions. However, Jet also supports
transforms such as <code>mapStateful</code>, where reordering any two events is
likely to result in different output.</p>
<p>In version 4.4 we provide a new option,
<code>pipeline.setPreserveOrder(true)</code>, which tells Jet to disable the
dataflow optimizations that result in reordered events. One consequence
of enabling it is that the level of parallelism in the source stage
determines the parallelism of all the subsequent stages because the data
flows in parallel lanes through the pipeline. So if you have a source
that isn't paralellized, your whole pipeline won't be parallelized
either (at least until a stage that explicitly changes the order, such
as <code>rebalance</code> or <code>groupingKey</code>). This feature works best when you have
a partitioned source and you only require strict order among events with
the same key. Then you get both the ordering you need and decent
parallelization.</p>
<h2><a class="anchor" aria-hidden="true" id="improved-packaging"></a><a href="#improved-packaging" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Improved Packaging</h2>
<p>We used to offer Jet packaged with some hand-picked extensions while you
could add others by downloading them separately. As of 4.4 we offer two
kinds: a full package with all the extensions, and a slim one with none.
Normally you want to use the full package, but if you want to optimize
the download size or disk usage, use the slim package.</p>
<p>Along the same lines, we now provide a slim Docker image,
<code>hazelcast/hazelcast-jet:4.4-slim</code>, to serve as the base image in your
Dockerfile that combines it with the extensions, like this:</p>
<pre><code class="hljs css language-Dockerfile"><span class="hljs-keyword">FROM</span> hazelcast-jet:<span class="hljs-number">4.4</span>-slim
<span class="hljs-keyword">ARG</span> JET_HOME=/opt/hazelcast-jet
<span class="hljs-keyword">ARG</span> REPO_URL=https://repo1.maven.org/maven2/com/hazelcast/jet
<span class="hljs-keyword">ADD</span><span class="bash"> <span class="hljs-variable">$REPO_URL</span>/hazelcast-jet-kafka/4.4/hazelcast-jet-kafka-4.4-jar-with-dependencies.jar <span class="hljs-variable">$JET_HOME</span>/lib/</span>
<span class="hljs-comment"># ... more ADD statements ...</span>
</code></pre>
<p>See the
<a href="/docs/operations/docker#build-a-custom-image-from-the-slim-image">instructions</a>
in our docs for more details.</p>
<h2><a class="anchor" aria-hidden="true" id="full-release-notes"></a><a href="#full-release-notes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Full Release Notes</h2>
<p>Hazelcast Jet 4.4 is based on IMDG version 4.1.1. Check out its Release
Notes <a href="https://docs.hazelcast.org/docs/rn/index.html#4-1-1">here</a> and,
for the Enterprise Edition,
<a href="https://docs.hazelcast.org/docs/ern/index.html#4-1-1">here</a>.</p>
<p>Members of the open source community that appear in these release notes:</p>
<ul>
<li>@TomaszGaweda</li>
<li>@hhromic</li>
</ul>
<p>Thank you for your valuable contributions!</p>
<h3><a class="anchor" aria-hidden="true" id="new-features"></a><a href="#new-features" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>New Features</h3>
<ul>
<li><p>[sql] SQL Beta: submit jobs to Jet from the command-line SQL shell.
(#2595, #2636, #2648, #2654, #2665, #2729, #2763, #2788)</p></li>
<li><p>[file-api] [017] Unified API to create sources and sinks from
file-like resources: local filesystem, Amazon S3, Azure Blob Storage
and Data Lake Storage, Google Cloud Storage (#2518)</p></li>
<li><p>[kinesis] [018] Amazon Kinesis connector (#2656)</p></li>
<li><p>[pipeline-api] [016] Prevent event reordering: by default Jet reorders
data for performance, now you can disable this to get strict event
order where you need it.</p></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="enhancements"></a><a href="#enhancements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Enhancements</h3>
<ul>
<li><p>[connectors] @hhromic improved the naming of source and sink stages
across different connectors, bringing them all in line with the same
convention <code>xSource</code> / <code>xSink</code> (#2685)</p></li>
<li><p>[pipeline-api] @TomaszGaweda added the <code>pipeline.isEmpty()</code> method
that tells whether it contains any stage (#2659)</p></li>
<li><p>[core] @TomaszGaweda added the
<code>jet.imdg.version.mismatch.check.disabled</code> config property that
disables the enforcement of the exact IMDG dependency version. This
allows adding IMDG quick fixes to the existing Jet release. (#2610)</p></li>
<li><p>[core] New packaging: download either the full package with all the
extensions enabled, or the minimal package and separately download the
extensions you want. (#2796)</p></li>
<li><p>[cli] Improved the behavior of <code>jet submit</code>: now it waits for the job
to start and prints a message about it. (#2699)</p></li>
<li><p>[python] Improved the error message when using a Python function but
Python is not installed. (#2672)</p></li>
<li><p>[kafka] Improved the performance of the Kafka source by fine-tuning
some timeouts. (#2732)</p></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="fixes"></a><a href="#fixes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fixes</h3>
<ul>
<li><p>[core] Fixed a problem where Jet would close <code>System.out</code> during JVM
shutdown, preventing shutdown hooks from printing to stdout. (#2649)</p></li>
<li><p>[file-connector] Fixed the blocking File connector declaring its
processors as cooperative, resulting in performance loss. (#2628)</p></li>
<li><p>[file-connector] Several bug fixes in the File connector. (#2772)</p></li>
<li><p>[core] Fixed a leak caused by Jet's ephemeral loggers created for each
job. They didn't get released from internal maps in the logging
framework. (#2737)</p></li>
<li><p>[core] Fixed two problems with the <code>peek</code> transform. (#2740, #2765)</p></li>
<li><p>[hadoop] Fixed a problem when using Hadoop for local files, it behaved
as if the files were shared. (#2764)</p></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="breaking-changes"></a><a href="#breaking-changes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Breaking Changes</h3>
<p>None.</p>
<p><em>If you enjoyed reading this post, check out Jet at
<a href="https://github.com/hazelcast/hazelcast-jet">GitHub</a> and give us a
star!</em></p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/10/23/jet-43-is-released">Jet 4.3 Released</a></h1><p class="post-meta">October 23, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener">Marko Topolnik</a></p><div class="authorPhoto"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener"><img src="https://pbs.twimg.com/profile_images/922726943614783488/Pb5DDGWF_400x400.jpg" alt="Marko Topolnik"/></a></div></div></header><article class="post-content"><div><span><p>Today we're releasing Hazelcast Jet 4.3, our fourth release in 2020!</p>
<p>We took part in Google Summer of Code that ended just a few weeks ago,
and this release already brings a productionized piece of work by our
student, <a href="https://github.com/MohamedMandouh">Mohamed Mandouh</a>:
distributed in-memory sorting. Mohamed's primary focus was research into
the feasibility of integrating RocksDB or a similar DB library as a
disk-based state backend for Jet's hash join, aggregation and sorting,
and we plan to continue with this work for some more time.</p>
<p>Here are the main improvements in this release:</p>
<h2><a class="anchor" aria-hidden="true" id="benchmarking-and-tuning-for-low-latency"></a><a href="#benchmarking-and-tuning-for-low-latency" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Benchmarking and Tuning for Low Latency</h2>
<p>Continuing the story from the previous release, we <a href="/blog/2020/08/05/gc-tuning-for-jet">benchmarked and
fine-tuned Jet</a> with a focus on
low-latency processing. Jet can now give you a 99.99th percentile
latency of less than 10 milliseconds at a pipeline throughput of 60M
items/second! Based on this work we significantly expanded the
Operations Guide section on <a href="/docs/operations/gc-concerns">Garbage
Collection</a> with many new
latency-squashing tricks.</p>
<h2><a class="anchor" aria-hidden="true" id="batchstagesort"></a><a href="#batchstagesort" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>BatchStage.sort()</h2>
<p>As mentioned, this is the work coming out of this year's GSoC. You can
now sort the data coming out of a batch pipeline stage. For example,
this starts from an asceding sequence 0..9,999, sorts it in descending
order, and prints the result:</p>
<pre><code class="hljs css language-java"><span class="token keyword">var</span> pipeline <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">var</span> integerSequence <span class="token operator">=</span> <span class="token class-name">TestSources</span><span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token class-name">IntStream</span><span class="token punctuation">.</span><span class="token function">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10_000</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">boxed</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toArray</span><span class="token punctuation">(</span><span class="token class-name">Integer</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">::</span><span class="token keyword">new</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
pipeline<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span>integerSequence<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">sort</span><span class="token punctuation">(</span><span class="token class-name">ComparatorEx</span><span class="token punctuation">.</span><span class="token function">comparing</span><span class="token punctuation">(</span>i <span class="token operator">-></span> <span class="token operator">-</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">logger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">try</span> <span class="token punctuation">{</span>
    <span class="token class-name">Jet</span><span class="token punctuation">.</span><span class="token function">bootstrappedInstance</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">newJob</span><span class="token punctuation">(</span>pipeline<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>
    <span class="token class-name">Jet</span><span class="token punctuation">.</span><span class="token function">shutdownAll</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Jet's current execution model allows reordering, e.g., when maximizing
parallel throughput in stateless transform stages, which means you may
easily lose the sort order. In the next release we'll add the ability to
set limits on these optimizations so that the ordering survives.</p>
<h2><a class="anchor" aria-hidden="true" id="testsourceslongstream"></a><a href="#testsourceslongstream" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>TestSources.longStream()</h2>
<p>Our community contributor <a href="https://github.com/guenter-hesse">Guenter
Hesse</a> took the ad-hoc work we did for
our low latency GC benchmarks and productionized it to be included in
our library. If you want to benchmark Hazelcast Jet in a way that
doesn't depend on the specifics of an actual data source, you can use
this distributed event generator that produces a timestamped sequence of
<code>Long</code> numbers. You can then transform the sequence numbers to whichever
mock events you are using for the benchmark:</p>
<pre><code class="hljs css language-java"><span class="token class-name">StreamStage</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> trades <span class="token operator">=</span> pipeline
        <span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">TestSources</span><span class="token punctuation">.</span><span class="token function">longStream</span><span class="token punctuation">(</span><span class="token number">1_000_000</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">withNativeTimestamps</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>i <span class="token operator">-></span> <span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"Trade %09d"</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>This stage will generate a steady stream of a million events per second,
keeping the latency of emiting any given event at a minimum. If you run
it in a cluster, every cluster node will generate its share of the
events.</p>
<h2><a class="anchor" aria-hidden="true" id="preserve-job-state-on-exception"></a><a href="#preserve-job-state-on-exception" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Preserve Job State on Exception</h2>
<p>Jet's default behavior (and so far the only choice) is to cancel and
dispose of a job that throws an exception from any part of the pipeline.
This is usually user code, but it could also be IO errors while
contacting outside services. We are now introducing an option that
applies to jobs with enabled fault tolerance: Jet can now keep the job
in a suspended state, with the latest snapshot attached to it. Once you
remove the cause of the exception, you can resume the job and it will
continue executing without data loss.</p>
<p>As a part of these improvements, we added a whole new section on <a href="/docs/api/error-handling">error
handling</a> in the Programming Guide.</p>
<h2><a class="anchor" aria-hidden="true" id="make-continuous-progress-in-pipelines-based-on-ingestion-time"></a><a href="#make-continuous-progress-in-pipelines-based-on-ingestion-time" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Make Continuous Progress in Pipelines Based on Ingestion Time</h2>
<p>Hazelcast Jet is primarily built to respect the original event
timestamps instead of just noting the time it received them. Time
advances in the pipeline when events with fresh timestamps arrive. This
system has an Achilles' heel for the case where the event stream is very
sparse: without events, time doesn't pass. When you have a partitioned
data source, each partition has its own event time, and Jet must
consolidate them into a single global event time. For this to work out
without losses, time advances according to the &quot;slowest&quot; partition, with
the lowest local event time. So all it takes is a single partition out
of potential hundreds or thousands, to experience very low traffic, and
your entire pipeline experiences stalls.</p>
<p>In this release we bring a partial solution to this general problem:
if you happen to work with a pipeline based on ingestion time instead of
event time, Jet can be certain that the time advances in any partition
with or without events. We use this to improve our watermark emission
logic and make progress regardless of actual events coming in. We expect
to invest more effort into heuristic approaches that will improve the
progress of event time-based pipelines as well.</p>
<h2><a class="anchor" aria-hidden="true" id="full-release-notes"></a><a href="#full-release-notes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Full Release Notes</h2>
<p>Hazelcast Jet 4.3 is based on IMDG version 4.0.3. Check out its Release
Notes <a href="https://docs.hazelcast.org/docs/rn/index.html#4-0-3">here</a> and,
for the Enterprise Edition,
<a href="https://docs.hazelcast.org/docs/ern/index.html#4-0-3">here</a>.</p>
<p>Members of the open source community that appear in these release notes:</p>
<ul>
<li>@caioguedes</li>
<li>@guenter-hesse</li>
<li>@MohamedMandouh</li>
</ul>
<p>Thank you for your valuable contributions!</p>
<h3><a class="anchor" aria-hidden="true" id="new-features"></a><a href="#new-features" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>New Features</h3>
<ul>
<li>[pipeline-api] [014] @MohamedMandouh implemented distributed sorting:
<code>BatchStage.sort()</code> (#2469, #2544)</li>
<li>[core] [012] Added <code>JobConfig.suspendOnFailure</code>: suspend a job on
exception instead of cancelling it (#2411)</li>
<li>[cdc] Improved the consistency of reconnect behaviour across CDC
sources, new uniform API to configure the reconnect strategy (#2419)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="enhancements"></a><a href="#enhancements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Enhancements</h3>
<ul>
<li>[core] @guenter-hesse contributed a test source to benchmark Jet's
throughput and latency (#2382)</li>
<li>[core] [013] Improved watermark semantics that prevent low event rate
from stalling an ingestion time-based pipeline (#2485, #2514)</li>
<li>[cdc] Exposed the sequence number in the CDC <code>ChangeRecord</code> that
orders the events (#2390)</li>
<li>[core] Two new DAG edge types: <code>distributeToOne</code> (sending all data to
one member) and <code>ordered</code> (maintaining the sort order) (#2394, #2469,
#2544)</li>
<li>[core] Disabled access to external XML entities when parsing XML
config, this was a potential XXE attack vector (#2528)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="fixes"></a><a href="#fixes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fixes</h3>
<ul>
<li>[core] Fixed error handling during job startup that could result in
inconsistent job state (#2383)</li>
<li>[core] Fixed an internal exception that leaked out of Observable
(#2313, #2389)</li>
<li>[core] Prevented Observable from processing in-flight items after
cancellation (#2415, #2418)</li>
<li>[cli] @caioguedes fixed an issue with <code>--targets</code> option in CLI where
it would overwrite other settings (#2373, #2421)</li>
<li>[metrics] Fixed a problem where an internally added DAG vertex would
show up as a source instead of the actual source vertex (#2475, #2476)</li>
<li>[core] Fixed a race that could cause <code>getJobStatus()</code> to throw an
exception if called right after <code>newJob()</code> (#2481, #2484)</li>
<li>[core] Fix a race between snapshotting and restarting (#2487, #2503)</li>
<li>[core] Fixed a race where <code>getJobStatus()</code> would report <code>RUNNING</code> even
though it was actually <code>COMPLETING</code>. (#2507)</li>
<li>[core] Fixed an issue where a <code>DONE_ITEM</code> could get lost due to
connection failure, preventing the job from completing (#2158, #2532)</li>
<li>[core] Fixed a job failure related to the coordinator member failing
(#2461, #2546)</li>
<li>[core] Fixed a job failure related to a member reconnecting (#2542,
#2547)</li>
<li>[core] Improved robustness related to Jet's internal <code>IMap</code> operations
(#2533, #2550)</li>
<li>[cdc] Upgraded Jackson jr dep, solving a null handling issue (#2459)</li>
<li>[cdc] Upgraded the Debezium dep, solving a Postgress issue resulting
in data loss when snapshotting (#2406)</li>
<li>[core] Fixed a bug where a non-keyed aggregating stage would produce
no output when no input (#2560, #2567)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="breaking-changes"></a><a href="#breaking-changes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Breaking Changes</h3>
<ul>
<li>[pipeline-api] Breaking signature change to
<code>Sources.streamFromProcessorWithWatermarks()</code></li>
<li>[pipeline-api] Deprecated <code>Pipeline.toDag()</code>, made <code>Pipeline</code> and all
its components <code>Serializable</code>.</li>
<li>[core-api] Breaking signature change to <code>StreamEventJournalP</code>, methods
<code>streamRemoteMapSupplier()</code> and <code>streamRemoteCacheSupplier</code></li>
</ul>
<p><em>If you enjoyed reading this post, check out Jet at
<a href="https://github.com/hazelcast/hazelcast-jet">GitHub</a> and give us a
star!</em></p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/10/06/enabling-full-text-search">Enabling Full-text Search with Change Data Capture in a Legacy Application</a></h1><p class="post-meta">October 6, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/frantisek-hartman/" target="_blank" rel="noreferrer noopener">František Hartman</a></p><div class="authorPhoto"><a href="https://www.linkedin.com/in/frantisek-hartman/" target="_blank" rel="noreferrer noopener"><img src="https://i.stack.imgur.com/3X7wE.png" alt="František Hartman"/></a></div></div></header><article class="post-content"><div><span><p>In this post, we will take a legacy application and improve its search
functionality. We will do this with only a few changes to the
application itself. Using a technique called change data capture (CDC)
we will listen for changes in a database and react to these
changes - write to a search index case. Before writing to the
search index, we will also enrich the data with a natural language
processing (NLP) step that extracts keywords from a text description.</p>
<p>We might want to use an external search index for various reasons,
especially:</p>
<ul>
<li><p>to provide more feature-rich functionality than full-text search in a
relational database;</p></li>
<li><p>to scale the search independently of the database;</p></li>
<li><p>to add more functionality (keyword extraction) to the application
without
modifying it - making changes to a legacy application is sometimes
risky, or time-consuming, so taking this approach might be faster,
therefore cheaper.</p></li>
</ul>
<p>In this tutorial we will do the following:</p>
<ul>
<li><p>Use Hazelcast Jet - an open-source stream processing system - and its CDC
module to read changes made to the application database for further
processing in a Jet pipeline.</p></li>
<li><p>In the Jet pipeline, we will enrich the data with an NLP mapping step.</p></li>
<li><p>Write the results to an Elasticsearch index, using an Elasticsearch
connector, <a href="/blog/2020/07/14/jet-42-is-released">released in Jet 4.2</a>.</p></li>
</ul>
<p><img src="/blog/assets/2020-10-06-architecture.png" alt="Architecture"></p>
<h2><a class="anchor" aria-hidden="true" id="the-application"></a><a href="#the-application" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Application</h2>
<p>We chose the <a href="https://github.com/spring-projects/spring-petclinic">Spring
PetClinic</a>
application. It is relatively well-known to many Java developers and is
rather similar to a typical enterprise application.</p>
<p>The application provides a management tool for managing pets, their
owners, and visits to vets. It allows searching for owners, but only
using the owner’s last name. We will make the search more feature-rich,
allowing us to search on first name, last name, pet names and keywords
extracted from descriptions of the visits.</p>
<p>First, let’s start a vanilla version of the application. Run the
following command to start MySQL database inside a Docker container, we
use the official MySQL image, which allows us to create a database for
the pet clinic application easily:</p>
<pre><code class="hljs css language-bash">docker run --name petclinic-mysql -it \
  -e MYSQL_DATABASE=petclinic \
  -e MYSQL_USER=petclinic \
  -e MYSQL_PASSWORD=petclinic \
  -e MYSQL_ROOT_PASSWORD=mysql \
  -p 3306:3306 mysql
</code></pre>
<p>Clone the pet clinic application source code from
<a href="https://github.com/hazelcast-demos/spring-petclinic">Github</a> (this is a
fork of the official <a href="https://github.com/spring-projects/spring-petclinic">Spring PetClinic
repository</a> with a
branch containing the changes we will make later for your convenience).</p>
<pre><code class="hljs css language-bash">git <span class="hljs-built_in">clone</span> https://github.com/hazelcast-demos/spring-petclinic.git
</code></pre>
<p>Start the pet clinic application from the command line by running the
following command:</p>
<pre><code class="hljs css language-bash"><span class="hljs-built_in">cd</span> spring-petclinic
./mvnw spring-boot:run -Dspring-boot.run.profiles=mysql
</code></pre>
<p>And wait for the following log message:</p>
<pre><code class="hljs css language-text">2020-09-30 16:17:04.113  INFO 24847 --- [  restartedMain] o.s.s.petclinic.PetClinicApplication     : Started PetClinicApplication in 3.177 seconds (JVM running for 3.5)
</code></pre>
<p>Navigate to <a href="http://localhost:8080/">http://localhost:8080/</a></p>
<p>-&gt; Click Find Owners in top-level menu</p>
<p>-&gt; Click Find Owner button to list all data</p>
<p>and you should see a screen similar to the following:</p>
<p><img src="/blog/assets/2020-10-06-spring-petclinic-list.png" alt="Spring PetClinic Sample Application"></p>
<h2><a class="anchor" aria-hidden="true" id="prepare-for-change-data-capture"></a><a href="#prepare-for-change-data-capture" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Prepare for Change Data Capture</h2>
<p>In order to stream the changes from the MySQL database we need to modify
certain settings and grant more permissions to the <code>petclinic</code> user.</p>
<p>Run the following command to start MySQL client, enter the <code>mysql</code>
password for the root user:</p>
<pre><code class="hljs css language-bash">docker run -it --rm --link petclinic-mysql:petclinic-mysql mysql mysql -hpetclinic-mysql -uroot -p
</code></pre>
<p>Run the following to grant privileges to the <code>petclinic</code> user to allow
listening to the database changes:</p>
<pre><code class="hljs css language-sql"><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">USER</span> petclinic <span class="hljs-keyword">IDENTIFIED</span> <span class="hljs-keyword">WITH</span> mysql_native_password <span class="hljs-keyword">BY</span> <span class="hljs-string">'petclinic'</span>;
<span class="hljs-keyword">GRANT</span> RELOAD <span class="hljs-keyword">ON</span> *.* <span class="hljs-keyword">TO</span> <span class="hljs-string">'petclinic'</span>;
<span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">REPLICATION</span> <span class="hljs-keyword">CLIENT</span> <span class="hljs-keyword">ON</span> *.* <span class="hljs-keyword">TO</span> <span class="hljs-string">'petclinic'</span>;
<span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">REPLICATION</span> <span class="hljs-keyword">SLAVE</span> <span class="hljs-keyword">ON</span> *.* <span class="hljs-keyword">TO</span> <span class="hljs-string">'petclinic'</span>;
</code></pre>
<p>The <code>ALTER USER</code> command changes the default authentication method to
one supported by the Jet CDC connector. The <code>GRANT</code> commands allow the
petclinic user to stream changes from the database in the same way as
during master-slave replication.</p>
<h2><a class="anchor" aria-hidden="true" id="start-elasticsearch"></a><a href="#start-elasticsearch" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Start Elasticsearch</h2>
<p>We want to enable full-text search across multiple fields, but not all
fields. With Elasticseach we need to create an index mapping that
copies fields into a single field, the field is then used for searching.</p>
<p>Run the following command to start Elasticsearch inside a docker
container:</p>
<pre><code class="hljs css language-bash">docker run --name petclinic-elastic \
  -e discovery.type=single-node \
  -e cluster.routing.allocation.disk.threshold_enabled=<span class="hljs-literal">false</span> \
  -p9200:9200 elasticsearch:7.9.2
</code></pre>
<p>Create an Elasticsearch index mapping by running the following command:</p>
<pre><code class="hljs css language-bash">curl -XPUT -H <span class="hljs-string">"Content-type: application/json"</span> -d <span class="hljs-string">'
{
  "mappings": {
    "properties": {
      "first_name": {
        "type": "text",
        "copy_to": "search"
      },
      "last_name": {
        "type": "text",
        "copy_to": "search"
      },
      "pets.name": {
        "type": "text",
        "copy_to": "search"
      },
      "pets.visits.keywords": {
        "type": "text",
        "copy_to": "search"
      },
      "search": {
        "type": "text"
      }
    }
  }
}'</span> http://localhost:9200/petclinic-index
</code></pre>
<p>The default setting of Elasticsearch analyzer is suitable for us. For
more elaborate configuration of the text analysis, you should look into
the Elasticsearch documentation or some other source.</p>
<h2><a class="anchor" aria-hidden="true" id="hazelcast-jet-job"></a><a href="#hazelcast-jet-job" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hazelcast Jet Job</h2>
<p>Now that we have the Petclinic and Elastic set-up and working, we can
start the data pump - a Jet job reading change events from MySQL
database and writing into the Elastic index.</p>
<p>A Jet job is a pipeline of steps that read, modify, aggregate or store
data items. The job definition is written in Java and packaged as a jar
file. The jar file is deployed to a Jet cluster, which takes care of the
execution, scaling, fail-over and other operational aspects.</p>
<p>The job consists of 4 main parts:</p>
<ul>
<li><p>CDC Source connecting to MySQL database</p></li>
<li><p>A mapping step running the keyword extraction</p></li>
<li><p>A joining step reconstructing the document from change records from</p></li>
<li><p>different tables</p></li>
<li><p>Elasticsearch sink</p></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="cdc-source"></a><a href="#cdc-source" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>CDC Source</h3>
<p>The configuration of the source is straightforward, just set the required
parameters:</p>
<pre><code class="hljs css language-java"><span class="token class-name">StreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">ChangeRecord</span><span class="token punctuation">></span></span> source <span class="token operator">=</span> <span class="token class-name">MySqlCdcSources</span>
    <span class="token punctuation">.</span><span class="token function">mysql</span><span class="token punctuation">(</span><span class="token string">"mysql"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">setDatabaseAddress</span><span class="token punctuation">(</span>databaseAddress<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">setDatabasePort</span><span class="token punctuation">(</span>databasePort<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">setDatabaseUser</span><span class="token punctuation">(</span>databaseUser<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">setDatabasePassword</span><span class="token punctuation">(</span>databasePassword<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">setClusterName</span><span class="token punctuation">(</span>clusterName<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">setDatabaseWhitelist</span><span class="token punctuation">(</span><span class="token string">"petclinic"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">setTableWhitelist</span><span class="token punctuation">(</span><span class="token string">"petclinic.owners"</span><span class="token punctuation">,</span> <span class="token string">"petclinic.pets"</span><span class="token punctuation">,</span> <span class="token string">"petclinic.visits"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Use the source to read change events from MySQL into the pipeline:</p>
<pre><code class="hljs css language-java"><span class="token class-name">Pipeline</span> p <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">StreamStage</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">ChangeRecord</span><span class="token punctuation">></span></span> allRecords <span class="token operator">=</span> p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span>mysqlSource<span class="token punctuation">)</span>
                                        <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="keyword-extraction"></a><a href="#keyword-extraction" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Keyword extraction</h3>
<p>The next step in the pipeline is to extract the keywords from the visit
description. We will use Rapid Automatic Keyword Extraction (RAKE)
algorithm, the implementation we use was originally published on
<a href="https://github.com/Linguistic/rake">Github</a>. The implementation is not
important for the demonstration, you could use any other Java library,
call a 3rd party service, e.g. via <a href="/docs/how-tos/grpc">grpc</a> or use our
<a href="/docs/tutorials/python">python integration</a>.</p>
<pre><code class="hljs css language-java"><span class="token comment">// Create factory for keyword service</span>
<span class="token class-name">ServiceFactory</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">,</span> <span class="token class-name">Rake</span><span class="token punctuation">></span></span> keywordService <span class="token operator">=</span> <span class="token class-name">ServiceFactories</span><span class="token punctuation">.</span><span class="token function">sharedService</span><span class="token punctuation">(</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token class-name">Rake</span><span class="token punctuation">(</span><span class="token string">"en"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span>mysqlSource<span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">mapUsingService</span><span class="token punctuation">(</span>keywordService<span class="token punctuation">,</span> <span class="token class-name">PetClinicIndexJob</span><span class="token operator">::</span><span class="token function">enrichWithKeywords</span><span class="token punctuation">)</span>
</code></pre>
<p>The method <code>enrichWithKeywords</code> simply passes the description field from
the change record to the keyword extraction service and sets the results
into the keywords field of the Visit instance.</p>
<p>It is a common pattern to enrich an item in a pipeline with more
information.  Hazelcast Jet works with POJOs in the pipeline, so you
need to somehow compose the original item and the enriching information.
One option is to use tuples.  This works for a small number of fields.
Another option would be to use a domain-specific object holding all the
information - e.g. the <code>keywords</code> field.  If you are on Java 14 or
newer, you might want to give the <a href="https://openjdk.java.net/jeps/359">Records preview
feature</a> a try.</p>
<h3><a class="anchor" aria-hidden="true" id="joining"></a><a href="#joining" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Joining</h3>
<p>Change data capture sends changes to the database as individual records
(represented by
<a href="https://jet-start.sh/javadoc/4.2/com/hazelcast/jet/cdc/ChangeRecord.html">ChangeRecord</a>).
Each record represents a changed row in a database table. If a single
row is all that you need, you are good to go. You can see such example
in our <a href="/blog/2020/07/16/designing-evergreen-cache-cdc">Evergreen Cache blog
post</a>.  But having a
single row to work with is not always the case - often you need to
aggregate either multiple records from the same table or join records
from different tables into a single aggregate record.</p>
<p>In our case, we need to join 3 tables into a single document, which we
then index into Elasticsearch. To perform the joining we will use
<code>mapStateful</code> step. This can be performed either globally or partitioned
on a grouping key. If all your records share a common key it is always a
good idea to do the grouping by the key, because the mapping state is
then evenly distributed across all nodes and the mapping operation
parallelized.</p>
<p>Our visit record contains the pet ID but not the owner ID, in such case,
so we don’t have a single grouping key for all records. There are two
options:</p>
<ul>
<li><p>perform the stateful mapping globally, which has the advantage of
having a single state - the joining logic is simpler and the pipeline
more straightforward. The obvious disadvantage is that such a solution
is not scalable because the state may not fit onto a single member and
must be performed by a single thread;</p></li>
<li><p>create two separate mapping steps - one grouped on the owner ID and
the other on the pet ID. This is a trade-off between simplicity and
scalability.</p></li>
</ul>
<p>There are several observations which hold for both implementations:</p>
<ul>
<li><p>the mapping state must cover all data from the beginning, unless there
is a domain-specific rule that would allow eviction of old items;</p></li>
<li><p>the records might arrive in any order, even if there is a foreign key
between the records in the database, the order is not guaranteed, this
is a property of CDC.</p></li>
<li><p>once the object is emitted from the join step, it must not be
modified, otherwise the later stages might see it in inconsistent
state, causing issues which are hard to debug. We make defensive copies
to avoid this.</p></li>
</ul>
<p>Go to
<a href="https://github.com/hazelcast-demos/pet-clinic-index-job/blob/master/src/main/java/org/example/jet/petclinic/JoiningState.java#L11">Github</a>
to see the full source code.</p>
<h3><a class="anchor" aria-hidden="true" id="deleting-changes"></a><a href="#deleting-changes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Deleting changes</h3>
<p>The <code>ChangeRecord#operation()</code> method provides information about what
kind of operation was performed on the record. If you need to handle
deletions, you should use it. The Petclinic application doesn’t allow
delete operations, so we don’t handle those.</p>
<h3><a class="anchor" aria-hidden="true" id="elastic-sink"></a><a href="#elastic-sink" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Elastic sink</h3>
<p>The fourth key part of the pipeline is the Elastic sink. It takes a
document and writes it to Elasticsearch. You as the developer need to
provide information where the Elastic instance is running, what index to
write to and how to convert the <code>Document</code> into one of <code>IndexRequest</code>,
<code>UpdateRequest</code> or <code>DeleteRequest</code>. The Sink then takes care of batching
the requests and parallelizing for higher performance, retries in case
of network issues.</p>
<h3><a class="anchor" aria-hidden="true" id="the-pipeline"></a><a href="#the-pipeline" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Pipeline</h3>
<p>The final pipeline composes all the individual steps in a
straightforward way:</p>
<pre><code class="hljs css language-java"><span class="token class-name">Pipeline</span> p <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span>mysqlSource<span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">PetClinicIndexJob</span><span class="token operator">::</span><span class="token function">mapChangeRecordToPOJO</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setName</span><span class="token punctuation">(</span><span class="token string">"mapChangeRecordToPOJO"</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">mapUsingService</span><span class="token punctuation">(</span>keywordService<span class="token punctuation">,</span> <span class="token class-name">PetClinicIndexJob</span><span class="token operator">::</span><span class="token function">enrichWithKeywords</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setName</span><span class="token punctuation">(</span><span class="token string">"enrichWithKeywords"</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">mapStateful</span><span class="token punctuation">(</span><span class="token class-name">JoiningState</span><span class="token operator">::</span><span class="token keyword">new</span><span class="token punctuation">,</span> <span class="token class-name">JoiningState</span><span class="token operator">::</span><span class="token function">join</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setName</span><span class="token punctuation">(</span><span class="token string">"JoiningState::join"</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span>elasticSink<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Or visualized as a graph:</p>
<p><img src="/blog/assets/2020-10-06-global-join-step.png" alt="Pipeline with global mapping state"></p>
<p>For the pipeline with the two-step join see <a href="https://github.com/hazelcast-demos/pet-clinic-index-job/blob/two-joins/src/main/java/org/example/jet/petclinic/PetClinicIndexJob.java#L87">the source
code</a>
on Github. This is the graph visualisation of the pipeline:</p>
<p><img src="/blog/assets/2020-10-06-two-join-step.png" alt="Pipeline with 2 separate grouped join steps"></p>
<h2><a class="anchor" aria-hidden="true" id="testing-the-job"></a><a href="#testing-the-job" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Testing the job</h2>
<p>In order to test the job, we need to create a test database identical to
the Petclinic database.</p>
<p>We have the following options:</p>
<ul>
<li><p>Start the pet clinic application inside the same JVM - the Petclinic
is a Spring Boot application, running it in-process would be
relatively easy, but it represents a legacy application, which is
usually quite difficult to run in such way. Also, there is a high
probability of dependency clashes, which would make this difficult.</p></li>
<li><p>Start the pet clinic application in a Docker container - it is likely
that the application is not containerized, we would need to create
such an image only for the tests.</p></li>
<li><p>Create the database and data using SQL directly - reusing the SQL
scripts from the Petclinic application and running inserts via JDBC
seems the easiest way to do this so we will continue with this approach.</p></li>
</ul>
<p>Go to
<a href="https://github.com/hazelcast-demos/pet-clinic-index-job/blob/master/src/main/java/org/example/jet/petclinic/PetClinicIndexJob.java#L121">Github</a>
to see the full source code.</p>
<h2><a class="anchor" aria-hidden="true" id="running-the-job"></a><a href="#running-the-job" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Running the Job</h2>
<p>In order to run the indexing job, first checkout the
<a href="https://github.com/hazelcast-demos/pet-clinic-index-job/">pet-clinic-indexing-job</a>
repository</p>
<pre><code class="hljs css language-bash">git <span class="hljs-built_in">clone</span> https://github.com/hazelcast-demos/pet-clinic-index-job.git
</code></pre>
<p>Then build the JAR containing to job</p>
<pre><code class="hljs css language-bash"><span class="hljs-built_in">cd</span> pet-clinic-indexing-job
mvn package
</code></pre>
<p>And finally submit the job by running the following command:</p>
<pre><code class="hljs css language-bash">bin/jet submit \
path/to/pet-clinic-index-job/target/pet-clinic-index-job-1.0-SNAPSHOT-jar-with-dependencies.jar\
   --database-address localhost \
   --database-port 3306 \
   --database-user petclinic \
   --database-password petclinic \
   --elastic-host localhost:9200 \
   --elastic-index petclinic-index
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="petclinic-application-update"></a><a href="#petclinic-application-update" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Petclinic application update</h2>
<p>Now that we have the data in Elasticsearch index, we can update the
Petclinic application to use it for search.</p>
<p>There are several changes in the application, but the most important
changes are:</p>
<ul>
<li><p>created a search service to search for the data;</p></li>
<li><p>update the search endpoint to use the new search service.</p></li>
</ul>
<p>The following snippet shows the search method in the SearchService. It
uses the Elasticsearch client directly, but one could use Spring Data
Elasticsearch as well.</p>
<pre><code class="hljs css language-java"><span class="token keyword">public</span> <span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> <span class="token function">search</span><span class="token punctuation">(</span><span class="token class-name">String</span> query<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token class-name">SearchRequest</span> searchRequest <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SearchRequest</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span><span class="token punctuation">;</span>
  searchRequest<span class="token punctuation">.</span><span class="token function">source</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">fetchSource</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">query</span><span class="token punctuation">(</span><span class="token class-name">QueryBuilders</span><span class="token punctuation">.</span><span class="token function">wildcardQuery</span><span class="token punctuation">(</span>searchField<span class="token punctuation">,</span> query <span class="token operator">+</span> <span class="token string">"*"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">try</span> <span class="token punctuation">{</span>
     <span class="token class-name">SearchResponse</span> response <span class="token operator">=</span> client<span class="token punctuation">.</span><span class="token function">search</span><span class="token punctuation">(</span>searchRequest<span class="token punctuation">,</span> <span class="token class-name">RequestOptions</span><span class="token punctuation">.</span>DEFAULT<span class="token punctuation">)</span><span class="token punctuation">;</span>

     <span class="token class-name">SearchHits</span> hits <span class="token operator">=</span> response<span class="token punctuation">.</span><span class="token function">getHits</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token keyword">return</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span>hits<span class="token punctuation">.</span><span class="token function">getHits</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>hit <span class="token operator">-></span> <span class="token punctuation">(</span><span class="token class-name">Integer</span><span class="token punctuation">)</span> hit<span class="token punctuation">.</span><span class="token function">getSourceAsMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"ownerId"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
           <span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token function">toList</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
  <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
     <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">RuntimeException</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>The search endpoint will use the SearchService to search for the data.
After retrieving the results the Owner entities need to be loaded from
the database. This is not an issue as only a small subset of
best-matching documents is returned from Elastic and loaded by ID from
the database.</p>
<pre><code class="hljs css language-java"><span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> ownerIds <span class="token operator">=</span> searchService<span class="token punctuation">.</span><span class="token function">search</span><span class="token punctuation">(</span>searchForm<span class="token punctuation">.</span><span class="token function">getQuery</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// find owners by last name</span>
<span class="token class-name">Collection</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Owner</span><span class="token punctuation">></span></span> results <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>owners<span class="token punctuation">.</span><span class="token function">findByIds</span><span class="token punctuation">(</span>ownerIds<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>There are some more minor changes to the view and the controller, you
can see all the changes in <a href="https://github.com/spring-projects/hazelcast-demos/compare/main...elasticsearch">this
commit</a>.</p>
<p>Checkout the <code>elasticsearch</code> branch with the changes and restart the
application by running the Maven command again:</p>
<pre><code class="hljs css language-bash">./mvnw spring-boot:run -Dspring-boot.run.profiles=mysql
</code></pre>
<p>We can verify that searching for “George” returns 2 results, one found
in the first name, other in the name of a pet:</p>
<p><img src="/blog/assets/2020-10-06-search-george.png" alt="Search &quot;George&quot;"></p>
<p>Entering “rabies” should bring up a single result (the detail screen is
shown in that case) matching a keyword extracted from the description:</p>
<p><img src="/blog/assets/2020-10-06-search-rabbies.png" alt="Search &quot;rabbies&quot;"></p>
<h2><a class="anchor" aria-hidden="true" id="summary"></a><a href="#summary" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Summary</h2>
<p>We have shown how to stream changes using CDC, enrich the data,
correlate (join) the records with other records and finally store the
data into an Elasticsearch index, so an application can provide better
search functionality to the user.</p>
<p>This is mostly done independently of the original application and its
database, reducing the impact it has on the original legacy system.</p>
<p>If you would like to discuss this topic with us, drop by at <a href="https://hazelcastcommunity.slack.com/">our
Community Slack channel</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="sources"></a><a href="#sources" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Sources</h2>
<p><a href="https://github.com/hazelcast-demos/spring-petclinic">Spring Petclinic</a>
- fork with modifications for this post.</p>
<p><a href="https://github.com/hazelcast-demos/pet-clinic-index-job">Petclinic Indexing Job</a></p>
<p><a href="https://github.com/Linguistic/rake">Rake - rapid keyword extraction algorithm</a></p>
<p><em>If you enjoyed reading this post, check out Jet at
<a href="https://github.com/hazelcast/hazelcast-jet">GitHub</a> and give us a
star!</em></p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/09/18/cdc-meets-stream-processing">Change Data Capture meets Stream Processing</a></h1><p class="post-meta">September 18, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/bjozsef/" target="_blank" rel="noreferrer noopener">Bartók József</a></p><div class="authorPhoto"><a href="https://www.linkedin.com/in/bjozsef/" target="_blank" rel="noreferrer noopener"><img src="https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg" alt="Bartók József"/></a></div></div></header><article class="post-content"><div><span><h2><a class="anchor" aria-hidden="true" id="introduction"></a><a href="#introduction" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Introduction</h2>
<p><em>Change Data Capture</em> (CDC) refers to the process of <em>observing
changes made to a database</em> and extracting them in a form usable by
other systems, for the purposes of replication, analysis and many more.</p>
<p><em>Hazelcast Jet</em> is a distributed, lightweight stream processing
framework. It allows you to write modern Java code that focuses purely
on data transformation while it does all the heavy lifting of getting
the data flowing and computation running across a cluster of nodes. Jet
stores computational state in <a href="https://jet-start.sh/docs/api/data-structures">fault-tolerant, distributed in-memory
storage</a>, allowing
thousands of concurrent users granular and fast access to your data
without breaking a sweat.</p>
<p>While stream processing is a natural solution for providing insight into
many big-data workloads, it’s a relatively new evolution over its
predecessor - offline batch processing. Utilizing stream processing
effectively requires re-architecting existing systems to event-driven
architectures and introducing several new components. This process is
not always straightforward and also requires a shift in mindset.</p>
<p>In this context, the functionality provided by change data capture
technologies, for which Debezium is one of the, if not THE best
open-source alternative, is a godsend. To be able to ingest data from
relational databases, without affecting the applications that use them,
changes the game for streaming systems. It becomes possible to safely
extend old systems with all kinds of new functionality: real-time
analytics, complex event processing, anomaly &amp; fraud detection and so
on.</p>
<h2><a class="anchor" aria-hidden="true" id="integration"></a><a href="#integration" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Integration</h2>
<p>When we first considered integrating Debezium into Jet, the most
important decisions were centered around the fact that Debezium is
designed to be deployed via Apache <a href="https://kafka.apache.org/documentation/#connect">Kafka
Connect</a>, which then
takes care of <em>fault tolerance</em> and <em>scalability</em>. Fortunately, Jet is
fully capable of providing these crucial services. Also, Kafka Connect
is a good enough abstraction that we were able to mimic it for Debezium.</p>
<p>We are aware that Debezium also offers an <em>embedded mode</em> for
applications not interested in fault-tolerance guarantees such as
exactly-once processing and resilience, but since Jet does not have a
“dumbed down” version (even as full-blown is light enough to be
embedded), we quickly discarded this approach.</p>
<p>So, first, we added generic support for Kafka Connect sources to Jet,
which should be a valuable feature even outside the scope of CDC. Then
we used Debezium to build a Kafka Connect source for Jet. Well… “build”
might be overstating it. Debezium already is a Kafka Connect source. We
just had to make sure that Jet’s specific fault-tolerance mechanisms
will interact with it properly, through the Kafka Connect API.</p>
<h2><a class="anchor" aria-hidden="true" id="synergy"></a><a href="#synergy" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Synergy</h2>
<p>One immediate benefit that Jet offers to Debezium users is eliminating
the need for <em>external services</em>. No Zookeeper, no Kafka needed. When
using Debezium through Jet, the latter takes care of the whole lifecycle
and fault tolerance of all the components involved. The setup is greatly
simplified.</p>
<p>Then, obviously, there is the <em>stream processing capability</em>, because
that’s what Jet does. Not only do you get access to the data, but you
also have the toolbox to process it, extract whatever insights you need
from it.</p>
<p>In addition, Jet also aims to offer <em>further convenience</em> wrappers when
the Debezium source is being used. For example:</p>
<ul>
<li>builders for the most common configuration properties to make setting
up Debezium for some specific DB as simple as possible</li>
<li>standard Java interfaces to give structure to the complex Debezium
events</li>
<li>JSON parsing, including mapping to Objects, based on <a href="https://github.com/FasterXML/jackson-jr">Jackson
jr</a>, to simplify how parts
of - or even entire Debezium events can be interpreted</li>
</ul>
<p>For an example look at this sample from our <a href="https://jet-start.sh/docs/tutorials/cdc#6-define-jet-job">CDC
tutorial</a>. All
the code you would need to build an in-memory replica of your MySQL
database table would be something like:</p>
<pre><code class="hljs css language-java"><span class="token class-name">StreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">ChangeRecord</span><span class="token punctuation">></span></span> source <span class="token operator">=</span> <span class="token class-name">MySqlCdcSources</span><span class="token punctuation">.</span><span class="token function">mysql</span><span class="token punctuation">(</span><span class="token string">"source"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setDatabaseAddress</span><span class="token punctuation">(</span><span class="token string">"127.0.0.1"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setDatabasePort</span><span class="token punctuation">(</span><span class="token number">3306</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setDatabaseUser</span><span class="token punctuation">(</span><span class="token string">"debezium"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setDatabasePassword</span><span class="token punctuation">(</span><span class="token string">"dbz"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setClusterName</span><span class="token punctuation">(</span><span class="token string">"dbserver1"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setDatabaseWhitelist</span><span class="token punctuation">(</span><span class="token string">"inventory"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setTableWhitelist</span><span class="token punctuation">(</span><span class="token string">"inventory.customers"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">Pipeline</span> pipeline <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
pipeline<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span>source<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">CdcSinks</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token string">"customers"</span><span class="token punctuation">,</span>
                r <span class="token operator">-></span> r<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                r <span class="token operator">-></span> r<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toObject</span><span class="token punctuation">(</span><span class="token class-name">Customer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">JobConfig</span> cfg <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JobConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setName</span><span class="token punctuation">(</span><span class="token string">"mysql-monitor"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Jet</span><span class="token punctuation">.</span><span class="token function">bootstrappedInstance</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">newJob</span><span class="token punctuation">(</span>pipeline<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="architecture"></a><a href="#architecture" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Architecture</h2>
<p>I have stated above that when Debezium is integrated into Jet, the
latter takes on the role of service-provider as far as fault tolerance
and scalability are concerned.</p>
<p>Jet doesn't delegate its cluster management and fault tolerance concerns
to an outside system like ZooKeeper. It reuses the groundwork
implemented for Hazelcast IMDG: cluster management and the IMap, and
adds its own implementation of Chandy-Lamport distributed snapshots. If
a cluster member fails, Jet will restart the job on the remaining
members, restore the state of processing from the last snapshot, and
then seamlessly continue from that point. For further details, consult
our <a href="https://jet-start.sh/docs/next/architecture/fault-tolerance">documentation on the
topic</a>.</p>
<p>Extending this functionality umbrella to cover Debezium has been
surprisingly simple. All we had to do was to add Debezium’s
source offset to Jet’s snapshots. This way, whenever Jet needs to
execute a recovery, it passes the recovered offset to Debezium,
which in turn resumes the data flow from that offset.</p>
<p>One other thing we did and might be worth mentioning is that the Jet
integration also makes use of Debezium’s <a href="https://debezium.io/documentation/reference/1.2/configuration/event-flattening.html">new record state
extraction</a>
SMT (Simple Message Transformation), for the purpose of message
structure simplification. With this transformation in effect, only the
&quot;after&quot; structure of the Debezium event envelope is processed by Jet.
However, whether this is a good idea or not, only time will tell. I
personally think that if and when we will start covering schema changes
more, we might end up re-enabling the full Debezium event content.</p>
<h2><a class="anchor" aria-hidden="true" id="examples"></a><a href="#examples" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Examples</h2>
<p>The simplest example of using the Jet-Debezium integration would be our
<a href="https://jet-start.sh/docs/next/tutorials/cdc">CDC tutorial</a> that I’ve
already mentioned above. A more involved one can be seen in my
colleague’s, Nicolas Fränkel’s <a href="https://jet-start.sh/blog/2020/07/16/designing-evergreen-cache-cdc">blog
post</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="license"></a><a href="#license" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>License</h2>
<p>The Jet - Debezium integration is currently provided under the <a href="https://www.apache.org/licenses/LICENSE-2.0.txt">Apache
License, Version 2</a>,
just like Debezium and most of Jet (full details <a href="https://jet-start.sh/license">here</a>),
so making full usage of the combination of the two should have no
impediments in your own projects.</p>
<h2><a class="anchor" aria-hidden="true" id="looking-ahead"></a><a href="#looking-ahead" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Looking ahead</h2>
<p>At the moment of writing the Jet-Debezium integration is fully finished
only for MySQL and Postgres databases and has been <a href="https://jet-start.sh/blog/2020/07/14/jet-42-is-released">released in version
4.2</a> of Jet.
Further work on covering more connectors and extending current
ones (for example by adding handling for database schema changes),
has not yet been scheduled.</p>
<p>The functionality provided by Debezium, the ability to allow modern
processing of legacy data is a great fit to Jet’s ability to carry out
that processing efficiently. The combination of the two has the
potential to become much more than the sum of their parts. I very much
look forward to finding out what this integration can lead to. Stay
tuned!</p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/08/05/gc-tuning-for-jet">Sub-10 ms Latency in Java: Concurrent GC with Green Threads</a></h1><p class="post-meta">August 5, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener">Marko Topolnik</a></p><div class="authorPhoto"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener"><img src="https://i.imgur.com/xuavzce.jpg" alt="Marko Topolnik"/></a></div></div></header><article class="post-content"><div><span><p>This post is a part of a series:</p>
<ul>
<li><a href="/blog/2020/06/09/jdk-gc-benchmarks-part1">Part 1 (Intro and high-throughput streaming
benchmark)</a></li>
<li><a href="/blog/2020/06/09/jdk-gc-benchmarks-part2">Part 2 (batch workload benchmark)</a></li>
<li><a href="/blog/2020/06/23/jdk-gc-benchmarks-rematch">Part 3 (low-latency benchmark)</a></li>
<li>Part 4 (you are here)</li>
<li><a href="/blog/2021/03/17/billion-events-per-second">Part 5 (billion events per second)</a></li>
</ul>
<p>In Part 3 we showed that a modern JVM running live stream aggregation
can achieve a 99.99% latency lower than 10 milliseconds. The focus of
that post was comparing the different GC options available for the JVM.
In order to maintain a level playing field, we kept to the default
settings as much possible.</p>
<p>In this round we wanted to look at the same problem from the opposite
angle: what can we do to help Hazelcast Jet achieve the best performance
available on a JVM? How much throughput can we get while staying within
the tight 10 ms bound for 99.99th percentile latency? We found our
opportunity in a distinct design feature of Jet: the Cooperative Thread
Pool.</p>
<h2><a class="anchor" aria-hidden="true" id="native-threads-with-concurrent-gc"></a><a href="#native-threads-with-concurrent-gc" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Native Threads with Concurrent GC</h2>
<p>Let's go through an example with a streaming job running on a four-core
machine. In a typical execution engine design, every task (roughly
corresponding to a <a href="/docs/concepts/dag">DAG vertex</a>) gets its own thread
to execute it:</p>
<p><img src="/blog/assets/2020-08-05-dag1.svg" alt="Native Multithreading"></p>
<p>There are eight threads and the OS is in charge of deciding how to
schedule them to run on the four available cores. The application has
no direct control over this and the cost of switching from one thread
to another on the same CPU core is around 2-10 microseconds.</p>
<p>This is how it will look when we add a concurrent GC thread into the
picture:</p>
<p><img src="/blog/assets/2020-08-05-dag1-with-gc.svg" alt="Native Multithreading with a GC Thread"></p>
<p>There's one more thread now, the concurrent GC thread, and it's
additionally interfering with the computation pipeline.</p>
<h2><a class="anchor" aria-hidden="true" id="green-threads-with-concurrent-gc"></a><a href="#green-threads-with-concurrent-gc" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Green Threads with Concurrent GC</h2>
<p>In Hazelcast Jet, tasks are designed to be
<a href="/docs/architecture/execution-engine">cooperative</a>: every time you give
it a bunch of data to process, the task will run for a short while and
return. It doesn't have to process all the data in one go and the
execution engine will give it control again later with all the
still-pending data. This basic design is also present in the concepts of
<em>green threads</em> and <em>coroutines</em>. In Hazelcast Jet we call them
<a href="/docs/architecture/execution-engine#tasklet"><em>tasklets</em></a>.</p>
<p>This design allows Jet to always use the same, fixed-size thread pool no
matter how many concurrent tasks it instantiates to run a data pipeline.
So, on the example of a four-core machine, it looks like this:</p>
<p><img src="/blog/assets/2020-08-05-dag2.svg" alt="Cooperative Multithreading"></p>
<p>By default, Jet creates as many threads for itself as there are
available CPU cores, and inside each thread there are many tasklets.
Switching from one tasklet to the next is extremely cheap — it
boils down to one tasklet returning from its <code>call()</code> method, the
top-level loop taking the next tasklet from a list, and invoking its
<code>call()</code> method. If you wonder at this point what happens to blocking IO
calls, for example connecting to a JDBC data source, Jet does support a
backdoor where it creates a dedicated thread for such a tasklet. Threads
that block for IO aren't CPU-bound and usually their interference is
quite low, but in a low-latency applications you should avoid depending
on blocking APIs.</p>
<p>Now comes another advantage of this design: if we know there will also
be a concurrent GC thread, we can configure Jet to use one thread less:</p>
<p><img src="/blog/assets/2020-08-05-dag2-with-gc.svg" alt="Cooperative Multithreading with a GC Thread"></p>
<p>There are still as many threads as CPU cores and the OS doesn't have to
do any context switching. We did give up one entire CPU core just for
GC, reducing the CPU capacity available to Jet, but we allowed
background GC to run truly concurrently to the Jet tasks. In low-latency
scenarios, <em>the application doesn't need 100% CPU, but it needs its
share of the CPU 100% of the time.</em></p>
<p>We went to see if this setup really makes the difference we hope for,
and found it indeed had a drammatic impact on the latency with both
garbage collectors we tested (G1 and ZGC). The most important outcome
was that we were now able to push G1 below the 10 ms line. Since G1 is
stable across a wide range of throughputs, we immediately got it to
perform within 10 ms at <em>double the throughput than in the previous
round</em>.</p>
<h2><a class="anchor" aria-hidden="true" id="the-setup"></a><a href="#the-setup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Setup</h2>
<p>Based on the expectations set by the previous benchmark, we focused on
the ZGC and G1 collectors and the latest pre-release of Java 15. Our
setup stayed the same for the most part; we refreshed the code a bit and
now use the released version 4.2 of Hazelcast Jet with OpenJDK 15 EA33.</p>
<p>We also implemented a parallelized event source simulator. Its higher
throughput capacity allows it to catch up faster after a hiccup, helping
to reduce the latency a bit more. The processing pipeline itself is
identical to the previous round,
<a href="https://github.com/mtopolnik/jet-gc-benchmark/blob/round-3/src/main/java/org/example/StreamingRound3.java">here</a>
is the complete source code.</p>
<p>We determined how many threads the given GC uses, set the size of the
Jet thread pool to 16 (=
<a href="https://aws.amazon.com/ec2/instance-types/c5/">c5.4xlarge</a> vCPU count)
minus that value and then did some trial-and-error runs to find the
optimum. G1 uses 3 threads, so we gave Jet 13. ZGC uses just 2 threads,
but we found Jet to perform a bit better with 13 instead of the
theoretical 14 threads, so we used that. We also experimented with
changing the GC's automatic choice for the thread count, but didn't find
a setting that would beat the default.</p>
<p>Additionally, with G1 we saw that in certain cases, even with
<code>MaxGCPauseMillis=5</code> (same as in the previous post), the size of the new
generation would grow large enough for Minor GC pauses to impact
latency. Therefore we added <code>MaxNewSize</code> with one of <code>100m</code>, <code>150m</code> and
<code>200m</code>, depending on the chosen throughput. This was also determined
through trial and error, the results seemed to be the best when a minor
GC was occurring about 10-20 times per second.</p>
<p>Summarizing, these are the changes we made with respect to the setup in
the previous post:</p>
<ol>
<li>Reduced Jet's cooperative thread pool size</li>
<li>Parallel event source where previously it was single-threaded</li>
<li>Used the <code>MaxNewSize</code> JVM parameter for G1</li>
<li>Updated Hazelcast Jet and JDK versions</li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="the-results"></a><a href="#the-results" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Results</h2>
<p>Comparing ZGC's results below with those in the <a href="/blog/2020/06/23/jdk-gc-benchmarks-rematch#a-sneak-peek-into-upcoming-versions">previous
round</a>,
we can see the latency stayed about the same where it was already good,
but the range of throughputs got extended from 8 to 10 M items/second,
a solid 25% improvement.</p>
<p>The effect on G1 is sort of dual to the above: while the G1 already had
great throughput but fell just short of making it below the 10 ms line,
in this round its latency improved across the board, up to 40% at
places. The best news: <em>the maximum throughput at which a single
Hazelcast Jet node maintains 99.99% latency within 10 ms now lies at 20
million items per second</em>, a 250% boost!</p>
<p><img src="/blog/assets/2020-08-05-latency-1m.png" alt="Latency on c5.4xlarge, 1 M Events per Second"></p>
<h2><a class="anchor" aria-hidden="true" id="upgrading-to-10-m-input-events-per-second"></a><a href="#upgrading-to-10-m-input-events-per-second" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Upgrading to 10 M Input Events per Second</h2>
<p>Encouraged by this strong result, we dreamed up a scenario like this: we
have 100,000 sensors, each producing a 100 Hz measurement stream. Can a
single-node Hazelcast Jet handle this load and produce, say, the time
integral of the measured quantity from each sensor over a 1-second
window, at a 10 ms latency? This implies an order-of-magnitude leap in
the event rate, from 1 M to 10 M events per second, but also a reduction
in window length by the same factor, from ten seconds to one.</p>
<p>Nominally, the scenario results in the same combined input+output
throughput as well as about the same size of state that we already saw
work: 20 M items/second and 10 M stored map entries. It's the maximum
point where G1 was still inside 10 ms, but even at 25 M items/second it
still had pretty low latency. However, for reasons we haven't yet
identified, the input rate seems to have a stronger impact on GC, so
when we traded output for input, it turned out that G1 was nowhere near
handling it.</p>
<p>But, since we picked the c5.4xlarge instance type as a medium-level
option, for this &quot;elite scenario&quot; we considered the top-shelf EC2 box as
well: c5.metal. It commands 96 vCPUs and has some scary amount of RAM
that we won't need. On this hardware G1 decides to take 16 threads for
itself, so the natural choice would be 80 threads for Jet. However,
through trial and error we chased down the real optimum, which turned
out to be 64 threads. Here is what we got:</p>
<p><img src="/blog/assets/2020-08-05-latency-10m.png" alt="Latency on c5.metal, 10 M Events per Second"></p>
<p>G1 comfortably makes it to the 20 M mark and then goes on all the way to
40 M items per second, gracefully degrading and reaching 60 M with just
12 ms. Beyond this point it was Jet who ran out of steam. The Jet
pipeline running at full speed just couldn't max out the G1! We repeated
the test with more threads given to Jet, 78, but that didn't make a
difference.</p>
<p><em>If you enjoyed reading this post, check out Jet at
<a href="https://github.com/hazelcast/hazelcast-jet">GitHub</a> and give us a
star!</em></p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/07/16/designing-evergreen-cache-cdc">Designing an Evergreen Cache with Change Data Capture</a></h1><p class="post-meta">July 16, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/nicolas_frankel" target="_blank" rel="noreferrer noopener">Nicolas Frankel</a></p><div class="authorPhoto"><a href="https://twitter.com/nicolas_frankel" target="_blank" rel="noreferrer noopener"><img src="https://3l0wd94f0qdd10om8642z9se-wpengine.netdna-ssl.com/wp-content/uploads/2019/12/nicolas-frankel-170x170.jpg" alt="Nicolas Frankel"/></a></div></div></header><article class="post-content"><div><span><p>It has been said that there are two things hard in software development:
naming things and cache invalidation (while some add off-by-one errors
to the mix).
I believe that keeping the cache in sync with the source of truth might
count as a third one.
In this post, I'd like to tackle this issue, describe the ideal
situation -
1 cache, 1 datastore - describe the problem of having multiple components
that can write to the datastore, list all possible solutions, and
describe one elegant solution based on Change Data Capture and Jet.</p>
<h2><a class="anchor" aria-hidden="true" id="the-ideal-design"></a><a href="#the-ideal-design" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The ideal design</h2>
<p>In a system, to improve performance, one of the first short-term
measures is to set up a cache.
It's a tradeoff between getting the data faster at the cost of the data
being not that fresh: one loads the data in-memory close to the
consumer, and presto, one gets an instant performance boost. In regard
to a database, this is akin to the following:</p>
<p><img src="/blog/assets/2020-07-16-starting-architecture.svg" alt="Starting architecture"></p>
<p>In this read-through design, when the app requires an item, the cache
first checks whether it has it.
If yes, it returns it.
If not, it fetches it from the underlying Relational Database Management
System, stores it, and returns it.
For a write, it stores it, and also calls the RDBMS to store it.</p>
<p>Note that using a cache-aside design instead of read-through would have
the same issue.
The only difference would be the fact that the app would be responsible
for the fetching/storing logic instead of the cache.</p>
<p>The RDBMS is the sole source of truth - as it should be. Since the cache
intercepts write statements to the RDBMS, it's a mirror of the data.</p>
<h2><a class="anchor" aria-hidden="true" id="handling-third-party-database-updates"></a><a href="#handling-third-party-database-updates" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Handling third-party database updates</h2>
<p>This design works as expected as long as the database doesn't receive
updates from another source:</p>
<p><img src="/blog/assets/2020-07-16-updating-database-bypassing-cache.svg" alt="Updating the database while bypassing the
cache"></p>
<p>Now, the RDBMS is still the source of truth, but the cache is not aware
of changes made by other components.
Hence, it might (will) return data that it has stored, but that is stale
compared to what is the source of truth in the RDBMS.</p>
<p>There are multiple ways to cope with this issue.</p>
<h3><a class="anchor" aria-hidden="true" id="cache-invalidation"></a><a href="#cache-invalidation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Cache invalidation</h3>
<p>Since the cache only queries the RDBMS if it doesn't store the requested
item, let's remove items after a specific time.
This is a built-in feature in enterprise-grade caches such as Hazelcast
IMDG and it is known as the Time-To-Live.
When an item is stored, a TTL can be attached to it.
After that time has elapsed, the item is removed from the cache and it
will be fetched from the RDBMS again if needed.</p>
<p>This approach has a couple of downsides:</p>
<ol>
<li><p>If an item is not updated in the RDBMS, but is evicted from the
cache, then there's an extra query from the cache to the RDBMS when
it's needed by the app. This is a net loss of resources.</p></li>
<li><p>If an item is updated in the RDBMS, but its TTL has not been reached
yet, then the cache will return the stale data. This defeats the
purpose.</p></li>
</ol>
<p>With longer TTL, we avoid unnecessary round trips but return more stale
data.
With shorter TTL, we waste resources with lesser chances of stale data.</p>
<h3><a class="anchor" aria-hidden="true" id="polling-the-rdbms"></a><a href="#polling-the-rdbms" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Polling the RDBMS</h3>
<p>Because the TTL doesn't seem to be the right approach, we could devise a
dedicated component that watches the RDBMS by regularly sending queries
to it and updating the cache accordingly.</p>
<p>Unfortunately, this strategy incurs the same issues as cache
invalidation:
the more frequent the queries, the more chances to catch changes, but
the more resources are wasted.
Worse, this also will put extra load on the RDBMS.</p>
<h3><a class="anchor" aria-hidden="true" id="rdbms-triggers"></a><a href="#rdbms-triggers" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>RDBMS triggers</h3>
<p>A common downside of the above approaches is the way they both poll the
database.
Polling happens with a specific frequency, while writes don't follow any
regular periodicity.
Thus, it's not possible to make the two match.</p>
<p>Instead of polling, it would make much more sense to be event-driven:</p>
<ol>
<li><p>if no writes happen, there's no need to update the cache</p></li>
<li><p>if a write happens, then the relevant cache item should be updated
accordingly</p></li>
</ol>
<p>In RDBMS this event-driven approach is implemented via <em>triggers</em>.
Triggers are dedicated stored procedures that are launched in response
to specific events, such as an <code>INSERT</code> or an <code>UPDATE</code>.</p>
<p>That works pretty well when the acted-upon object is inside the database,
e.g. &quot;when a record of table A is updated, then add a record to table
B&quot;.
For our use case where the acted-upon object is the cache which sits
outside the database, it's not as simple.
For example, MySQL allows you to <a href="https://dev.mysql.com/doc/refman/8.0/en/faqs-triggers.html#faq-mysql-can-triggers-udf">make an external system call from a
trigger</a>.
However, this approach is very implementation-dependent and makes the
overall design of the system much more fragile.
Also, only some RDBMS implement triggers. Even if they do, there's no
standard implementation.</p>
<h2><a class="anchor" aria-hidden="true" id="change-data-capture"></a><a href="#change-data-capture" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Change Data Capture</h2>
<p>Wikipedia defines Change Data Capture (or CDC) as:</p>
<blockquote>
<p>[...] a set of software design patterns used to determine and track
the data that has changed so that action can be taken using the
changed data.</p>
<p>CDC is an approach to data integration that is based on the
identification, capture and delivery of the changes made to enterprise
data sources.</p>
</blockquote>
<p>In practice, CDC is a tool that allows to transform standard write
queries into events.
It implements it by &quot;turning the database inside-out&quot; (quote from Martin
Kleppmann).
This definition is because a database keeps a record of all changes in
an implementation-dependent append-only log.
Regularly, it uses it to manage its state. Some RDBMS also have other
usage, e.g. MySQL uses the log for replication across nodes.</p>
<p>For example, here's a sample for MySQL binlog:</p>
<pre><code class="hljs css language-text">### UPDATE `test`.`t`
### WHERE
###   @1=1 /* INT meta=0 nullable=0 is_null=0 */
###   @2='apple' /* VARSTRING(20) meta=20 nullable=0 is_null=0 */
###   @3=NULL /* VARSTRING(20) meta=0 nullable=1 is_null=1 */
### SET
###   @1=1 /* INT meta=0 nullable=0 is_null=0 */
###   @2='pear' /* VARSTRING(20) meta=20 nullable=0 is_null=0 */
###   @3='2009:01:01' /* DATE meta=0 nullable=1 is_null=0 */
# at 569
#150112 21:40:14 server id 1  end_log_pos 617 CRC32 0xf134ad89
#Table_map: `test`.`t` mapped to number 251
# at 617
#150112 21:40:14 server id 1  end_log_pos 665 CRC32 0x87047106
#Delete_rows: table id 251 flags: STMT_END_F
</code></pre>
<p>A CDC component connects to this immutable log to extract change events.</p>
<p>One can view CDC as the opposite of Event Sourcing:
the latter captures state by aggregating events, while the former
extracts events &quot;from the state&quot;.</p>
<h2><a class="anchor" aria-hidden="true" id="debezium"></a><a href="#debezium" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Debezium</h2>
<p>CDC is quite recent and hasn't had time to mature.
As such, there's no universal standard, but specific tools.
In this section, we are going to have a look at
<a href="https://debezium.io/">Debezium</a>.
Debezium is an Open Source set of services for CDC provided by Red Hat.</p>
<p>Debezium is an umbrella term covering several components:</p>
<ol>
<li><p>Debezium Connectors are specific bridges that read the append-only
proprietary log for each supported database. For example, there’s a
connector for MySQL, one for MongoDB, one for PostgreSQL, etc.</p></li>
<li><p>Each connector is also a Kafka Connect Source Connector:
this allows to easily output CDC events to one’s Kafka cluster</p></li>
<li><p>Finally, the Debezium Engine is a JAR that allows Debezium to be
embedded in one’s applications. Note that even in that case, Debezium
produces Kafka Connect-specific content, which then needs to be
handled and transformed in one’s application.</p></li>
</ol>
<p>While Kafka is a great technology and probably also quite widespread
nowadays, data in Kafka needs to be persisted to disk.
The benefit of persistence is that data survive even in the event of the
cluster going down.
The tradeoff, however, is that the access time of disk-persisted data is
one (or 2) orders of magnitude slower than the access time of in-memory
data, depending on the underlying disk technology.</p>
<h2><a class="anchor" aria-hidden="true" id="hazelcast-jet"></a><a href="#hazelcast-jet" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hazelcast Jet</h2>
<p><a href="https://jet-start.sh/">Hazelcast Jet</a> is a distributed stream
processing framework built on Hazelcast and combines a cache with
fault-tolerant data processing.
It has sources and sinks to integrate with various file, messaging and
database systems (such as Amazon S3, Kafka, message brokers and
relational databases).</p>
<p>Jet also provides a Debezium module where it can process change events
directly from the database and write them to its distributed key-value
store.
This avoids having to write the intermediate messages to Kafka and then
read again to be written to a separate cache.</p>
<h2><a class="anchor" aria-hidden="true" id="putting-it-all-together"></a><a href="#putting-it-all-together" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Putting it all together</h2>
<p>It’s (finally!) time to assemble all the previous bits together.
Here are the components and their responsibilities:</p>
<ol>
<li><p>A MySQL database instance is where the data is stored.
It’s accessed in read-only mode by the cache, and in write-only mode
by some external component</p></li>
<li><p>A Jet instance reads events from MySQL through the Debezium connector,
transforms them into cache-compatible key-value pairs, and updates
the cache accordingly. Note that while Jet pipelines provide
filtering capabilities, it’s also possible to filter items in the CDC
connector to optimize the load of the pipeline</p></li>
<li><p>The app uses the cache, which is always up-to-date with the database,
give or take the time it takes for the above to execute</p></li>
</ol>
<p><img src="/blog/assets/2020-07-16-architecture-with-cdc.svg" alt="Final architecture with
CDC"></p>
<p>Note that this architecture assumes one starts from a legacy state with
an existing app that uses caching, where a new component that could
update the database was set up later on.</p>
<p>If one starts from scratch, it’s possible to simplify the above diagram
(and associated code) as Jet embeds its own Hazelcast instance.
In that case instead of Jet being a client of a third-party Hazelcast
instance, Jet is the one to configure and start the instance.
Obviously, it also can then get/put data.</p>
<h2><a class="anchor" aria-hidden="true" id="talk-is-cheap-show-me-the-code"></a><a href="#talk-is-cheap-show-me-the-code" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Talk is cheap, show me the code</h2>
<p>Sources for this post are available <a href="https://github.com/hazelcast-demos/evergreen-cache">on
GitHub</a>.</p>
<p>The repository is made of the following modules:</p>
<ul>
<li><p><code>app</code> is a Spring Boot application using Spring Data JDBC to access a
MySQL database. It abstracts away Hazelcast by using a Spring Cache
layer</p></li>
<li><p><code>update</code> is a Spring Shell application.
It allows to update the data inside the database, with the cache none
the wiser</p></li>
<li><p><code>pipeline</code> is the Jet pipeline that listens to CDC events and updates
the cache when data is updated</p></li>
</ul>
<p>The pipeline definition is quite straightforward:</p>
<pre><code class="hljs css language-java">pipeline<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span>source<span class="token punctuation">)</span>                                       <span class="token comment">//1</span>
        <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>r <span class="token operator">-></span> <span class="token punctuation">{</span>
            <span class="token class-name">Person</span> person <span class="token operator">=</span> r<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toObject</span><span class="token punctuation">(</span><span class="token class-name">Person</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">//2</span>
            <span class="token keyword">return</span> <span class="token class-name">Util</span><span class="token punctuation">.</span><span class="token function">entry</span><span class="token punctuation">(</span>person<span class="token punctuation">.</span>id<span class="token punctuation">,</span> person<span class="token punctuation">)</span><span class="token punctuation">;</span>               <span class="token comment">//3</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">remoteMap</span><span class="token punctuation">(</span>                               <span class="token comment">//4</span>
                <span class="token string">"entities"</span><span class="token punctuation">,</span>                                     <span class="token comment">//5</span>
                <span class="token keyword">new</span> <span class="token class-name">CustomClientConfig</span><span class="token punctuation">(</span>env<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"CACHE_HOST"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment">//6</span>
        <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<ol>
<li><p>Get a stream of Jet <code>ChangeRecord</code></p></li>
<li><p>Convert <code>ChangeRecord</code> to a regular <code>Person</code> POJO</p></li>
<li><p>Wrap <code>Person</code> objects into <code>Map.Entry</code>s keyed by ID</p></li>
<li><p>Create the sink to write to, a remote map</p></li>
<li><p>Name of the remote map</p></li>
<li><p>Client configuration so it can connect to the right host, cluster
and instance</p></li>
</ol>
<pre><code class="hljs css language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomClientConfig</span> <span class="token keyword">extends</span> <span class="token class-name">ClientConfig</span> <span class="token punctuation">{</span>

  <span class="token keyword">public</span> <span class="token class-name">CustomClientConfig</span><span class="token punctuation">(</span><span class="token class-name">String</span> cacheHost<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token function">getNetworkConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">addAddress</span><span class="token punctuation">(</span>cacheHost <span class="token operator">!=</span> <span class="token keyword">null</span> <span class="token operator">?</span> cacheHost <span class="token operator">:</span> <span class="token string">"localhost"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>To try the demo, a local Docker <em>daemon</em> must be running.</p>
<ol>
<li><p>To create the necessary Docker images, at the root of the project,
run the build:</p>
<pre><code class="hljs css language-bash">mvn compile
</code></pre></li>
<li><p>At the root of the repo, run the compose file.
This will start a MySQL instance, the app, the Jet pipeline job, as
well as Hazelcast Management Center to get additional insight into
the cluster state</p>
<pre><code class="hljs css language-bash">docker-compose up
</code></pre></li>
<li><p>Open a browser at <a href="http://localhost:8080/">http://localhost:8080/</a></p></li>
<li><p>Refresh the browser, and check the logs: there should be no
interaction with the database, only with the cache</p></li>
<li><p>In the <code>update</code> module, set the database user and password and then
execute the Maven Spring Boot plugin:</p>
<pre><code class="hljs css language-bash"><span class="hljs-built_in">export</span> SPRING_DATASOURCE_USERNAME=root
<span class="hljs-built_in">export</span> SPRING_DATASOURCE_PASSWORD=root
mvn spring-boot:run
</code></pre>
<p>This will open an interactive shell to execute specific commands.
The update command requires two arguments, the primary key of the
<code>Person</code> entity to update, and the new value for the <code>firstName</code> column.
The following command will update the <code>firstName</code> value of the
entity with PK <code>1</code> with value <code>&quot;Foo&quot;</code></p>
<pre><code class="hljs css language-bash">update 1 Foo
</code></pre></li>
<li><p>Refresh the browser again. The cache has been updated, the
application doesn’t access the database, and still the value <code>Foo</code>
should be shown for entity with PK <code>1</code></p></li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="conclusion"></a><a href="#conclusion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conclusion</h2>
<p>Caching is easy if the cache is the only component that writes to the
database.
As soon as other components update the database, no traditional strategy
to keep the data of the database and the cache in sync is satisfying.</p>
<p>The Hazelcast Jet streaming engine, using Debezium under the hood, is
able to leverage Change Data Capture over traditional RDBMS to achieve
an evergreen cache in a simple way.</p>
<h2><a class="anchor" aria-hidden="true" id="references"></a><a href="#references" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>References</h2>
<ul>
<li><p><a href="https://jet-start.sh/docs/get-started/intro">Introduction to Jet</a></p></li>
<li><p><a href="https://jet-start.sh/docs/tutorials/cdc">Change Data Capture from MySQL</a></p></li>
<li><p><a href="https://debezium.io/blog/2020/02/10/event-sourcing-vs-cdc/">Event Sourcing vs. Change Data
Capture</a></p></li>
<li><p><a href="https://www.percona.com/blog/2015/01/20/identifying-useful-information-mysql-row-based-binary-logs/">Identifying useful info from MySQL row-based binary
logs</a></p></li>
<li><p><a href="https://github.com/hazelcast-demos/evergreen-cache">Demo source code</a></p></li>
</ul>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/07/14/jet-42-is-released">Jet 4.2 is Released</a></h1><p class="post-meta">July 14, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="http://twitter.com/cgencer" target="_blank" rel="noreferrer noopener">Can Gencer</a></p><div class="authorPhoto"><a href="http://twitter.com/cgencer" target="_blank" rel="noreferrer noopener"><img src="https://pbs.twimg.com/profile_images/1187734846749196288/elqWdrPj_400x400.jpg" alt="Can Gencer"/></a></div></div></header><article class="post-content"><div><span><p>Jet 4.2 is finally here! Here's an overview of what's new:</p>
<h2><a class="anchor" aria-hidden="true" id="change-data-capture-support-for-mysql-and-postgresql"></a><a href="#change-data-capture-support-for-mysql-and-postgresql" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Change Data Capture Support for MySQL and PostgreSQL</h2>
<p>Previously, Jet has had support for <a href="https://debezium.io/">Debezium</a> as
a contrib package. We're happy to announce that we've made several
improvements to this package and decided to make this a part of our main
release.</p>
<p>Debezium was developed initially as a Kafka Connect module, which can
read the snapshot and changes of relational databases such as MySQL and
PostgreSQL. Jet's Debezium integration removes the Kafka dependency
completely, and you can work with the stream of changes directly using
the full power of the Jet API.</p>
<p>Along with this change, we've created a new high-level API which makes
it easier to work directly with change stream records. For example, to
observe changes from MySQL, all you need to do do is:</p>
<pre><code class="hljs css language-java">pipeline<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span>
    <span class="token class-name">MySqlCdcSources</span><span class="token punctuation">.</span><span class="token function">mysql</span><span class="token punctuation">(</span><span class="token string">"customers"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setDatabaseAddress</span><span class="token punctuation">(</span><span class="token string">"127.0.0.1"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setDatabasePort</span><span class="token punctuation">(</span><span class="token number">3306</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setDatabaseUser</span><span class="token punctuation">(</span><span class="token string">"debezium"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setDatabasePassword</span><span class="token punctuation">(</span><span class="token string">"dbz"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setClusterName</span><span class="token punctuation">(</span><span class="token string">"dbserver1"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setDatabaseWhitelist</span><span class="token punctuation">(</span><span class="token string">"inventory"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">setTableWhitelist</span><span class="token punctuation">(</span><span class="token string">"inventory.customers"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">withNativeTimestamps</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">logger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>You can also combine this feature with Jet's
<a href="/docs/api/data-structures">in-memory-storage</a> allowing you to build an
in-memory replica of the database in just a few lines of code. The
example below will hydrate the distributed map <code>customers</code> with the
records from the database table with the same name:</p>
<pre><code class="hljs css language-java"><span class="token class-name">StreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">ChangeRecord</span><span class="token punctuation">></span></span> source <span class="token operator">=</span> <span class="token class-name">MySqlCdcSources</span><span class="token punctuation">.</span><span class="token function">mysql</span><span class="token punctuation">(</span><span class="token string">"source"</span><span class="token punctuation">)</span>
   <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token punctuation">.</span><span class="token function">setTableWhitelist</span><span class="token punctuation">(</span><span class="token string">"inventory.customers"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

pipeline<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span>source<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">peek</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">CdcSinks</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token string">"customers"</span><span class="token punctuation">,</span>
                r <span class="token operator">-></span> r<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                r <span class="token operator">-></span> r<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toObject</span><span class="token punctuation">(</span><span class="token class-name">Customer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>For a more in-depth example of this feature, see the <a href="/docs/tutorials/cdc">CDC
Tutorials</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="elasticsearch-connectors"></a><a href="#elasticsearch-connectors" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>ElasticSearch Connectors</h2>
<p>We've also had ElasticSearch (5, 6, 7) connectors available as contrib
modules and happy to announce that they have also been through several
rounds of improvements and merged into the main release. A summary is
below:</p>
<ul>
<li>Support for slicing reads: Jet can use the slicing feature of
ElasticSearch to read data in parallel.</li>
<li>Collocated read and write: You can make use of collocated reading from
ElasticSearch by placing Jet on the same nodes as your ElasticSearch
cluster - this will significantly improve the speed of querying and
ingestion.</li>
<li>Improved the retry mechanism for writes: As Jet can be used to write
to ElasticSearch as part of a streaming job, we've improved the retry
mechanism so that transient ES cluster failures can be retries.</li>
</ul>
<p>The ElasticSearch source and sink can be used with a simple API with the
example given below:</p>
<pre><code class="hljs css language-java"><span class="token class-name">BatchSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> elasticSource <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ElasticSourceBuilder</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token string">"elastic-source"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">clientFn</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token class-name">RestClient</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">HttpHost</span><span class="token punctuation">(</span>
                <span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">9200</span>
        <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">searchRequestFn</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token class-name">SearchRequest</span><span class="token punctuation">(</span><span class="token string">"my-index"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">optionsFn</span><span class="token punctuation">(</span>request <span class="token operator">-></span> <span class="token class-name">RequestOptions</span><span class="token punctuation">.</span>DEFAULT<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">mapToItemFn</span><span class="token punctuation">(</span>hit <span class="token operator">-></span> hit<span class="token punctuation">.</span><span class="token function">getSourceAsString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">slicing</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">Sink</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Map</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">></span><span class="token punctuation">></span></span> elasticSink <span class="token operator">=</span> <span class="token class-name">ElasticSinks</span><span class="token punctuation">.</span><span class="token function">elasticsearch</span><span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token function">client</span><span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"password"</span><span class="token punctuation">,</span> <span class="token string">"host"</span><span class="token punctuation">,</span> <span class="token number">9200</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    item <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token class-name">IndexRequest</span><span class="token punctuation">(</span><span class="token string">"my-index"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">source</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>See
<a href="https://github.com/hazelcast/hazelcast-jet/tree/master/examples/elastic">GitHub</a>
for a full, end-to-end example.</p>
<h2><a class="anchor" aria-hidden="true" id="rebalance-operator"></a><a href="#rebalance-operator" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>.rebalance() operator</h2>
<p>Hazelcast Jet, by default, prefers not to send the data around the
computing cluster. If your data source retrieves some part of the data
stream on member A and you apply a mapping to it, the processing will
only happen on member A. If you have a non-distributed data source, this
may mean that all processing only happens on one member.</p>
<p>Jet 4.2 introduces the <code>.rebalance()</code> operator, which lets Jet
re-distribute data across the cluster at any point in the pipeline. To
use it is very simple:</p>
<pre><code class="hljs css language-java"><span class="token class-name">Pipeline</span> p <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">Sources</span><span class="token punctuation">.</span><span class="token function">itemStream</span><span class="token punctuation">(</span><span class="token number">1_000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">withIngestionTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">rebalance</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
</code></pre>
<p>For more details, please see the <a href="/docs/api/more-transforms#rebalance">documentation page</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="improved-json-support"></a><a href="#improved-json-support" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Improved JSON Support</h2>
<p>In previous versions of Jet, it was possible to read JSON files using
the file source, but it required some manual effort to set up the parsing
yourself. With 4.2, we're now making use of
<a href="https://github.com/FasterXML/jackson-jr">jackson-jr</a> to parse JSON
files and offer a native JSON file source. The source provides support
for object mapping out of the box, so all you need to do is like below:</p>
<pre><code class="hljs css language-java"><span class="token class-name">Pipeline</span> p <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">Sources</span><span class="token punctuation">.</span><span class="token function">json</span><span class="token punctuation">(</span><span class="token string">"/home/data/people"</span><span class="token punctuation">,</span> <span class="token class-name">Person</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>person <span class="token operator">-></span> person<span class="token punctuation">.</span><span class="token function">location</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"NYC"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">logger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Similarly, we have added a sink that can output JSON files
in the same way. For more details, please see the <a href="/docs/api/sources-sinks#json-files">documentation
page</a>.</p>
<h3><a class="anchor" aria-hidden="true" id="support-for-json-parsing"></a><a href="#support-for-json-parsing" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Support for JSON parsing</h3>
<p>As part of JSON improvements, there is also now a built-in utility
method which you can use to parse JSON inside a pipeline:</p>
<pre><code class="hljs css language-java">stage<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>json <span class="token operator">-></span> <span class="token class-name">JsonUtil</span><span class="token punctuation">.</span><span class="token function">beanFrom</span><span class="token punctuation">(</span>json<span class="token punctuation">,</span> <span class="token class-name">Person</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>See the <a href="/docs/api/more-transforms#json">documentation page</a> for
additional instructions.</p>
<h2><a class="anchor" aria-hidden="true" id="apache-pulsar-connector"></a><a href="#apache-pulsar-connector" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Apache Pulsar Connector</h2>
<p><a href="https://pulsar.apache.org/">Apache Pulsar</a> is a popular, fault-tolerant
pub-sub messaging system which is a good fit for stream processing
systems. A connector for Apache Pulsar is now also available as a
<a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/pulsar">contrib module</a>
.</p>
<p>The source is fault-tolerant and can be used as below:</p>
<pre><code class="hljs css language-java"><span class="token class-name">StreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Event</span><span class="token punctuation">></span></span> source <span class="token operator">=</span> <span class="token class-name">PulsarSources</span><span class="token punctuation">.</span><span class="token function">pulsarReaderBuilder</span><span class="token punctuation">(</span>
                topicName<span class="token punctuation">,</span>
                <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token class-name">PulsarClient</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">serviceUrl</span><span class="token punctuation">(</span><span class="token string">"pulsar://localhost:6650"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token class-name">Schema</span><span class="token punctuation">.</span><span class="token function">JSON</span><span class="token punctuation">(</span><span class="token class-name">Event</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token class-name">Message</span><span class="token operator">::</span><span class="token function">getValue</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>For a more detailed example, you can see the <a href="/docs/tutorials/pulsar">Apache Pulsar
Tutorial</a>.</p>
<h3><a class="anchor" aria-hidden="true" id="command-line-and-docker-improvements"></a><a href="#command-line-and-docker-improvements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Command-line and Docker Improvements</h3>
<p>We've also made some improvements to the Jet command-line scripts. A
quick summary is below:</p>
<ul>
<li>You can now use the <code>config/jvm.options</code> file to control the JVM
options when starting Jet without having to set environment variables.</li>
<li>We've added support to export JMX metrics through Prometheus. It's
enough to specify a <code>PROMETHEUS_PORT</code> environment variable to start
exporting metrics using Prometheus.</li>
<li>Rebuild the docker image using a multi-stage process for a
smaller footprint.</li>
<li>You can use the <code>JET_MODULES</code> environment variable to auto-import
modules to Jet without having to copy files, which is especially
useful in a docker environment.</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="documentation-improvements"></a><a href="#documentation-improvements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Documentation Improvements</h3>
<p>As part of the release, we've also made improvements and added new
sections to the documentation:</p>
<ul>
<li>Revamped and simplified <a href="/docs/operations/kubernetes">Jet on
Kubernetes</a> documentation.</li>
<li>Overhauled <a href="/docs/operations/docker">Running With Docker</a> with
additional information.</li>
<li>A new section on <a href="/docs/operations/gc-concerns">Garbage Collection</a> which
was the result of our <a href="/blog/2020/06/09/jdk-gc-benchmarks-part1">extensive research and benchmarking</a></li>
<li>Extended the documentation for <a href="/docs/api/stateless-transforms#mapusingpython">Python
transformations</a>.</li>
<li>Added additional docs about <a href="/docs/api/pipeline#adding-timestamps-to-a-stream">adding timestamps to a
stream</a>.</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="full-release-notes"></a><a href="#full-release-notes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Full Release Notes</h2>
<p>Members of the open source community that appear in these release notes:</p>
<ul>
<li>@caioguedes</li>
</ul>
<p>Thank you for your valuable contributions!</p>
<h3><a class="anchor" aria-hidden="true" id="new-features"></a><a href="#new-features" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>New Features</h3>
<ul>
<li>[core] [011] Add JSON file source as well as built-in functions for
parsing JSON strings (#2218, #2270)</li>
<li>[pipeline-api] [008] Add support for stage rebalancing (#2149)</li>
<li>[cdc] [005] New Change Data Capture Source for MySQL (#2142)</li>
<li>[cdc] [005] New Change Data Capture Source for PostgreSQL (#2247)</li>
<li>[cdc] [005] CDC Map Sink for keeping a Map in sync with a stream of
changes from the database (#2262)</li>
<li>[elasticsearch] [003] Added source and sink connectors for
Elasticsearch 5, 6, 7 (#2098, #2286, #2287)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="enhancements"></a><a href="#enhancements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Enhancements</h3>
<ul>
<li>[core] Support Hazelcast Serialization for ProcessorSupplier (#2298)</li>
<li>[core] Increase default parallelism for file and Avro source to 4
(#2359)</li>
<li>[pipeline-api] Support for keyFn and valueFn in map sink (#2198)</li>
<li>[jet-cli] Introduce --targets as the default command for specifying
where to connect and add it as a mixins for all comments (@caioguedes
#2276)</li>
<li>[jet-cli] Add support JET_MODULES environment variable to import
modules automatically without having to copy them (#2314)</li>
<li>[jet-cli] Support PROMETHEUS_PORT environment variable to start Jet
with prometheus metrics enabled (#2328)</li>
<li>[jet-cli] Add jvm.options file which can be used to specify JVM
options during startup (#2349)</li>
<li>[docker] Several Docker image improvements (hazelcast-jet-docker#27)</li>
<li>[grpc] Performance improvements to gRPC module (#2245)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="fixes"></a><a href="#fixes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fixes</h3>
<ul>
<li>[core] Fix potential ClassCastException in onSnapshotPhase2Completed()
(#2338)</li>
<li>[core] Fix JobConfig.attachFile path resolution on Windows (#2357)</li>
<li>[jet-cli] Fix bad rolling filename causing misplaced files (#2270)</li>
<li>[jet-cli] Use exec in jet-start to support ctrl-C in docker
environment [#2307)</li>
<li>[avro] Add missing serializer for Avro Utf-8 class (#2358)</li>
</ul>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/06/23/jdk-gc-benchmarks-rematch">Performance of Modern Java on Data-Heavy Workloads: The Low-Latency Rematch</a></h1><p class="post-meta">June 23, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener">Marko Topolnik</a></p><div class="authorPhoto"><a href="https://twitter.com/mtopolnik" target="_blank" rel="noreferrer noopener"><img src="https://i.imgur.com/xuavzce.jpg" alt="Marko Topolnik"/></a></div></div></header><article class="post-content"><div><span><p>This post is a part of a series:</p>
<ul>
<li><a href="/blog/2020/06/09/jdk-gc-benchmarks-part1">Part 1 (Intro and high-throughput streaming
benchmark)</a></li>
<li><a href="/blog/2020/06/09/jdk-gc-benchmarks-part2">Part 2 (batch workload benchmark)</a></li>
<li>Part 3 (you are here)</li>
<li><a href="/blog/2020/08/05/gc-tuning-for-jet">Part 4 (concurrent GC with green threads)</a></li>
<li><a href="/blog/2021/03/17/billion-events-per-second">Part 5 (billion events per second)</a></li>
</ul>
<p>This is a followup on Part 1 of the blog post series we started earlier
this month, analyzing the performance of modern JVMs on workloads that
are relevant to the use case of real-time stream processing.</p>
<p>As a quick recap, in Part 1 we tested the basic functionality of
<a href="https://github.com/hazelcast/hazelcast-jet">Hazelcast Jet</a> (sliding
window aggregation) on two types of workload: lightweight with a focus
on low latency, and heavyweight with a focus on the data pipeline
keeping up with high throughput and large aggregation state. For the
low-latency benchmarks we chose the JDK 14 as the most recent stable
version and three of its garbage collectors: Shenandoah, ZGC, and G1 GC.</p>
<p>Our finding that Shenandoah apparently fared worse than the other GCs
attracted some reactions, most notably from the Shenandoah team who
reproduced our finding, created an
<a href="https://bugs.openjdk.java.net/browse/JDK-8247358">issue</a>, came up with
a fix, and committed it to the jdk/jdk16 repository, all in the span of
a few days. The change pertains to the heuristics that decide how much
work the GC should do in the background in order to exactly match the
applications allocation rate. This component is called the <em>pacer</em>. It
was constantly detecting it's falling behind the application, triggering
a brief &quot;panic mode&quot; in order to catch up. The fix fine-tunes the
pacer's heuristics to make the background GC work more proactive.</p>
<p>Given this quick development, we wanted to test out the effects of the
fix, but also take the opportunity to zoom in on the low-latency
streaming case and make a more detailed analysis.</p>
<p>Here are our main conclusions:</p>
<ol>
<li>ZGC is still the winner and the only GC whose 99.99th percentile
latency stayed below 10 ms across almost all of our tested range</li>
<li>Shenandoah's pacer improvement showed a very strong effect, reducing
the latency by a factor of three, but still staying well above 10 ms
except in the very lowest part of our tested range</li>
<li>G1 kept its 99.99th percentile latency below 13 ms across a wide
range of throughputs</li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="the-jdk-we-tested"></a><a href="#the-jdk-we-tested" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The JDK We Tested</h2>
<p>Since this is all so fresh, we couldn't use an existing JDK release, not
even EA, to see the effects of the fix. JDK version 14.0.2 is slated to
be released on July 14. To nevertheless make progress, we took the
source code from the jdk14u tree, at the changeset number
<a href="http://hg.openjdk.java.net/jdk-updates/jdk14u/rev/e9d41bbaea38">57869:e9d41bbaea38</a>,
and applied the changeset number
<a href="https://hg.openjdk.java.net/jdk/jdk/rev/29b4bb22b5e2">59746:29b4bb22b5e2</a>
from the main jdk tree on top of it. The jdk14u tree is where JDK 14.0.2
will be released from and the changeset 59746:29b4bb22b5e2 applies the
patch resolving the mentioned Shenandoah issue.</p>
<h2><a class="anchor" aria-hidden="true" id="the-jvm-options"></a><a href="#the-jvm-options" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The JVM Options</h2>
<p>There are two HotSpot JVM options whose default values change
automatically when you use the ZGC so we had to decide which choice to
make when testing the other garbage collectors.</p>
<ul>
<li><p><code>-XX:-UseBiasedLocking</code>: biased locking has for a while been under
criticism that it causes higher latency spikes due to bias revocation
that must be done within a GC safepoint. In the upcoming JDK version
15, biased locking will be <a href="https://openjdk.java.net/jeps/374">disabled by default and
deprecated</a>. Any low-latency Java
application should have this disabled and we disabled it in all our
measurements.</p></li>
<li><p><code>-XX:+UseNUMA</code>: Shenandoah and ZGC can query the NUMA layout of the
host machine and optimize their memory layout accordingly. The only
reason why Shenandoah doesn't do it by default is a general precaution
against suddenly changing the behavior for upgrading users, but the
precaution is no longer necessary. It will be <a href="https://openjdk.java.net/jeps/163">enabled by
default</a> in upcoming JDK versions,
and we saw no harm in enabling it in all cases as well. <strong>Late
update</strong>: G1 can also optimize for the NUMA layout, but we didn't use
<code>UseNUMA</code> for it. However, we also checked the c5.4xlarge instance
with <code>numactl</code> and it indicated that the entire machine was a single
NUMA node anyway.</p></li>
</ul>
<p>There is also a JVM feature that is simply incompatible with ZGC's
colored pointers: compressed object pointers. In other words, ZGC
applies <code>-XX:-UseCompressedOops</code> without the option to enable it.
A compressed pointer is just 32 bits long but handles heaps of up to
32 GB and it's usually beneficial to both memory usage and performance.
We left this option enabled for Shenandoah.</p>
<p>For the G1 collector, we also set <code>-XX:MaxGCPauseMillis=5</code>, same as in
the previous testing round, because the default of 200 milliseconds is
optimized for throughput and the G1 can give you much better latency
than that.</p>
<p>We performed all our tests on an EC2 c5.4xlarge instance. It has 16
vCPUs and 32 GB of RAM.</p>
<h2><a class="anchor" aria-hidden="true" id="the-data-pipeline"></a><a href="#the-data-pipeline" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Data Pipeline</h2>
<p>To get a more nuanced insight into the performance, we made some
improvements to the testing code. Whereas in the first iteration we just
reported the maximum latency, this time around we wanted to capture the
entire latency profile. To this end we had to increase the number of
reports per second the pipeline outputs. Initially we set it to 10 times
per second, a number which results in too few data points for the
latency chart. The pipeline in this round emits 100 reports per second.
The event rate and the length of the time window are the same: 1 million
events per second and 10 seconds, respectively. This results in 1,000
hashtables each holding 10,000 keys as the aggregation state. We tested
across a wide range of keyset sizes, starting from 5,000 up to 105,000.</p>
<p>Note that the size of the keyset, somewhat counterintuitively, does not
affect the size of the aggregation state. As long as the 10,000 input
events received during one time slice of 10 milliseconds all use
distinct keys, the state is fixed as described above. Only in the lowest
setting, 5,000, the state is half as large since every hashtable
contains just 5,000 keys.</p>
<p>What the keyset size does affect is allocation rate. The pipeline emits
the full keyset every 10 milliseconds. For example, with 50,000 keys
that's 5,000,000 result items per second. If we add to that the rate of
the input stream (a fixed million events per second), we get a value
that is a good proxy for the overall allocation rate. This is why we
chose combined input+output rate as the x-axis value in the charts that
we'll be showing below.</p>
<p>Here is the basic code of the pipeline, available on
<a href="https://github.com/mtopolnik/jet-gc-benchmark/blob/round-2/src/main/java/org/example/StreamingRound2.java">GitHub</a>:</p>
<pre><code class="hljs css language-java"><span class="token class-name">StreamStage</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">></span></span> source <span class="token operator">=</span> p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token function">longSource</span><span class="token punctuation">(</span>EVENTS_PER_SECOND<span class="token punctuation">)</span><span class="token punctuation">)</span>
                            <span class="token punctuation">.</span><span class="token function">withNativeTimestamps</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
                            <span class="token punctuation">.</span><span class="token function">rebalance</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">StreamStage</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> latencies <span class="token operator">=</span> source
        <span class="token punctuation">.</span><span class="token function">groupingKey</span><span class="token punctuation">(</span>n <span class="token operator">-></span> n <span class="token operator">%</span> NUM_KEYS<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token function">sliding</span><span class="token punctuation">(</span>WIN_SIZE_MILLIS<span class="token punctuation">,</span> SLIDING_STEP_MILLIS<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">aggregate</span><span class="token punctuation">(</span><span class="token function">counting</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>kwr <span class="token operator">-></span> kwr<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">%</span> DIAGNOSTIC_KEYSET_DOWNSAMPLING_FACTOR <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">mapStateful</span><span class="token punctuation">(</span><span class="token class-name">DetermineLatency</span><span class="token operator">::</span><span class="token keyword">new</span><span class="token punctuation">,</span> <span class="token class-name">DetermineLatency</span><span class="token operator">::</span><span class="token function">map</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

latencies<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>t2 <span class="token operator">-></span> t2<span class="token punctuation">.</span><span class="token function">f0</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> TOTAL_TIME_MILLIS<span class="token punctuation">)</span>
         <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>t2 <span class="token operator">-></span> <span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"%d,%d"</span><span class="token punctuation">,</span> t2<span class="token punctuation">.</span><span class="token function">f0</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> t2<span class="token punctuation">.</span><span class="token function">f1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
         <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">files</span><span class="token punctuation">(</span><span class="token string">"/home/ec2-user/laten"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
latencies
      <span class="token punctuation">.</span><span class="token function">mapStateful</span><span class="token punctuation">(</span><span class="token class-name">RecordLatencyHistogram</span><span class="token operator">::</span><span class="token keyword">new</span><span class="token punctuation">,</span> <span class="token class-name">RecordLatencyHistogram</span><span class="token operator">::</span><span class="token function">map</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">files</span><span class="token punctuation">(</span><span class="token string">"/home/ec2-user/bench"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>The main part, sliding window aggregation, remains the same, but the
following stages that process the results are new. We write the data to
two files: <code>laten</code>, containing all the raw latency data points, and
<code>bench</code>, containing an <a href="https://hdrhistogram.github.io/HdrHistogram/plotFiles.html">HDR
Histogram</a>
of the latencies.</p>
<p>Another key difference is that, in the original post, we measured the
latency of <em>completing</em> to emit a result set, but here we measure the
latency of <em>starting</em> to emit it. Since we are changing the size of the
output, if we kept measuring the completion latency, we'd be introducing
a different amount of application-induced latency at each data point.</p>
<p>There's another, relatively minor technical point worth mentioning:
since we tested on a cloud server instance, we used Jet's client-server
mode, which means we separately start a Jet node and then deploy the
pipeline to it using Jet's command <code>jet submit</code>. The code available on
GitHub is the client code and the Jet server code was a build from the
Jet master branch before Jet 4.2 was released. We expect all the results
to be reproducible with the <a href="https://github.com/hazelcast/hazelcast-jet/releases/download/v4.2/hazelcast-jet-4.2.tar.gz">Jet 4.2
release</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="what-exactly-we-measured"></a><a href="#what-exactly-we-measured" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What Exactly We Measured</h2>
<p>We measured the latency as the timestamp at which the pipeline emits a
given result minus the timestamp to which the result pertains, giving us
end-to-end latency (the only kind the user actually cares about).</p>
<p>Keep especially in mind that latency does not equal a GC pause.
Normally, neither Shenandoah nor ZGC enter anything more than a
millisecond of GC pause, but their background work shares the limited
system capacity with the application. With G1 the equivalence is much
stronger and its 10-20 millisecond latencies are primarily the result of
GC pauses that long.</p>
<h2><a class="anchor" aria-hidden="true" id="the-measurements"></a><a href="#the-measurements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Measurements</h2>
<p>To come up with the charts below, for each data point we let the
pipeline warm up for 20 seconds and then gathered the latencies for 4
minutes, collecting 24,000 samples.</p>
<p>Here is the latency histogram taken at 2 million items per second,
close to the bottom of our range:</p>
<p><img src="/blog/assets/2020-06-23-histo-2m.png" alt="Latency on JDK 14.0.2 pre-release, 2M items per second"></p>
<p>Unpatched Shenandoah seems like the winner, except for the single
worst-case latency. With the patch applied, latency increases sooner but
more gently and doesn't have a strong peak. ZGC comes somewhere between,
but overall all three cases show pretty similar behavior. G1 is clearly
worse and its latency exceeds the 10 ms mark before even reaching the
99th percentile. Since our pipeline emits a new result set ever 10 ms,
we shall consider 10 ms as the cutoff point: everything above 10 ms
should be considered a failure for our use case.</p>
<p>Next, let's take a look at the latencies after increasing the throughput
a bit, to 3 million items per second:</p>
<p><img src="/blog/assets/2020-06-23-histo-3m.png" alt="Latency on JDK 14.0.2 pre-release, 3M items per second"></p>
<p>Wow, what an unexpected difference! Now we can clearly see the pacer
improvement doing its thing, lowering the latency about threefold.
However, even with the improvement, Shenandoah unfortunately crosses the
10 ms mark pretty early, below the 99th percentile, and is worse than G1
at almost every percentile. ZGC and G1 score basically the same as
before.</p>
<p>Note also the very regular shape of the pale blue curve (unpatched
Shenandoah): this is a symptom of the way a single bad event trickles
down into the lower latency percentiles. For example, if one result is
late by 50 ms, that means it has already caused the next four results to
have at least the latencies of 40, 30, 20, and 10 ms, even if they would
be emitted instantaneously.</p>
<p>Next, let's zoom out to an overview of the entire range of throughputs
we benchmarked, taking the 99.99%ile as the reference point and showing
its dependence on throughput. To paint an intuitive picture, 99.99%
latency tells you that, in any span of 100 seconds you look at, you're
likely to find a latency spike at least that large. Here's the chart:</p>
<p><img src="/blog/assets/2020-06-23-latencies-jdk14.png" alt="Latencies on JDK 14.0.2 pre-release"></p>
<p>Here are some things to note:</p>
<ol>
<li>ZGC stays below 10 ms over a large part of the range, up to 8 M items
per second. This makes it not just the winner, but the only choice
for the range from 2 million to 8 million items per second.</li>
<li>The G1 collector is unphased by the differences in throughput. While
its latency is never under 10 milliseconds, it keeps its level over
the entire tested range and more. Its latency even improves a bit
with higher loads.</li>
<li>At 9.5 M items per second, ZGC shows a remarkable recovery.
Sandwiched between the latencies of 92 and 209 milliseconds, at this
exact throughput it achieves 10 ms latency! We of course thought it
was a measurement error and repeated it for three times, but the
result was consistent. Maybe there's a lesson in there for the ZGC
engineers.</li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="a-sneak-peek-into-upcoming-versions"></a><a href="#a-sneak-peek-into-upcoming-versions" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>A Sneak Peek into Upcoming Versions</h2>
<p>As a preview into what's coming up in OpenJDK, we also took a look at
the <a href="https://download.java.net/java/early_access/jdk15/28/GPL/openjdk-15-ea+28_linux-x64_bin.tar.gz">Early Access release 27 of JDK
15</a>.
Shenandoah's pacer improvement is not applied in it, so to properly test
Shenandoah's prospects we used a build available at
<a href="https://builds.shipilev.net/openjdk-jdk/">builds.shipilev.net/openjdk-jdk</a>,
specifically one that reports its version as <code>build 16-testing+0-builds.shipilev.net-openjdk-jdk-b1282-20200611</code>. Out of
interest we also doubled our throughput range to capture more of the
behavior after the latency exceeds 10 milliseconds. Here's what we got:</p>
<p><img src="/blog/assets/2020-06-23-latencies-latest.png" alt="Latencies on upcoming JDK versions"></p>
<p>We can see a nice incremental improvement for the ZGC: less than 5 ms
latencies at throughputs below 5 M/s. Shenandoah's curve is even a bit
worse at 2.5-3 M per second, but generally pretty similar. At higher
loads we can see ZGC's failure mode is quite a bit more severe than
Shenandoah's, although just how bad the latency gets doesn't affect the
bottom line of a scenario where everything above 10 ms is already a
failure.</p>
<p>The wider chart also gives better insight into the stability of G1,
keeping itself below 20 ms all the way up to 20 M items per second.</p>
<p><em>If you enjoyed reading this post, check out Jet at
<a href="https://github.com/hazelcast/hazelcast-jet">GitHub</a> and give us a
star!</em></p>
</span></div></article></div><div class="docs-prevnext"><a class="docs-next" href="/blog/page2/">Next →</a></div></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div style="text-align:left"><a href="/" class="nav-home"><img src="/img/logo-light.svg" alt="Hazelcast Jet" width="200" height="40"/></a><div style="margin-left:12px"><a class="github-button" href="https://github.com/hazelcast/hazelcast-jet" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star On GitHub</a></div></div><div><h5>Docs</h5><a href="/docs/get-started/intro">Get Started</a><a href="/docs/concepts/dag">Concepts</a><a href="/docs/tutorials/kafka">Tutorials</a><a href="/docs/architecture/distributed-computing">Architecture</a><a href="/docs/operations/installation">Operations Guide</a><a href="/docs/enterprise">Enterprise Edition</a></div><div><h5>Community</h5><a href="https://groups.google.com/forum/#!forum/hazelcast-jet" target="_blank" rel="noreferrer noopener">Google Groups</a><a href="http://stackoverflow.com/questions/tagged/hazelcast-jet" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://slack.hazelcast.com">Slack</a></div><div><h5>Latest From the Blog</h5><a href="/blog/2021/04/21/jet-45-is-released">Jet 4.5 Released</a><a href="/blog/2021/03/17/billion-events-per-second">Billion Events Per Second with Millisecond Latency: Streaming Analytics at Giga-Scale</a><a href="/blog/2021/02/03/jet-44-is-released">Jet 4.4 Released</a><a href="/blog/2020/10/23/jet-43-is-released">Jet 4.3 Released</a><a href="/blog/2020/10/06/enabling-full-text-search">Enabling Full-text Search with Change Data Capture in a Legacy Application</a></div><div><h5>More</h5><a href="https://github.com/hazelcast/hazelcast-jet">GitHub Project</a><a href="http://hazelcast.com/company/careers/">Work at Hazelcast</a><a href="/license">License</a></div></section><section class="copyright">Copyright © 2021 Hazelcast Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '79d1e4941621b9fd761d279d4d19ed69',
                indexName: 'hazelcast-jet',
                inputSelector: '#search_input_react',
                algoliaOptions: {"facetFilters":["language:en","version:4.5.2"]}
              });
            </script></body></html>