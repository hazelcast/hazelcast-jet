<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Blog · Hazelcast Jet</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Open-Source Distributed Stream Processing"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Blog · Hazelcast Jet"/><meta property="og:type" content="website"/><meta property="og:url" content="https://jet-start.sh/"/><meta property="og:description" content="Open-Source Distributed Stream Processing"/><meta property="og:image" content="https://jet-start.sh/img/Hazelcast-Jet-Logo-Blue_Dark.jpg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://jet-start.sh/img/Hazelcast-Jet-Logo-Blue_Dark.jpg"/><link rel="shortcut icon" href="/img/favicon.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://jet-start.sh/blog/atom.xml" title="Hazelcast Jet Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://jet-start.sh/blog/feed.xml" title="Hazelcast Jet Blog RSS Feed"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-158279495-1', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,500,600"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600,700,800"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/code-block-buttons.js"></script><script type="text/javascript" src="https://plausible.io/js/plausible.js" async="" defer="" data-domain="jet-start.sh"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/prism.css"/><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="blog"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/logo-dark.svg" alt="Hazelcast Jet"/></a><a href="/versions"><h3>4.3</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/get-started/intro" target="_self">Docs</a></li><li class=""><a href="/download" target="_self">Download</a></li><li class=""><a href="/demos" target="_self">Demos</a></li><li class=""><a href="https://github.com/hazelcast/hazelcast-jet" target="_self">GitHub</a></li><li class=""><a href="https://slack.hazelcast.com/" target="_self">Community</a></li><li class="siteNavGroupActive siteNavItemActive"><a href="/blog/" target="_self">Blog</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>All posts</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">All posts</h3><ul class=""><li class="navListItem"><a class="navItem" href="/blog/2020/10/23/jet-43-is-released">Jet 4.3 Released</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/10/06/enabling-full-text-search">Enabling Full-text Search with Change Data Capture in a Legacy Application</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/09/18/cdc-meets-stream-processing">Change Data Capture meets Stream Processing</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/08/05/gc-tuning-for-jet">Sub-10 ms Latency in Java: Concurrent GC with Green Threads</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/07/16/designing-evergreen-cache-cdc">Designing an Evergreen Cache with Change Data Capture</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/07/14/jet-42-is-released">Jet 4.2 is Released</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/06/23/jdk-gc-benchmarks-rematch">Performance of Modern Java on Data-Heavy Workloads: The Low-Latency Rematch</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/06/09/jdk-gc-benchmarks-part2">Performance of Modern Java on Data-Heavy Workloads: Batch Processing</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/06/09/jdk-gc-benchmarks-part1">Performance of Modern Java on Data-Heavy Workloads: Real-Time Streaming</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/05/25/grcp">Processing 10M queries / second on a single node using Jet and gRPC</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/05/18/spark-jet">How Hazelcast Jet Compares to Apache Spark</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/04/29/jet-41-is-released">Jet 4.1 is Released</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/04/01/upgrading-to-jet-40">Upgrading to Jet 4.0</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/03/30/ml-inference">Machine Learning Inference at Scale</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/03/02/jet-40-is-released">Jet 4.0 is Released</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/02/20/transactional-processors">Transactional connectors in Hazelcast Jet</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/01/28/new-website">Announcing New Documentation Website</a></li><li class="navListItem"><a class="navItem" href="/blog/2019/11/12/stream-deduplication">Stream Deduplication with Hazelcast Jet</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer postContainer blogContainer"><div class="wrapper"><div class="posts"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/05/18/spark-jet">How Hazelcast Jet Compares to Apache Spark</a></h1><p class="post-meta">May 18, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/voloda" target="_blank" rel="noreferrer noopener">Vladimir Schreiner</a></p><div class="authorPhoto"><a href="https://twitter.com/voloda" target="_blank" rel="noreferrer noopener"><img src="https://3l0wd94f0qdd10om8642z9se-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/speaker-vladimir-schreiner-e1551380845855-170x170.jpg" alt="Vladimir Schreiner"/></a></div></div></header><article class="post-content"><div><span><p>“How Jet compares to Spark” and “why should I choose Jet over Spark” are
arguably the most frequent questions I’ve been asked during the talks
and workshops. While it is hard to assess the product fit without
focusing on a concrete use-case, I’d still like to compare concepts and
architecture used under the hood of both frameworks.</p>
<p>Versions considered: <a href="https://jet-start.sh/download">Hazelcast Jet 4.1</a>
and <a href="https://spark.apache.org/downloads.html">Apache Spark 2.4.5</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="computations-modeled-as-graphs"></a><a href="#computations-modeled-as-graphs" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Computations Modeled as Graphs</h2>
<p>Apache Spark and Hazelcast Jet (referred to as “frameworks”) are both
tools for clustered computing. They are applicable mostly for analytical
(OLAP) applications, including those that apply a series of processing
steps to many uniform data records (such as lines in a file, rows in a
table or records appended to a stream), as one example.</p>
<p>Both frameworks build on the principles of dataflow programming: a user
builds an application by chaining high-level coarse-grained operators
such as map, join or aggregate. The operators form a network that can be
modeled as a graph (<a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">directed acyclic
graphs</a> or DAG to
be specific) where nodes represent steps in the computation and edges
represent data exchange.</p>
<p>The dataflow model has some important properties that both frameworks
use for scaling and fault-tolerance:</p>
<ul>
<li>Pipeline Parallelism: operators can work independently, in parallel.</li>
<li>Data Parallelism: a single operator can run in multiple instances,
each instance processing a particular data partition</li>
<li>No Shared State: each operator instance manages its state exclusively.
There is no shared state to coordinate access to or to replicate.
Moreover, the state is only determined by the input data. As a result,
the operator can be recovered by replaying the input data.</li>
</ul>
<p>Spark and Jet differ in how they use and execute the DAG as explained in
the next section but fundamentally: no matter which API you use (RDDs,
Spark SQL or a Pipeline API of Jet), <strong>the physical execution plan is a
DAG representing the dataflow</strong>.</p>
<h2><a class="anchor" aria-hidden="true" id="staged-x-continuous-execution-mode"></a><a href="#staged-x-continuous-execution-mode" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Staged x Continuous Execution Mode</h2>
<p>In Spark, the DAG nodes represent execution stages. A stage must be
fully completed before Spark starts the next one. In Jet, DAG represents
connected operators. Jet executes all DAG nodes concurrently.</p>
<p>Let’s use a textbook OLAP example to elaborate: the log analysis (a
real-world application of notorious word count). Data from the access
logs are aggregated over different grouping keys, such as counting the
web sessions over several web applications using shared session id.</p>
<p>This is the Spark and Jet code to load the data, pre-process (parse) and
aggregate it:</p>
<p>Spark RDD API (Java)</p>
<pre><code class="hljs css language-java">sc<span class="token punctuation">.</span><span class="token function">textFile</span><span class="token punctuation">(</span><span class="token string">"/path/to/input/"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">LineIterator</span><span class="token operator">::</span><span class="token keyword">new</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">mapToPair</span><span class="token punctuation">(</span>s <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token number">1L</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">Function2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> <span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span> <span class="token operator">-></span> a <span class="token operator">+</span> b<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">saveAsTextFile</span><span class="token punctuation">(</span><span class="token string">"/path/to/output/"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Jet Pipeline API (Java)</p>
<pre><code class="hljs css language-java">p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">Sources</span><span class="token punctuation">.</span><span class="token function">files</span><span class="token punctuation">(</span><span class="token string">"/path/to/input/"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">LogLine</span><span class="token operator">::</span><span class="token function">parse</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">groupingKey</span><span class="token punctuation">(</span><span class="token function">wholeItem</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">aggregate</span><span class="token punctuation">(</span><span class="token function">counting</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">files</span><span class="token punctuation">(</span><span class="token string">"/path/to/output/"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="spark-and-staged-execution"></a><a href="#spark-and-staged-execution" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Spark and Staged Execution</h3>
<p>Spark splits the computation to non-overlapping stages. A reading stage
and a group-and-aggregate stage, in our case. During the reading stage,
Spark workers fetch data from disk files, parse it and cache it in the
cluster memory. Spark schedules more tasks if the source can be read in
parallel (e.g. data is partitioned). All reading stage tasks must be
finished before the first aggregating task is started.</p>
<p>This is the DAG representing execution stages (
<a href="https://www.tutorialkart.com/apache-spark/dag-and-physical-execution-plan/">source</a>).</p>
<p><img src="/blog/assets/2020-05-18-spark-dag-stages.svg" alt="Spark Staged Execution"></p>
<p>Staged execution was designed to support an iterative analytics use-case
where the results of one stage stay cached in a cluster memory to be
reused by a following step in the analysis. This makes Spark a popular
choice for ML research where a data scientist gradually evolves the
dataset with new experiments, evicting the data when their Spark session
is over. It is also a powerful debugging tool.</p>
<p>On the other hand, staged execution doesn’t perform well for
latency-sensitive use-cases, namely stream processing.</p>
<p>Streaming data is continuously incrementing. Staged execution is however
designed for finite datasets. Whole input must be read before Spark
starts subsequent steps. Spark Streaming works around this by batching
the input data, e.g. creating finite chunks from an infinite stream.
Buffering adds to the job latency as the data are waiting for the batch
to fill, staying idle.</p>
<p>The stages are planned and scheduled again and again for every batch.
The overhead of the planning process increases the latency further.</p>
<p>Another latency penalty comes if the data partitions are not balanced
evenly. If a single partition of data takes longer to read or process,
it would block the whole job from progressing since the next stage can’t
be started. Jet would be impacted by this scenario, too, but it can
still provide early results – in-complete, indicative results based on
already processed partitions.</p>
<h3><a class="anchor" aria-hidden="true" id="jet-and-continuous-execution"></a><a href="#jet-and-continuous-execution" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Jet and Continuous Execution</h3>
<p>Jet executes all DAG nodes concurrently. The DAG is deployed to all
cluster nodes when the job is submitted and runs until a termination.
The instances of running DAG nodes, called Processors, then run in
parallel and continuously exchange data. For partitioned data sets, the
data partitions are evenly distributed among available processors (see
the
<a href="https://jet-start.sh/docs/architecture/distributed-computing">docs</a>).</p>
<p>This is the DAG representing the execution plan for the log aggregation.
Jet would create multiple instances of each and route data among it
following the routing strategy (<a href="https://jet-start.sh/docs/next/architecture/distributed-computing">source</a>):</p>
<p><img src="/blog/assets/2020-05-18-jet-dag.svg" alt="Jet Execution DAG"></p>
<p>A reading Processor keeps fetching data from the data source and sends
it to a downstream channel immediately. The channel routes data to the
respective aggregating processor, following the grouping key. The
aggregating processor is observing the input channel and updates the
aggregate with each input item. It’s an application concern to specify
when the aggregator emits the aggregate downstream – with every input
item, after a period of time, after the whole dataset has been processed
or based on a data-driven trigger.</p>
<p>The continuous execution model is a natural fit for streaming use-cases
that stress low latency. Jet Jobs can keep millisecond latencies on a
large scale.</p>
<p>Spark has introduced the continuous execution mode in 2.4. The mode is
still experimental and is limited to stateless operators (mapping,
filtering) so it wasn’t considered for this comparison.</p>
<h2><a class="anchor" aria-hidden="true" id="in-memory-execution"></a><a href="#in-memory-execution" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>In-Memory Execution</h2>
<p>Spark and Jet both rely on an in-memory execution. That means that <em>data
transfer</em> and <em>execution state</em> both use the cluster RAM.</p>
<h3><a class="anchor" aria-hidden="true" id="data-transfer"></a><a href="#data-transfer" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data Transfer</h3>
<p>In-memory data transfer means that the data between the consecutive DAG
nodes are exchanged using shared memory instead of a disk (shuffling the
data among cluster nodes still requires a network, of course).</p>
<p>Spark exchanges data between stages by saving the complete output of an
upstream stage in the memory of the worker to be used as an input of a
downstream stage. Jet uses in-memory queues to connect upstream and
downstream Processors.</p>
<p>That makes Spark more memory demanding as it caches the whole dataset
exchanged between two steps which can easily be hundreds of GB of data.
Spark workers are therefore able to spill data to disk not to run out of
memory. Jet processors run all in parallel and exchange data
continuously. The in-flight data are no more than a few thousand
records.</p>
<h3><a class="anchor" aria-hidden="true" id="execution-state"></a><a href="#execution-state" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Execution State</h3>
<p>Execution state refers to the temporary data of the computation, such as
the value of an ongoing aggregation or join. Both Jet and Spark keep the
state data on heap by default.</p>
<p>Spark can however also place execution state off-heap and even spill it
to disk. It can, therefore, perform calculations that require a large
state such as joins or sorts on huge datasets. For Jet, the execution
state must fit to cluster memory.</p>
<h2><a class="anchor" aria-hidden="true" id="dedicated-x-shared-resources"></a><a href="#dedicated-x-shared-resources" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Dedicated x Shared Resources</h2>
<p>Spark applications running in a cluster are isolated from each other.
Jet shares the cluster resources between applications (called Jobs). No
approach is “the right one”. It’s trading-off isolation and performance.</p>
<h3><a class="anchor" aria-hidden="true" id="spark-assigns-dedicated-resources"></a><a href="#spark-assigns-dedicated-resources" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Spark Assigns Dedicated Resources</h3>
<p>For each application, Spark runs dedicated processes for both scheduling
and execution.</p>
<p>The processes are created with the resources (CPU, memory and disk)
allocated to the application upon startup and reserved during job
lifetime. After the Spark Application ends, the processes are terminated
and the resources are freed.</p>
<p>This design clearly favours isolation. A noisy application doesn’t
affect the neighbours using the same computer. It can, however, lead to
overprovisioning as an Application holds allocated resources even if it
doesn’t require it.</p>
<p>Spark was designed in the age of Hadoop – huge clusters of heterogeneous
machines running many workloads. Multi-tenancy was, therefore, a
first-level design concern.</p>
<h3><a class="anchor" aria-hidden="true" id="jet-shares-resources"></a><a href="#jet-shares-resources" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Jet Shares Resources</h3>
<p>The Jet cluster is also formed by multiple member processes. Those
processes are started when the cluster starts and aren’t coupled with a
lifecycle of individual hosted Job.</p>
<p>Jobs share the cluster resources and run in a <a href="https://jet-start.sh/docs/architecture/execution-engine">cooperative
mode</a>. Each job
does a small amount of work and yields to the next one. Job is removed
from this round-robin after it finishes.</p>
<p>This design leads to efficient resource utilization. All jobs get a fair
amount of CPU time. If a job gets idle (e.g. waiting for more input
data), it simply backs off and Jet excludes it from the round-robin
rotation for a few milliseconds, giving busy Jobs more CPU to keep up.</p>
<p>Resource sharing is of course prone to noisy neighbours – a greedy job
can starve others. To prevent this, Jet recommends starting a cluster
per tenant or even per job, increasing the isolation to a Spark level.</p>
<h3><a class="anchor" aria-hidden="true" id="shared-datasets"></a><a href="#shared-datasets" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Shared Datasets</h3>
<p>Another benefit of job sharing processes is exchanging data over the
shared memory.</p>
<p>A job can load and pre-process data, caching it in cluster memory (Jet
comes with distributed storage). The cached collection then becomes a
source for further processing jobs, leading to <a href="https://hazelcast.com/resources/jet-0-4-vs-spark-flink-batch-benchmark/">significant performance
gains</a>
from reading the local memory instead of a remote data source. Another
use-case is shared reference data (such as lookup tables or parameters)
or queues connecting the output stream of one job to an input of another
one.</p>
<p>Spark applications run in isolated processes so they must use external
storage to exchange data.</p>
<h2><a class="anchor" aria-hidden="true" id="conclusion"></a><a href="#conclusion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conclusion</h2>
<p>Jet and Spark are frameworks that use principles of dataflow programming
to run analytical computations on clusters of machines for scalability
and resiliency.</p>
<p>They differ in how they implement and execute the data flow. Jet’s
design favours streaming use-cases that benefit from the low-latency
continuous execution. Spark can spill data to disk and isolates jobs on
a process level. Therefore it’s a good fit for large, multi-tenant
clusters.</p>
<p>Other areas worth comparing are the cluster architecture and APIs. They
will be covered in the next part of the article.</p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/04/29/jet-41-is-released">Jet 4.1 is Released</a></h1><p class="post-meta">April 29, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="http://twitter.com/cgencer" target="_blank" rel="noreferrer noopener">Can Gencer</a></p><div class="authorPhoto"><a href="http://twitter.com/cgencer" target="_blank" rel="noreferrer noopener"><img src="https://pbs.twimg.com/profile_images/1187734846749196288/elqWdrPj_400x400.jpg" alt="Can Gencer"/></a></div></div></header><article class="post-content"><div><span><p>We are happy to present the new release of Hazelcast Jet 4.1. Here's a
quick overview of the new features.</p>
<h2><a class="anchor" aria-hidden="true" id="extended-grpc-support"></a><a href="#extended-grpc-support" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Extended gRPC Support</h2>
<p>We've applied the lessons learned from the Jet-Python integration and
made it easier to integrate a Jet pipeline with <a href="https://grpc.io">gRPC</a>
services. The utility class <code>GrpcServices</code> introduces two new
<code>ServiceFactory</code>s you can use with the <code>mapUsingServiceAsync</code> transform.
Using this feature can be a significant performance boost vs. using the
sync <code>mapUsingService</code> call.</p>
<p>Here's a quick example on how you can use the gRPC service factory:</p>
<pre><code class="hljs css language-java"><span class="token keyword">var</span> greeterService <span class="token operator">=</span> <span class="token function">unaryService</span><span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token class-name">ManagedChannelBuilder</span><span class="token punctuation">.</span><span class="token function">forAddress</span><span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">5000</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">usePlaintext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    channel <span class="token operator">-></span> <span class="token class-name">GreeterGrpc</span><span class="token punctuation">.</span><span class="token function">newStub</span><span class="token punctuation">(</span>channel<span class="token punctuation">)</span><span class="token operator">::</span><span class="token function">sayHello</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">Pipeline</span> p <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">TestSources</span><span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token string">"one"</span><span class="token punctuation">,</span> <span class="token string">"two"</span><span class="token punctuation">,</span> <span class="token string">"three"</span><span class="token punctuation">,</span> <span class="token string">"four"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">mapUsingServiceAsync</span><span class="token punctuation">(</span>greeterService<span class="token punctuation">,</span> <span class="token punctuation">(</span>service<span class="token punctuation">,</span> input<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">{</span>
    <span class="token class-name">HelloRequest</span> request <span class="token operator">=</span> <span class="token class-name">HelloRequest</span><span class="token punctuation">.</span><span class="token function">newBuilder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setName</span><span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">return</span> service<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">logger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>In addition to the unary gRPC service, we support bidirectional
streaming as well as request batching. For a more in-depth look, see the
<a href="/docs/how-tos/grpc">Call a gRPC Service how-to guide</a> and the <a href="/docs/design-docs/007-grpc-support">design
document</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="transactional-jdbc-and-jms-sinks"></a><a href="#transactional-jdbc-and-jms-sinks" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Transactional JDBC and JMS sinks</h2>
<p>In Jet 4.0 we added support for <a href="/blog/2020/02/20/transactional-processors">transactional sources and
sinks</a> through the use of
two-phase commit. We're now extending this support for two additional
sinks: JDBC and JMS. The support requires the broker or the database to
support XA transactions. To test your database's support for XA
transactions, we've also released a <a href="/docs/how-tos/xa">how-to guide</a>.</p>
<p>You can also see a full summary of sinks and sources and the variety of
transaction support on the <a href="/docs/api/sources-sinks#summary">sources and sinks
page</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="code-deployment-improvements"></a><a href="#code-deployment-improvements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Code Deployment Improvements</h2>
<p>When you're deploying a Jet job programmatically (not using the <code>jet submit</code> command-line tool), you must add every class the job needs to
the job's configuration. So far, Jet has supported adding classes one by
one with <code>JobConfig.addClass()</code> and that wouldn't add any of the class's
nested classes. This was especially problematic for anonymous classes,
which you can't even refer to from Java code. In 4.1 we improved
<code>addClass()</code> so that it adds all the nested classes and we added
<code>JobConfig.addPackage()</code> so you can add the whole package in a
one-liner, and don't have to manually maintain the list of classes as
you develop your pipeline. Take a look at the <a href="/docs/design-docs/001-code-deployment-improvements">design
document</a> for more
details.</p>
<h2><a class="anchor" aria-hidden="true" id="job-scoped-serializer-support"></a><a href="#job-scoped-serializer-support" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Job-Scoped Serializer Support</h2>
<p>So far Jet has had a pain point in terms of serialization. The objects
that travel through the pipeline must sometimes be sent from one cluster
member to the other, so they must be serialized. You can let the object
implement <code>Serializable</code>, but that's inefficient. If you wanted to use
a better serialization scheme, you had to register a serializer object
with the Jet cluster and restart the whole cluster.</p>
<p>It is now possible to attach a serializer directly to the job you're
submitting.</p>
<pre><code class="hljs css language-java"><span class="token class-name">JobConfig</span> config <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JobConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">registerSerializer</span><span class="token punctuation">(</span><span class="token class-name">Person</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> <span class="token class-name">PersonSerializer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

jet<span class="token punctuation">.</span><span class="token function">newJob</span><span class="token punctuation">(</span>pipeline<span class="token punctuation">,</span> config<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>Jet will use these serializers only inside the job. You can read more
about how serialization in Hazelcast Jet works in the <a href="/docs/api/serialization">serialization
guide</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="protocol-buffers-support"></a><a href="#protocol-buffers-support" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Protocol Buffers Support</h2>
<p>Having added the job-level serializers, we also added an extra layer of
convenience to use <a href="https://developers.google.com/protocol-buffers">Google Protocol
Buffers</a> for
serialization. You just need to write a simple class that delegates the
work to the Protobuf compiler-generated serializer class (<code>Person</code> in
this case):</p>
<pre><code class="hljs css language-java"><span class="token keyword">class</span> <span class="token class-name">PersonSerializer</span> <span class="token keyword">extends</span> <span class="token class-name">ProtobufSerializer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Person</span><span class="token punctuation">></span></span> <span class="token punctuation">{</span>

    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> TYPE_ID <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>

    <span class="token class-name">PersonSerializer</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token class-name">Person</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">,</span> TYPE_ID<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<p>For more information, see the <a href="/docs/api/serialization#google-protocol-buffers">serialization guide</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="spring-boot-starter"></a><a href="#spring-boot-starter" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Spring Boot Starter</h2>
<p>Spring Boot is a framework that helps you create standalone Spring-based
applications that just run. Spring Boot provides auto-configuration of
some of the commonly used libraries through spring-boot-starters.
Hazelcast Jet now provides its own <a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/hazelcast-jet-spring-boot-starter">Spring Boot
Starter</a>
which can be used to auto-configure and start a Hazelcast Jet instance.</p>
<p>Just by adding the starter dependency to your Spring Boot application,
you can start a <code>JetInstance</code> with the default configuration. If you
want to customize the configuration, just add a configuration file
(<code>hazelcast-jet.yaml</code>) to your classpath or working directory. The
starter will pick it up and configure your Hazelcast Jet instance.  If
you want a client instance, add the client configuration file
(<code>hazelcast-client.yaml</code>).</p>
<p>For more details, see the <a href="/docs/design-docs/004-spring-boot-starter">design
document</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="kubernetes-operator-and-openshift-support"></a><a href="#kubernetes-operator-and-openshift-support" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Kubernetes Operator and OpenShift Support</h2>
<p>With version 4.1 we are introducing our <a href="https://operatorhub.io/?keyword=jet">Hazelcast Jet Kubernetes
Operator</a>. It's available for both
Hazelcast Jet open-source and Enterprise editions. Hazelcast Jet
Enterprise Operator is also a certified by Red Hat and available on the
Red Hat Marketplace.</p>
<h2><a class="anchor" aria-hidden="true" id="discovery-support-for-microsoft-azure"></a><a href="#discovery-support-for-microsoft-azure" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Discovery Support for Microsoft Azure</h2>
<p>We have extended the list of cloud environments where Hazelcast Jet
instances are able to automatically discover each other and form a
cluster. Self-discovery now works in the Microsoft Azure environment.
Here's a quick example on how to enable it:</p>
<pre><code class="hljs css language-yaml"><span class="hljs-attr">hazelcast:</span>
  <span class="hljs-attr">network:</span>
    <span class="hljs-attr">join:</span>
      <span class="hljs-attr">multicast:</span>
        <span class="hljs-attr">enabled:</span> <span class="hljs-literal">false</span>
      <span class="hljs-attr">azure:</span>
        <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span>
        <span class="hljs-attr">tag:</span> <span class="hljs-string">TAG-NAME=HZLCAST001</span>
        <span class="hljs-attr">hz-port:</span> <span class="hljs-number">5701</span><span class="hljs-number">-5703</span>
</code></pre>
<p>For more details, please see the <a href="/docs/operations/discovery#azure-cloud">discovery
guide</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="full-release-notes"></a><a href="#full-release-notes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Full Release Notes</h2>
<p>Members of the open source community that appear in these release notes:</p>
<ul>
<li>@TomaszGaweda</li>
<li>@caioguedes</li>
<li>@SapnaDerajeRadhakrishna</li>
</ul>
<p>Thank you for your valuable contributions!</p>
<h3><a class="anchor" aria-hidden="true" id="new-features"></a><a href="#new-features" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>New Features</h3>
<ul>
<li>[jms] Exactly-once guarantee for JMS sink (#1813)</li>
<li>[jdbc] Exactly-once guarantee for JDBC sink (#1813)</li>
<li>[core] JobConfig.addClass() automatically adds nested classes to the
job (#1932)</li>
<li>[core] JobConfig.addPackage() adds a whole Java package to the job
(#1932, #2077)</li>
<li>[core] Job-scoped serializer deployment (#2020, #2038, #2039, #2043,
#2071, #2075, #2082, #2190)</li>
<li>[core] [006] Protobuf serializer support (#2100)</li>
<li>[pipeline-api] [007] Support gRPC for mapUsingService (#2095, #2185)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="enhancements"></a><a href="#enhancements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Enhancements</h3>
<ul>
<li>[jet-cli] Use log4j2 instead of log4j (#1981)</li>
<li>[jet-cli] Simplify default log output (#2047)</li>
<li>[core] Add useful error message when serializer not registered (#2061)</li>
<li>[jet-cli] Add hazelcast-azure cluster self-discovery plugin to the
fat JAR in the distribution archive (#2079)</li>
<li>[pipeline-api] First-class support for inner hash join (@TomaszGaweda
#2089)</li>
<li>[core] When Jet starts up, it now logs the cluster name (@caioguedes
#2105)</li>
<li>[core] Add useful error message when trying to deploy a JDK class with
JobConfig (#2108)</li>
<li>[core] Implement JobConfig.toString (@SapnaDerajeRadhakrishna #2152)</li>
<li>[core] Do not destroy Observable on shutdown (#2170)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="fixes"></a><a href="#fixes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fixes</h3>
<ul>
<li>[core] Don't send the interrupt signal to blocking threads when a job
is terminating (#1971)</li>
<li>[core] Consistently prefer YAML over XML config files when both
present (#2033)</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="breaking-changes"></a><a href="#breaking-changes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Breaking Changes</h3>
<ul>
<li>[avro] Replace Supplier<Schema> with just Schema for Avro Sink (#2005)</li>
<li>[jms] Reorder parameters in JMS source so the lambda comes last
(#2062)</li>
<li>[jet-cli] Change smart routing (connecting to all cluster members)
default to disabled (#2104)</li>
<li>[pipeline-api] For xUsingServiceAsync transforms, reduce the default
number of concurrent service calls per processor. Before: 256; now: 4.
(#2204)</li>
</ul>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/04/01/upgrading-to-jet-40">Upgrading to Jet 4.0</a></h1><p class="post-meta">April 1, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/bjozsef/" target="_blank" rel="noreferrer noopener">Bartók József</a></p><div class="authorPhoto"><a href="https://www.linkedin.com/in/bjozsef/" target="_blank" rel="noreferrer noopener"><img src="https://www.itdays.ro/public/images/speakers-big/Jozsef_Bartok.jpg" alt="Bartók József"/></a></div></div></header><article class="post-content"><div><span><p>As we have announce earlier <a href="/blog/2020/03/02/jet-40-is-released">Jet 4.0 is out</a>!
In this blog post we aim to give you the lower level details needed for
migrating from older versions.</p>
<p>Jet 4.0 is a major version release. According to the semantic versioning
we apply, this means that in version 4.0 some of the API has changed in
a breaking way and code written for 3.x may no longer compile against
it.</p>
<h2><a class="anchor" aria-hidden="true" id="jet-on-imdg-40"></a><a href="#jet-on-imdg-40" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Jet on IMDG 4.0</h2>
<p>Jet 4.0 uses IMDG 4.0, which is also a major release with its own
breaking changes. For details see <a href="https://docs.hazelcast.org/docs/rn/index.html#4-0">IMDG Release Notes</a>
and <a href="https://docs.hazelcast.org/docs/4.0/manual/html-single/#migration-guides">IMDG Migration Guides</a>.</p>
<p>The most important changes we made and which have affected Jet too are
as follows:</p>
<ul>
<li><p>We renamed many packages and moved classes around. For details see the
<a href="https://docs.hazelcast.org/docs/rn/index.html#4-0">IMDG Release Notes</a>.
The most obvious change is that many classes that used to be in the
general <code>com.hazelcast.core</code> package are now in specific packages like
<code>com.hazelcast.map</code> or <code>com.hazelcast.collection</code>.</p></li>
<li><p><code>com.hazelcast.jet.function</code>, the package containing serializable
variants of <code>java.util.function</code>, is now merged into
<code>com.hazelcast.function</code>: <code>BiConsumerEx</code>, <code>BiFunctionEx</code>,
<code>BinaryOperatorEx</code>, <code>BiPredicateEx</code>, <code>ComparatorEx</code>, <code>ComparatorsEx</code>,
<code>ConsumerEx</code>, <code>FunctionEx</code>, <code>Functions</code>, <code>PredicateEx</code>, <code>SupplierEx</code>,
<code>ToDoubleFunctionEx</code>, <code>ToIntFunctionEx</code>, <code>ToLongFunctionEx</code>.</p></li>
<li><p><code>EntryProcessor</code> and several other classes and methods received a
cleanup of their type parameters. See the <a href="https://docs.hazelcast.org/docs/4.0/manual/html-single/#introducing-lambda-friendly-interfaces">relevant section</a>
in the IMDG Migration Guide.</p></li>
<li><p>The term &quot;group&quot; in configuration was replaced with &quot;cluster&quot;. See the
code snippet below for an example. This changes a Jet Command Line
parameter as well (<code>-g/--groupName</code> renamed to <code>-n/--cluster-name</code>).</p>
<pre><code class="hljs css language-java">clientConfig<span class="token punctuation">.</span><span class="token function">setClusterName</span><span class="token punctuation">(</span><span class="token string">"cluster_name"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//clientConfig.getGroupConfig().setName("cluster_name")</span>
</code></pre></li>
<li><p><code>EventJournalConfig</code> moved from the top-level Config class to data
structure-specific configs (<code>MapConfig</code>, <code>CacheConfig</code>):</p>
<pre><code class="hljs css language-java">config<span class="token punctuation">.</span><span class="token function">getMapConfig</span><span class="token punctuation">(</span><span class="token string">"map_name"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getEventJournalConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//config.getMapEventJournalConfig("map_name")</span>
</code></pre></li>
<li><p><code>ICompletableFuture</code> was removed and replaced with the JDK-standard
<code>CompletionStage</code>. This affects the return type of async methods. See
the <a href="https://docs.hazelcast.org/docs/4.0/manual/html-single/#removal-of-icompletablefuture">relevant section</a>
in the IMDG Migration Guide.</p></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="jet-api-changes"></a><a href="#jet-api-changes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Jet API Changes</h2>
<p>We made multiple breaking changes in Jet’s own APIs too:</p>
<ul>
<li><p><code>IMapJet</code>, <code>ICacheJet</code> and <code>IListJet</code>, which used to be Jet-specific
wrappers around IMDG’s standard <code>IMap</code>, <code>ICache</code> and <code>IList</code>, were
removed. The methods that used to return these types now return the
standard ones.</p></li>
<li><p>Renamed <code>Pipeline.drawFrom</code> to <code>Pipeline.readFrom</code> and
<code>GeneralStage.drainTo</code> to <code>GeneralStage.writeTo</code>:</p>
<pre><code class="hljs css language-java">pipeline<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">TestSources</span><span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">logger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//pipeline.drawFrom(TestSources.items(1, 2, 3)).drainTo(Sinks.logger());</span>
</code></pre></li>
<li><p><code>ContextFactory</code> was renamed to <code>ServiceFactory</code> and we added support
for instance-wide initialization. createFn now takes
<code>ProcessorSupplier.Context</code> instead of just <code>JetInstance</code>. We also
added convenience methods in <code>ServiceFactories</code> to simplify
constructing the common variants:</p>
<pre><code class="hljs css language-java"><span class="token class-name">ServiceFactories</span><span class="token punctuation">.</span><span class="token function">sharedService</span><span class="token punctuation">(</span>ctx <span class="token operator">-></span> <span class="token class-name">Executors</span><span class="token punctuation">.</span><span class="token function">newFixedThreadPool</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token class-name">ExecutorService</span><span class="token operator">::</span><span class="token function">shutdown</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//ContextFactory.withCreateFn(jet -> Executors.newFixedThreadPool(8)).withLocalSharing();</span>

<span class="token class-name">ServiceFactories</span><span class="token punctuation">.</span><span class="token function">nonSharedService</span><span class="token punctuation">(</span>ctx <span class="token operator">-></span> <span class="token class-name">DateTimeFormatter</span><span class="token punctuation">.</span><span class="token function">ofPattern</span><span class="token punctuation">(</span><span class="token string">"HH:mm:ss.SSS"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token class-name">ConsumerEx</span><span class="token punctuation">.</span><span class="token function">noop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//ContextFactory.withCreateFn(jet -> DateTimeFormatter.ofPattern("HH:mm:ss.SSS"))</span>
</code></pre></li>
<li><p><code>map/filter/flatMapUsingContext</code> was renamed to
<code>map/filter/flatMapUsingService</code>:</p>
<pre><code class="hljs css language-java">pipeline<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">TestSources</span><span class="token punctuation">.</span><span class="token function">items</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">filterUsingService</span><span class="token punctuation">(</span>
                <span class="token class-name">ServiceFactories</span><span class="token punctuation">.</span><span class="token function">sharedService</span><span class="token punctuation">(</span>pctx <span class="token operator">-></span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token punctuation">(</span>svc<span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token operator">-></span> i <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> svc<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">logger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/*
pipeline.drawFrom(TestSources.items(1, 2, 3))
        .filterUsingContext(
                ContextFactory.withCreateFn(i -> 1),
                (ctx, i) -> i % 2 == ctx)
        .drainTo(Sinks.logger());
*/</span>
</code></pre></li>
<li><p><code>filterUsingServiceAsync</code> has been removed. Usages can be replaced
with <code>mapUsingServiceAsync</code>, which behaves like a filter if it returns
a <code>null</code> future or the returned future contains a <code>null</code> result:</p>
<pre><code class="hljs css language-java">stage<span class="token punctuation">.</span><span class="token function">mapUsingServiceAsync</span><span class="token punctuation">(</span>serviceFactory<span class="token punctuation">,</span>
        <span class="token punctuation">(</span>executor<span class="token punctuation">,</span> item<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">{</span>
            <span class="token class-name">CompletableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">></span></span> f <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">CompletableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            executor<span class="token punctuation">.</span><span class="token function">submit</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> f<span class="token punctuation">.</span><span class="token function">complete</span><span class="token punctuation">(</span>item <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">?</span> item <span class="token operator">:</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">return</span> f<span class="token punctuation">;</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">/*
stage.filterUsingServiceAsync(serviceFactory,
        (executor, item) -> {
            CompletableFuture&lt;Boolean> f = new CompletableFuture&lt;>();
            executor.submit(() -> f.complete(item % 2 == 0));
            return f;
        });
*/</span>
</code></pre></li>
<li><p><code>flatMapUsingServiceAsync</code> has been removed. Usages can be replaced
with <code>mapUsingServiceAsync</code> followed by non-async <code>flatMap</code>:</p>
<pre><code class="hljs css language-java">stage<span class="token punctuation">.</span><span class="token function">mapUsingServiceAsync</span><span class="token punctuation">(</span>serviceFactory<span class="token punctuation">,</span>
        <span class="token punctuation">(</span>executor<span class="token punctuation">,</span> item<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">{</span>
            <span class="token class-name">CompletableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">List</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span><span class="token punctuation">></span></span> f <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">CompletableFuture</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            executor<span class="token punctuation">.</span><span class="token function">submit</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> f<span class="token punctuation">.</span><span class="token function">complete</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span>item <span class="token operator">+</span> <span class="token string">"-1"</span><span class="token punctuation">,</span> item <span class="token operator">+</span> <span class="token string">"-2"</span><span class="token punctuation">,</span> item <span class="token operator">+</span> <span class="token string">"-3"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">return</span> f<span class="token punctuation">;</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">Traversers</span><span class="token operator">::</span><span class="token function">traverseIterable</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">/*
stage.flatMapUsingServiceAsync(serviceFactory,
        (executor, item) -> {
            CompletableFuture&lt;Traverser&lt;String>> f = new CompletableFuture&lt;>();
            executor.submit(() -> f.complete(traverseItems(item + "-1", item + "-2", item + "-3")));
            return f;
        })
*/</span>
</code></pre></li>
<li><p>The methods <code>withMaxPendingCallsPerProcessor(int)</code> and
<code>withUnorderedAsyncResponses()</code> were removed from <code>ServiceFactory</code>.
These properties are relevant only in the context of asynchronous
operations and were used in conjunction with
<code>GeneralStage.mapUsingServiceAsync(…)</code>. In Jet 4.0 the
<code>GeneralStage.mapUsingServiceAsync(…)</code> method has a new variant with
explicit parameters for the above settings:</p>
<pre><code class="hljs css language-java">stage<span class="token punctuation">.</span><span class="token function">mapUsingServiceAsync</span><span class="token punctuation">(</span>
        <span class="token class-name">ServiceFactories</span><span class="token punctuation">.</span><span class="token function">sharedService</span><span class="token punctuation">(</span>ctx <span class="token operator">-></span> <span class="token class-name">Executors</span><span class="token punctuation">.</span><span class="token function">newFixedThreadPool</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token number">2</span><span class="token punctuation">,</span>
        <span class="token boolean">false</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span>exec<span class="token punctuation">,</span> task<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token class-name">CompletableFuture</span><span class="token punctuation">.</span><span class="token function">supplyAsync</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> task<span class="token punctuation">,</span> exec<span class="token punctuation">)</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/*
stage.mapUsingContextAsync(
        ContextFactory.withCreateFn(jet -> Executors.newFixedThreadPool(8))
                .withMaxPendingCallsPerProcessor(2)
                .withUnorderedAsyncResponses(),
        (exec, task) -> CompletableFuture.supplyAsync(() -> task, exec)
);
*/</span>
</code></pre></li>
<li><p><code>com.hazelcast.jet.pipeline.Sinks#mapWithEntryProcessor</code> got a new
signature in order to accommodate the improved <code>EntryProcessor</code>, which
became more lambda-friendly in IMDG (see the <a href="https://docs.hazelcast.org/docs/4.0/manual/html-single/#introducing-lambda-friendly-interfaces">relevant section</a>
in the IMDG Migration Guide). The return type of <code>EntryProcessor</code> is
now an explicit parameter in <code>mapWithEntryProcessor</code>'s method
signature:</p>
<pre><code class="hljs css language-java"><span class="token class-name">FunctionEx</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Map<span class="token punctuation">.</span>Entry</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">EntryProcessor</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Void</span><span class="token punctuation">></span><span class="token punctuation">></span></span> entryProcFn <span class="token operator">=</span>
        entry <span class="token operator">-></span>
                <span class="token punctuation">(</span><span class="token class-name">EntryProcessor</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">,</span> <span class="token class-name">Void</span><span class="token punctuation">></span></span><span class="token punctuation">)</span> e <span class="token operator">-></span> <span class="token punctuation">{</span>
                    e<span class="token punctuation">.</span><span class="token function">setValue</span><span class="token punctuation">(</span>e<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">?</span> <span class="token number">1</span> <span class="token operator">:</span> e<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token keyword">return</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span><span class="token punctuation">;</span>
<span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">mapWithEntryProcessor</span><span class="token punctuation">(</span>map<span class="token punctuation">,</span> <span class="token class-name">Map<span class="token punctuation">.</span>Entry</span><span class="token operator">::</span><span class="token function">getKey</span><span class="token punctuation">,</span> entryProcFn<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/*
FunctionEx&lt;Map.Entry&lt;String, Integer>, EntryProcessor&lt;String, Integer>> entryProcFn =
        entry ->
                (EntryProcessor&lt;String, Integer>) e -> {
                    e.setValue(e.getValue() == null ? 1 : e.getValue() + 1);
                    return null;
                };
Sinks.mapWithEntryProcessor(map, Map.Entry::getKey, entryProcFn);
*/</span>
</code></pre></li>
<li><p>HDFS source and sink methods are now <code>Hadoop.inputFormat</code> and
<code>Hadoop.outputFormat</code>.</p></li>
<li><p><code>MetricsConfig</code> is no longer part of <code>JetConfig</code>, but resides in the
IMDG <code>Config</code> class:</p>
<pre><code class="hljs css language-java">jetConfig<span class="token punctuation">.</span><span class="token function">getHazelcastConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getMetricsConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setCollectionFrequencySeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//jetConfig.getMetricsConfig().setCollectionIntervalSeconds(1);</span>
</code></pre></li>
<li><p><code>Traverser</code> type got a slight change in the <code>flatMap</code> lambda’s generic
type wildcards. This change shouldn’t affect anything in practice.</p></li>
<li><p>In sources and sinks we changed the method signatures so that the
lambda becomes the last parameter, where applicable.</p></li>
<li><p><code>JetBootstrap.getInstance()</code> moved to <code>Jet.bootstrappedInstance()</code> and
now it automatically creates an isolated local instance when not
running through <code>jet submit</code>. If used from <code>jet submit</code>, the behaviour
remains the same.</p></li>
<li><p><code>JobConfig.addResource(…)</code> is now <code>addClasspathResource(…)</code>.</p></li>
<li><p><code>ResourceType</code>, <code>ResourceConfig</code> and <code>JobConfig.getResourceConfigs()</code>
are now labeled as private API and we discourage their direct usage.
We also renamed <code>ResourceType.REGULAR_FILE</code> to <code>ResourceType.FILE</code>,
but this is now an internal change.</p></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="further-help"></a><a href="#further-help" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Further help</h2>
<p>In case you encounter any difficulties with migrating to Jet 4.0 feel
free to <a href="https://gitter.im/hazelcast/hazelcast-jet">contact us any time</a>.</p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/03/30/ml-inference">Machine Learning Inference at Scale</a></h1><p class="post-meta">March 30, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/voloda" target="_blank" rel="noreferrer noopener">Vladimir Schreiner</a></p><div class="authorPhoto"><a href="https://twitter.com/voloda" target="_blank" rel="noreferrer noopener"><img src="https://3l0wd94f0qdd10om8642z9se-wpengine.netdna-ssl.com/wp-content/uploads/2018/10/speaker-vladimir-schreiner-e1551380845855-170x170.jpg" alt="Vladimir Schreiner"/></a></div></div></header><article class="post-content"><div><span><p>Machine learning projects can be split into two phases:</p>
<ul>
<li>Training</li>
<li>Inference</li>
</ul>
<p>During the training phase, data science teams have to obtain, analyze
and understand available data and generalize it into a mathematical
model. The model uses the features of the sample data to reason about
data it has never seen. Although it can be completely custom code, it is
usually based on proven machine learning algorithms, such as Naïve
Bayes, K Means, Linear Regression, Deep Learning, Random Forests or
Decision Trees. The act of building the model from the sample (training)
data is referred to as training.</p>
<p>The inference phase refers to using the model to predict an unknown
property of the input data. This requires deploying the model into a
production environment and operating it.</p>
<h2><a class="anchor" aria-hidden="true" id="operating-machine-learning"></a><a href="#operating-machine-learning" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Operating Machine Learning</h2>
<p>The most straightforward way to deploy the model is to wrap it in a REST
web service and let other applications remotely invoke the inference
service. Many machine learning frameworks provide such a service
out-of-the-box to support simple deployments that don’t deal with much
data.</p>
<p>What Hazelcast Jet adds to this story is a simple way to deploy the
model so that it is automatically parallelized and scaled out across a
cluster of machines.</p>
<p><img src="/blog/assets/2020-03-30-parallel-inference.png" alt="Parallel ML inference"></p>
<p>Jet uses its parallel, distributed and resilient execution engine to
turn the model into a high-performance inference service. To use all
available CPU cores, Jet spins up multiple parallel instances of the
model and spreads the inference requests among them. The Jet cluster is
elastic; to scale with the workload, add or remove cluster members on
the fly with no downtime.</p>
<p>Another trick is using a <em>pipelined</em> design instead of a request-reply
pattern. It allows Jet to batch inference requests together and reduce
fixed overheads of serving each request individually. This improves the
overall throughput of the model significantly! The pipelined design
requires a change in the client’s workflow. Instead of calling the
inference service directly, it sends its inference request to an inbox.
It may be implemented using a message broker such as JMS topic, Kafka or
distributed topic of Hazelcast. Jet watches the inbox and groups
multiple requests together to use the model service efficiently. It uses
<a href="https://mechanical-sympathy.blogspot.com/2011/10/smart-batching.html">smart
batching</a>
where the batch size changes with the data volume to keep the latency
always low. The inference results are published to an outbox for callers
to pick it up.</p>
<h2><a class="anchor" aria-hidden="true" id="models-supported"></a><a href="#models-supported" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Models Supported</h2>
<h3><a class="anchor" aria-hidden="true" id="python-models"></a><a href="#python-models" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Python models</h3>
<p>Python is the lingua franca of the data science world. There is a wide
ecosystem of libraries and tools to build and train models in Python:
<a href="https://www.tensorflow.org/">TensorFlow</a>, <a href="https://keras.io/">Keras</a>,
<a href="http://deeplearning.net/software/theano/">Theano</a>,
<a href="https://scikit-learn.org/stable/">Scikit-learn</a> or
<a href="https://pytorch.org/">PyTorch</a> to name a few. Jet can host any Python
model.</p>
<p>Upon model deployment, Jet’s JVM runtime launches Python processes and
establishes bi-directional gRPC communication channels to stream
inference requests through it. So, the model runs natively in a Python
process that is completely managed by Jet. It can be tuned to spin
multiple Python processes on each machine to make use of multicore
processors.</p>
<p>Jet makes sure that the Python code is distributed to all machines that
participate in the cluster. If you add another machine to a Jet cluster,
it creates a directory on it and deploys the Python code there.
Moreover, Jet can install all required Python libraries to prepare the
runtime for your Python model.</p>
<p>Documentation:
<a href="https://docs.hazelcast.org/docs/jet/latest/manual/#map-using-python">https://docs.hazelcast.org/docs/jet/latest/manual/#map-using-python</a></p>
<p>Code sample:
<a href="https://github.com/hazelcast/hazelcast-jet/tree/master/examples/python">https://github.com/hazelcast/hazelcast-jet/tree/master/examples/python</a></p>
<p><img src="/blog/assets/2020-03-30-python-vms.svg" alt="Python integration architecture"></p>
<h3><a class="anchor" aria-hidden="true" id="java-models"></a><a href="#java-models" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Java models</h3>
<p>Java models are used for high-performance inference execution. Favourite
Java model libraries include
<a href="https://github.com/jpmml/jpmml-evaluator">JPMML</a>, <a href="https://www.tensorflow.org/install/lang_java">TensorFlow for
Java</a>,
<a href="https://mxnet.apache.org/api/java">MXNet</a>, <a href="https://xgboost.readthedocs.io/en/latest/jvm/index.html">XGBoost JVM
Package</a> and
<a href="https://www.h2o.ai/">H20</a>.</p>
<p>Similarly to Python, the model is packaged as a Jet Job resource. The
Job usually includes model inference code (the ML library) and a
serialized model. Jet runs the Java models in-process with the cluster
members so there is no need to start extra processes and there is no
communication overhead (serialization, deserialization, networking).
This makes Java model the best performing option. The inference job can
be configured to use one model instance per JVM or multiple model
instances.</p>
<p>Documentation:
<a href="https://docs.hazelcast.org/docs/jet/latest/manual/#machine-learning-model-prediction">https://docs.hazelcast.org/docs/jet/latest/manual/#machine-learning-model-prediction</a></p>
<p>Code samples:</p>
<ul>
<li><a href="https://github.com/hazelcast/hazelcast-jet-demos/tree/master/h2o-breast-cancer-classification">H2O Model</a></li>
<li><a href="https://github.com/hazelcast/hazelcast-jet-demos/tree/master/tensorflow">TensorFlow Model</a></li>
<li><a href="https://github.com/hazelcast/hazelcast-jet-demos/tree/master/realtime-image-recognition">Custom Java Model</a></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="remote-services"></a><a href="#remote-services" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Remote services</h3>
<p>We started this article by saying that using a model as an RPC service
is simple but requires extra effort when scaling. Jet supports this
pattern, too. The Jet Job can invoke a remote inference service. The
model isn’t managed by Jet in this case, so the operational and
performance advantages are gone. Jet still provides the convenience of
smart batching, inbox/outbox <a href="/docs/api/sources-sinks">connectors</a> and
many <a href="/docs/api/pipeline#types-of-transforms">pipeline operators</a>. Smart
batching works only if the RPC service can operate on batches of input
items.</p>
<p>Benefits of this setup</p>
<ul>
<li>Isolating the model service and the data pipeline</li>
<li>Sharing the model among many Jet pipelines</li>
</ul>
<p>Code samples:</p>
<ul>
<li><a href="https://github.com/hazelcast/hazelcast-jet/tree/master/examples/grpc">Invoking remote gRPC service</a></li>
<li><a href="https://github.com/hazelcast/hazelcast-jet-demos/tree/master/tensorflow">Remote TensorFlow</a></li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="execution-mode-overview"></a><a href="#execution-mode-overview" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Execution Mode Overview</h3>
<table>
<thead>
<tr><th>Execution Mode</th><th>Java Model</th><th>Python Model</th><th>Remote Model</th></tr>
</thead>
<tbody>
<tr><td>Model managed by Jet</td><td>✅</td><td>✅</td><td>✅</td></tr>
<tr><td>Model shared between Jobs</td><td>❌</td><td>❌</td><td>✅</td></tr>
<tr><td>Jet ↔ Model Communication</td><td>Shared memory</td><td>gRPC<br>(processes collocated)</td><td>RPC<br>(processes usually on different machines)</td></tr>
<tr><td>Throughput (single node)</td><td>1M / sec</td><td>50k / sec</td><td>Depends on underlying architecture</td></tr>
<tr><td>Prerequisites</td><td>Model runs in JVM</td><td>Python runtime installed on all cluster machines</td><td>Model available as a RPC service</td></tr>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" id="framework-integration-overview"></a><a href="#framework-integration-overview" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Framework Integration Overview</h3>
<table>
<thead>
<tr><th>Framework</th><th>Execution Mode</th><th>Code Sample</th></tr>
</thead>
<tbody>
<tr><td>H2O</td><td>Java</td><td><a href="https://github.com/hazelcast/hazelcast-jet-demos/tree/master/h2o-breast-cancer-classification">Code Sample</a></td></tr>
<tr><td>TensorFlow for Java</td><td>Java</td><td><a href="https://github.com/hazelcast/hazelcast-jet-demos/blob/master/tensorflow/src/main/java/InProcessClassification.java">Code Sample</a></td></tr>
<tr><td>Custom Java Model</td><td>Java</td><td><a href="https://github.com/hazelcast/hazelcast-jet-demos/tree/master/realtime-image-recognition">Code Sample</a></td></tr>
<tr><td>PMML</td><td>Java</td><td>N/A, use <a href="https://github.com/jpmml/jpmml-evaluator">JPMML Evaluator</a> as a Custom Java Model</td></tr>
<tr><td>MXNet</td><td>Java</td><td>N/A, use <a href="https://mxnet.apache.org/api/java.html">MXNet Java Inference API</a> as a Custom Java Model</td></tr>
<tr><td>XGBoost</td><td>Java</td><td>N/A, use <a href="https://xgboost.readthedocs.io/en/latest/jvm/index.html">XGBoost JVM Package</a> as a Custom Java Model</td></tr>
<tr><td><a href="https://keras.io/">Keras</a>, <a href="http://deeplearning.net/software/theano/">Theano</a>, <a href="https://scikit-learn.org/stable/">Scikit-learn</a> or <a href="https://pytorch.org/">PyTorch</a></td><td>Python</td><td>N/A, use the <a href="https://github.com/hazelcast/hazelcast-jet/tree/master/examples/python">Custom Python Model</a></td></tr>
<tr><td>Custom Python Model</td><td>Python</td><td><a href="https://github.com/hazelcast/hazelcast-jet/tree/master/examples/python">Code Sample</a></td></tr>
<tr><td>Remote gRPC service</td><td>Remote</td><td><a href="https://github.com/hazelcast/hazelcast-jet/tree/master/examples/grpc">Code Sample</a></td></tr>
<tr><td>Remote TensorFlow service</td><td>Remote</td><td><a href="https://github.com/hazelcast/hazelcast-jet-demos/blob/master/tensorflow/src/main/java/ModelServerClassification.java">Code Sample</a></td></tr>
</tbody>
</table>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/03/02/jet-40-is-released">Jet 4.0 is Released</a></h1><p class="post-meta">March 2, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="http://twitter.com/cgencer" target="_blank" rel="noreferrer noopener">Can Gencer</a></p><div class="authorPhoto"><a href="http://twitter.com/cgencer" target="_blank" rel="noreferrer noopener"><img src="https://pbs.twimg.com/profile_images/1187734846749196288/elqWdrPj_400x400.jpg" alt="Can Gencer"/></a></div></div></header><article class="post-content"><div><span><p>We're happy to introduce the release of Jet 4.0 which brings several new
features. This release was a big effort and a total of <a href="https://github.com/hazelcast/hazelcast-jet/pulls?q=is%3Apr+milestone%3A4.0">230
PRs</a>
were merged, making it one of our biggest in terms of new features.</p>
<h2><a class="anchor" aria-hidden="true" id="distributed-transactions"></a><a href="#distributed-transactions" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Distributed Transactions</h2>
<p>Jet previously had first-class support for fault tolerance through an
implementation of the <a href="https://lamport.azurewebsites.net/pubs/chandy.pdf">Chandy-Lamport distributed snapshotting</a>
algorithm which requires participation from the whole pipeline,
including sources and sinks. Previously, the at-least-once and
exactly-once processing guarantees were only limited to replayable
sources such as Kafka. Jet 4.0 comes with a full two-phase commit (2PC)
implementation which makes it possible to have end-to-end exactly-once
processing with acknowledgement-based sources such as JMS. Jet is now
also able to work with transactional sinks to avoid duplicate writes, and
this version adds transactional file and Kafka sinks, with transactional
JMS and JDBC sinks utilizing XA transactions coming in the next release.</p>
<p>We will have additional posts about this topic in the future detailing
the mechanism and also results of our tests done with 2PC for various
message brokers and databases.</p>
<h2><a class="anchor" aria-hidden="true" id="python-user-defined-functions"></a><a href="#python-user-defined-functions" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Python User-Defined Functions</h2>
<p>Python is a popular language with a very large ecosystem of libraries,
and has especially become popular in the domain of data processing and
machine learning. Jet itself is a data processing framework for both
streams and batches of data, but the API for defining the pipeline
itself has been previously limited to Java and Java functions only.</p>
<p>In this version we have added a native way to execute Python code within
a Jet pipeline. Jet can now spawn separate Python processes on
each node which communicate back using
<a href="https://github.com/hazelcast/hazelcast-jet-demos/tree/master/debezium-cdc-without-kafka">gRPC</a>.
The processes are fully managed by Jet and can make use of techniques
such as smart batching of events.</p>
<p>The user defines a mapping stage which takes an input item, and
transforms it using a supplied Python function. The function can make
use of libraries such as scikit, numpy and many others. This makes it
possible to use Jet for deploying ML models into production. For
example, given this pipeline:</p>
<pre><code class="hljs css language-java"><span class="token class-name">Pipeline</span> p <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">TestSources</span><span class="token punctuation">.</span><span class="token function">itemStream</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>ts<span class="token punctuation">,</span> seq<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token function">bigRandomNumberAsString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token function">mapUsingPython</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">PythonServiceConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token punctuation">.</span><span class="token function">setBaseDir</span><span class="token punctuation">(</span>baseDir<span class="token punctuation">)</span>
            <span class="token punctuation">.</span><span class="token function">setHandlerModule</span><span class="token punctuation">(</span><span class="token string">"take_sqrt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">observable</span><span class="token punctuation">(</span>RESULTS<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>The user only has to supply the following Python function:</p>
<pre><code class="hljs css language-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">transform_list</span><span class="hljs-params">(input_list)</span>:</span>
    <span class="hljs-string">"""
    Uses NumPy to transform a list of numbers into a list of their square
    roots.

    :param input_list: the list with input items
    :return: the list with input items' square roots
    """</span>
    num_list = [float(it) <span class="hljs-keyword">for</span> it <span class="hljs-keyword">in</span> input_list]
    sqrt_list = np.sqrt(num_list)
    <span class="hljs-keyword">return</span> [str(it) <span class="hljs-keyword">for</span> it <span class="hljs-keyword">in</span> sqrt_list]
</code></pre>
<p>For a more in-depth discussion on this topic, I recommend Jet Core
Engineer Marko Topolnik's presentation,
<a href="https://www.youtube.com/watch?v=q1vBbqxnJIQ">Deploying ML models at scale</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="observables"></a><a href="#observables" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Observables</h2>
<p>When you submit a Jet pipeline, typically it reads the data from a
source and writes to a sink (such as a <code>IMap</code>). When the submitter of
the pipeline wants to read the results, the sink must be read outside of
the pipeline, which is not always very convenient.</p>
<p>In Jet 4.0, a new sink type called <code>Observable</code> is added which can be
used to publish messages directly to the caller. It utilizes a Hazelcast
Ringbuffer as the underlying data store which allows the decoupling of
the producer and consumer.</p>
<pre><code class="hljs css language-java"><span class="token class-name">Observable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">SimpleEvent</span><span class="token punctuation">></span></span> o <span class="token operator">=</span> jet<span class="token punctuation">.</span><span class="token function">newObservable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
o<span class="token punctuation">.</span><span class="token function">addObserver</span><span class="token punctuation">(</span>event <span class="token operator">-></span> <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">TestSources</span><span class="token punctuation">.</span><span class="token function">itemStream</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">observable</span><span class="token punctuation">(</span>o<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
jet<span class="token punctuation">.</span><span class="token function">newJob</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>The <code>Observable</code> can also be used to be notified of a job's completion
and any errors that may occur during processing.</p>
<h2><a class="anchor" aria-hidden="true" id="custom-metrics"></a><a href="#custom-metrics" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Custom Metrics</h2>
<p>Over the last few releases we've been improving the metrics support in
Jet, such as being able to get metrics directly from running or
completed jobs through the use of <code>Job.getMetrics()</code>. In this release,
we've made it possible to also add your own custom metrics into a
pipeline through the use of a simple API:</p>
<pre><code class="hljs css language-java">p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">TestSources</span><span class="token punctuation">.</span><span class="token function">itemStream</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>event <span class="token operator">-></span> <span class="token punctuation">{</span>
     <span class="token keyword">if</span> <span class="token punctuation">(</span>event<span class="token punctuation">.</span><span class="token function">sequence</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
         <span class="token class-name">Metrics</span><span class="token punctuation">.</span><span class="token function">metric</span><span class="token punctuation">(</span><span class="token string">"numEvens"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">increment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token keyword">return</span> event<span class="token punctuation">;</span>
 <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">logger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>These custom metrics will then be available as part of
<code>Job.getMetrics()</code> or through JMX along with the rest of the metrics.</p>
<h2><a class="anchor" aria-hidden="true" id="debezium-kafka-connect-and-twitter-connectors"></a><a href="#debezium-kafka-connect-and-twitter-connectors" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Debezium, Kafka Connect and Twitter Connectors</h2>
<p>As part of Jet 4.0, we're releasing three new connectors:</p>
<h3><a class="anchor" aria-hidden="true" id="debezium"></a><a href="#debezium" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Debezium</h3>
<p>Debezium is a Change Data Capture (CDC) platform and the new
<a href="https://debezium.io/">Debezium</a> connector for Jet allows you to stream
changes directly from databases such as MySQL and PostgreSQL without
requiring any other dependencies.</p>
<p>Although Debezium typically requires use of Kafka and Kafka Connect, the
native Jet integration means you can directly stream changes without
having to use Kafka. The integration also supports fault-tolerance so
that when a Jet job is scaled up or down, old changes do not need to
replayed.</p>
<p>This makes it suitable to build an end-to-end solution where for example
an in-memory cache supported by <code>IMap</code> is always kept up to date with the
latest changes in the database.</p>
<pre><code class="hljs css language-java"><span class="token class-name">Configuration</span> configuration <span class="token operator">=</span> <span class="token class-name">Configuration</span>
        <span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span> <span class="token string">"mysql-inventory-connector"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token string">"connector.class"</span><span class="token punctuation">,</span> <span class="token string">"io.debezium.connector.mysql.MySqlConnector"</span><span class="token punctuation">)</span>
        <span class="token comment">/* begin connector properties */</span>
        <span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token string">"database.hostname"</span><span class="token punctuation">,</span> mysql<span class="token punctuation">.</span><span class="token function">getContainerIpAddress</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token string">"database.port"</span><span class="token punctuation">,</span> mysql<span class="token punctuation">.</span><span class="token function">getMappedPort</span><span class="token punctuation">(</span>MYSQL_PORT<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token string">"database.user"</span><span class="token punctuation">,</span> <span class="token string">"debezium"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token string">"database.password"</span><span class="token punctuation">,</span> <span class="token string">"dbz"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token string">"database.server.id"</span><span class="token punctuation">,</span> <span class="token string">"184054"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token string">"database.server.name"</span><span class="token punctuation">,</span> <span class="token string">"dbserver1"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token string">"database.whitelist"</span><span class="token punctuation">,</span> <span class="token string">"inventory"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token keyword">with</span><span class="token punctuation">(</span><span class="token string">"database.history.hazelcast.list.name"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">Pipeline</span> p <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span><span class="token class-name">DebeziumSources</span><span class="token punctuation">.</span><span class="token function">cdc</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token keyword">record</span> <span class="token operator">-></span> <span class="token class-name">Values</span><span class="token punctuation">.</span><span class="token function">convertToString</span><span class="token punctuation">(</span><span class="token keyword">record</span><span class="token punctuation">.</span><span class="token function">valueSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">record</span><span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">logger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>The Debezium connector is currently available in the
<a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/debezium">hazelcast-jet-contrib repository</a>,
along with a <a href="https://github.com/hazelcast/hazelcast-jet-demos/tree/master/debezium-cdc-without-kafka">demo application</a>.</p>
<h3><a class="anchor" aria-hidden="true" id="kafka-connect"></a><a href="#kafka-connect" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Kafka Connect</h3>
<p>The <a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/kafka-connect">Kafka Connect source</a>
allows you to use any existing Kafka Connect source and use it natively
with Jet, without requiring presence of a Kafka Cluster. The records
will be streamed as Jet events instead, which can be processed further
and it has full support for fault-tolerance and replaying. A full list
of connectors can be viewed through <a href="https://www.confluent.io/hub/">Confluent Hub</a>.</p>
<h3><a class="anchor" aria-hidden="true" id="twitter"></a><a href="#twitter" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Twitter</h3>
<p>We've also released a simple <a href="https://github.com/hazelcast/hazelcast-jet-contrib/tree/master/twitter">Twitter source</a>
that uses the Twitter client, which can be used to process a stream of
Tweets.</p>
<pre><code class="hljs css language-java"><span class="token class-name">Properties</span> credentials <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"consumerKey"</span><span class="token punctuation">,</span> <span class="token string">"???"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// OAuth1 Consumer Key</span>
properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"consumerSecret"</span><span class="token punctuation">,</span> <span class="token string">"???"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// OAuth1 Consumer Secret</span>
properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"token"</span><span class="token punctuation">,</span> <span class="token string">"???"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// OAuth1 Token</span>
properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"tokenSecret"</span><span class="token punctuation">,</span> <span class="token string">"???"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// OAuth1 Token Secret</span>
<span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> terms <span class="token operator">=</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"term1"</span><span class="token punctuation">,</span> <span class="token string">"term2"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">StreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> streamSource <span class="token operator">=</span>
             <span class="token class-name">TwitterSources</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span>credentials<span class="token punctuation">,</span>
                     <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token class-name">StatusesFilterEndpoint</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">trackTerms</span><span class="token punctuation">(</span>terms<span class="token punctuation">)</span>
             <span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Pipeline</span> p <span class="token operator">=</span> <span class="token class-name">Pipeline</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
p<span class="token punctuation">.</span><span class="token function">readFrom</span><span class="token punctuation">(</span>streamSource<span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">withoutTimestamps</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token function">writeTo</span><span class="token punctuation">(</span><span class="token class-name">Sinks</span><span class="token punctuation">.</span><span class="token function">logger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>These connectors are currently under incubation, and will be part of a
main release in the future.</p>
<h2><a class="anchor" aria-hidden="true" id="improved-jet-installation"></a><a href="#improved-jet-installation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Improved Jet Installation</h2>
<p>We've also made many improvements to the Jet installation package. It
has been cleaned up to reduce the size, and now supports the following:</p>
<ul>
<li>Default config format is now YAML and many of the common options are
in the default configuration.</li>
<li>A rolling file logger which writes to the log folder is now the
default logger</li>
<li>Support for daemon mode through <code>jet-start -d</code> switch.</li>
<li>Improved readme and a new &quot;hello world&quot; application which can be
submitted right after installation.</li>
<li>Improved JDK9+ support, to avoid illegal import warnings.</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="hazelcast-40"></a><a href="#hazelcast-40" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hazelcast 4.0</h2>
<p>Another major change that's worth noting is that Jet is now based on
Hazelcast 4.0 - which in itself was a major release and brought many new
features and technical improvements such as improved performance and
Intel Optane DC Support and encryption at rest.</p>
<h2><a class="anchor" aria-hidden="true" id="breaking-changes-and-migration-guide"></a><a href="#breaking-changes-and-migration-guide" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Breaking Changes and Migration Guide</h2>
<p>As part of 4.0, we've also done some house cleaning and as a result some
things have been moved around. All the changes are listed as part of the
<a href="/blog/2020/04/01/upgrading-to-jet-40">migration guide blog post</a>.</p>
<p>We are committed to backwards compatibility going forward and any
interfaces or classes which are subject to change will be marked as
<code>@Beta</code> or <code>@EvolvingApi</code> going forwards.</p>
<h2><a class="anchor" aria-hidden="true" id="wrapping-up"></a><a href="#wrapping-up" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Wrapping Up</h2>
<p>This is a big release for Hazelcast Jet, and we have many more exciting
features in the pipeline (pun intended), including SQL support, extended
support for 2PC, improved Serialization support, even more connectors,
Kubernetes Operators and many more. We will also be aiming to make
shorter, more frequent releases to bring new features to users quicker.</p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/02/20/transactional-processors">Transactional connectors in Hazelcast Jet</a></h1><p class="post-meta">February 20, 2020</p><div class="authorBlock"><p class="post-authorName"><a target="_blank" rel="noreferrer noopener">Viliam Ďurina</a></p><div class="authorPhoto"><a target="_blank" rel="noreferrer noopener"><img src="https://en.gravatar.com/userimage/154381144/a68feb9e86a976869d646e7cf7669510.jpg" alt="Viliam Ďurina"/></a></div></div></header><article class="post-content"><div><span><p><img src="/blog/assets/2020-02-20-transactional-processors-featured-img.png" alt="Transaction Processors Featured
Image"></p>
<p>Hazelcast Jet is a distributed stream processing engine which supports
exactly-once semantics even in the presence of cluster member failures.
This is achieved by snapshotting the internal state of the processors at
regular intervals into a reliable storage and then, in case of a
failure, using the latest snapshot to restore the state and continue.</p>
<p>However, the exactly-once guarantee didn't work with most of the
connectors. Only <a href="/docs/architecture/fault-tolerance">replayable
sources</a>,
such as Apache Kafka or IMap Journal were supported. And no sink
supported this level of guarantee. Why was that?</p>
<p>The original snapshot API had only one phase. A processor was asked to
save its state at regular intervals and that was it. But a sink writes
items to some external resource and must commit if the snapshot was
successful; and it must not commit if it wasn't. It also needs to ensure
that if some processor committed, all will commit, even in the presence
of failures. This is where distributed transactions come to the rescue.</p>
<h2><a class="anchor" aria-hidden="true" id="distributed-transactions"></a><a href="#distributed-transactions" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Distributed transactions</h2>
<p>Jet uses the two-phase commit algorithm to coordinate individual
transactions. The basic algorithm is simple:</p>
<ol>
<li><p>The coordinator asks all participants to prepare for commit</p></li>
<li><p>If all participants were successful, the coordinator asks them to
commit. Otherwise it asks all of them to roll back</p></li>
</ol>
<p>For correct functionality it is required that if a participant reported
success in the first phase, it must be able to commit when requested.</p>
<p>Jet acts as a transaction coordinator. Individual processors (that is
the parallel workers doing the writes) are adapters to actual
transactional resources, that is to databases, message queues etc. So
even if you have just one transactional connector in your pipeline, you
have multiple participants of a distributed transaction, one on each
cluster member.</p>
<h2><a class="anchor" aria-hidden="true" id="two-phase-snapshot-procedure"></a><a href="#two-phase-snapshot-procedure" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Two-phase snapshot procedure</h2>
<p>The commit procedure in Jet is tied to the life cycle of the snapshot.
When a snapshot is taken, the previous transaction is committed and a
new one is started. The snapshot also serves as the durable storage for
the coordinator.</p>
<p>Since Jet 4.0, the snapshot has two phases. In the first phase the
participants prepare, in the second phase they commit. Important thing
is that the snapshot is successful and can be used to restore the state
of a job after the 1st phase is successful. If the job fails before
executing the 2nd phase, that is without executing the commits, the
processors must be able to commit the transactions after the job
restart. To do so, they store transaction IDs to the snapshot. This is
the basic process:</p>
<ol>
<li><p>When a processor starts, it opens transaction <code>T0</code>. It writes
incoming items, but doesn't commit.</p></li>
<li><p>Later the processor is asked to do the 1st phase of the snapshot (the
<code>snapshotCommitPrepare()</code> method). The processor prepares <code>T0</code>,
stores its ID to the snapshot and starts <code>T1</code>.</p></li>
<li><p>Items that arrive until the 2nd phase occurs are handled using <code>T1</code>.</p></li>
<li><p>When a coordinator member receives responses from all processors that
they successfully did 1st phase, it marks the snapshot as successful
and initiates the phase-2.</p></li>
<li><p>Some time later the processor is asked to do the 2nd phase (the
<code>snapshotCommitFinish()</code> method). The processor now commits <code>T0</code> and
continues to use <code>T1</code> until the next snapshot.</p></li>
<li><p>The process repeats with incremented transaction ID.</p></li>
</ol>
<p>Keep in mind that a failure can occur at or between any of the above
steps and exactly-once guarantee must be preserved. If it occurs before
step 2, the transaction is just rolled back by the remote system when
the client disconnects.</p>
<p>If it occurs between steps 2-4, items in <code>T1</code> are are rolled back by the
remote system because the transaction wasn't prepared (the XA API
requires this). But there's also <code>T0</code> that is prepared, but not
committed. After the job restarts, it will restore from a previous
snapshot (step 4 wasn't yet executed), and since <code>T0</code> isn't found in the
restored state, it will be rolled back.</p>
<p>If the failure occurs after step 4, then after the job restarts, it will
try to commit all transaction IDs found in the restored state. So it
will try to commit <code>T0</code>. The commit must be idempotent: if that
transaction was already committed, it should do nothing, because we
don't know if the step 5 was executed or not.</p>
<h2><a class="anchor" aria-hidden="true" id="consistency-with-internal-state"></a><a href="#consistency-with-internal-state" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Consistency with internal state</h2>
<p>The 1st phase is common for transactional processors and for processors
that only save internal state. It is coordinated using the snapshot
barrier, based on the <a href="/docs/architecture/fault-tolerance#distributed-snapshot">Chandy-Lamport
algorithm</a>.
The consequence is that the moment at which internal processors save
their state and external processors prepare and switch their
transactions is the same. Therefore you can combine exactly-once stages
of any type in the pipeline and it will work seamlessly.</p>
<h2><a class="anchor" aria-hidden="true" id="transactions-are-needed-for-sources-too"></a><a href="#transactions-are-needed-for-sources-too" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Transactions are needed for sources too</h2>
<p>It might seem that since sources are designed to be read, we don’t need
anything to store. But, for example, some message systems use
acknowledgements, which are in fact writes: they change the state of the
message to consumed or they delete the message.</p>
<p>Jet supports JMS as a source. We’ve initially implemented the JMS source
using XA transactions, but it turned out that major brokers don’t
support it or the support is buggy. For example, ActiveMQ only delivers
a handful of messages to consumers and then stops
(<a href="https://issues.apache.org/jira/projects/AMQ/issues/AMQ-7369">issue</a>).
Artemis sometimes loses messages
(<a href="https://issues.apache.org/jira/projects/ARTEMIS/issues/ARTEMIS-2546">issue</a>).
RabbitMQ doesn't support two-phase transactions at all.</p>
<p>Therefore for JMS source we implemented a different strategy. We
acknowledge consumption in the 2nd phase of the snapshot. But if the job
fails after the snapshot is successful but before we manage to
acknowledge, already processed messages could be redelivered, so we
store the IDs of seen messages in the snapshot and then use that to
deduplicate. If you’re interested in details, check the <a href="https://github.com/hazelcast/hazelcast-jet/blob/master/hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/connector/StreamJmsP.java">source
code</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="real-life-issues"></a><a href="#real-life-issues" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Real-life issues</h2>
<p>As mentioned above, some brokers have incorrect or buggy XA
implementation. In other cases, prepared transactions are rolled back
when the client disconnects (for example in
<a href="https://jira.mariadb.org/browse/MDEV-742">MariaDB</a> or <a href="https://github.com/h2database/h2database/issues/2347">H2
Database</a>) - these
systems are not usable at all. On the contrary, other implementations
keep even non-prepared transactions, such as Artemis
(<a href="https://issues.apache.org/jira/browse/ARTEMIS-2559">issue</a>, fixed
recently). Artemis doesn't even return these transactions when calling
<code>recover()</code>, the XA API method to list prepared transactions, but those
transactions still exist and hold locks. Transaction interleaving is
mostly also not supported, this prevents us from doing any work while
waiting for the 2nd phase.</p>
<p>Apache Kafka, while having all the building blocks needed to implement
XA standard, has its own API. It also lacks a method to commit a
transaction after reconnection, but we’ve been able to do it by calling
a few <a href="https://github.com/hazelcast/hazelcast-jet/blob/master/extensions/kafka/src/main/java/com/hazelcast/jet/kafka/impl/ResumeTransactionUtil.java#L43-L64">private
methods</a>.
Also it binds transaction ID to the connection which forces us to have
multiple open connections.</p>
<h2><a class="anchor" aria-hidden="true" id="transaction-id-pool"></a><a href="#transaction-id-pool" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Transaction ID pool</h2>
<p>Due to the above real-life limitations in most connectors we use two
transaction IDs interchangeably per processor. This avoids the need for
the <code>recover()</code> method to list prepared transactions, which is
unreliable or missing. Instead, we just probe known transaction IDs for
existence.</p>
<p>This tactic also avoids the problem with Apache Kafka that it binds the
transaction ID to a connection: we keep a pool of 2 connections in each
processor instead and we don't have to open a new connection after each
snapshot.</p>
<p>All connectors except for the file sink use this approach, including the
JMS and JDBC sinks
<a href="https://github.com/hazelcast/hazelcast-jet/pull/1813">planned</a> for 4.1.</p>
<h2><a class="anchor" aria-hidden="true" id="conclusion"></a><a href="#conclusion" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conclusion</h2>
<p>The new feature allowed us to implement exactly-once guarantee for
sources and sinks where it previously wasn't possible. Even though these
kinds of connectors are not ideal for a distributed system because they
generally are not distributed, they still are very useful for
integration with existing systems. JMS source, Kafka sink and file sink
are available out-of-the-box in Jet 4.0.</p>
<p>If you consider writing your own exactly-once connector, currently you
have to implement the Core API <code>Processor</code> class. We consider
introducing some higher-level API in the future.</p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/01/28/new-website">Announcing New Documentation Website</a></h1><p class="post-meta">January 28, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="http://twitter.com/emndmrc" target="_blank" rel="noreferrer noopener">Emin Demirci</a></p><div class="authorPhoto"><a href="http://twitter.com/emndmrc" target="_blank" rel="noreferrer noopener"><img src="https://3l0wd94f0qdd10om8642z9se-wpengine.netdna-ssl.com/wp-content/uploads/2019/07/emin-demirci-170x170.png" alt="Emin Demirci"/></a></div></div></header><article class="post-content"><div><span><p>We are excited to tell you that we've just launched a new website for
Hazelcast Jet, where we share technical content regarding the project
including how-to-guides and technical design documents.</p>
<p>We'll keep this website frequently updated. Stay tuned!</p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2019/11/12/stream-deduplication">Stream Deduplication with Hazelcast Jet</a></h1><p class="post-meta">November 12, 2019</p><div class="authorBlock"><p class="post-authorName"><a href="https://twitter.com/jerrinot" target="_blank" rel="noreferrer noopener">Jaromir Hamala</a></p><div class="authorPhoto"><a href="https://twitter.com/jerrinot" target="_blank" rel="noreferrer noopener"><img src="https://3l0wd94f0qdd10om8642z9se-wpengine.netdna-ssl.com/wp-content/uploads/2019/02/jaromir-hamala-170x170.png" alt="Jaromir Hamala"/></a></div></div></header><article class="post-content"><div><span><p>Hazelcast Jet 3.2 introduces stateful map, filter, and flatmap
operations, which are very strong primitives. In this blog, I am going
to show you how to use stateful filter for detecting and removing
duplicate elements in a stream.</p>
<h2><a class="anchor" aria-hidden="true" id="why-deduplication"></a><a href="#why-deduplication" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why Deduplication?</h2>
<p>Deduplication is often used to achieve idempotency or effectively-once
delivery semantics in messaging systems. Imagine you have a
microservices architecture where individual microservices use a message
broker to communicate with each other. Achieving exactly-once semantics
is a hard problem.</p>
<p>If you cannot have exactly-once then you are typically left with
at-most-once and at-least-once semantics. At-most-once means messages
can get lost. This is often unacceptable. At-least-once means messages
cannot get lost, but some can be delivered more than once. This is
oftentimes better than losing messages, yet for some use cases, it’s
still not good enough. The common solution to this problem is
effectively-once. It’s essentially at-least-once combined with duplicate
detection and removal.</p>
<h2><a class="anchor" aria-hidden="true" id="implementation-idea"></a><a href="#implementation-idea" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Implementation Idea</h2>
<p>The deduplication process is usually straightforward. Producers attach a
unique ID to each message. Consumers track all processed message IDs and
discard messages with already observed IDs. This is often easy for batch
processing as each batch has a finite size. Thus, it’s often feasible to
store all IDs observed in a given batch.</p>
<p>However, streaming systems are different beasts. Streams are
conceptually infinite and it’s not feasible to hold all observed IDs,
let alone in memory. On the other hand, it’s often sensible to assume
duplicated messages will be close to each other. Hence we can introduce
time-to-live for each ID and remove it from memory when the time-to-live
expires.</p>
<h2><a class="anchor" aria-hidden="true" id="implementation-with-hazelcast-jet"></a><a href="#implementation-with-hazelcast-jet" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Implementation with Hazelcast Jet</h2>
<p>Let’s say I am running a discussion forum and I have a microservice that
sends a new message whenever a user posts a new comment. The message
looks like this:</p>
<pre><code class="hljs css language-java"><span class="token keyword">public</span> <span class="token keyword">final</span> <span class="token keyword">class</span> <span class="token class-name">AddNewComment</span> <span class="token keyword">implements</span> <span class="token class-name">Serializable</span> <span class="token punctuation">{</span>
  <span class="token keyword">private</span> <span class="token class-name">UUID</span> uuid<span class="token punctuation">;</span>
  <span class="token keyword">private</span> <span class="token class-name">String</span> comment<span class="token punctuation">;</span>
  <span class="token keyword">private</span> <span class="token keyword">long</span> authorId<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>The UUID field is unique for each message posted. My consumer is a
Hazelcast Jet application, and I want a processing pipeline to discard
all messages with a UUID already processed in the past. It turns out to
be really trivial:</p>
<pre><code class="hljs css language-java">stage<span class="token punctuation">.</span><span class="token function">groupingKey</span><span class="token punctuation">(</span><span class="token class-name">AddNewComment</span><span class="token operator">::</span><span class="token function">getUuid</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">filterStateful</span><span class="token punctuation">(</span><span class="token number">10_000</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token keyword">boolean</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span>s<span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">{</span>
        <span class="token keyword">boolean</span> res <span class="token operator">=</span> s<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
        s<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token operator">!</span>res<span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>How does it work? In the first step, we group a stream of incoming
comments by UUID. In the next step, we apply a filter with an array of
Booleans used as a state object. The state object will be created for
each UUID.</p>
<p>When a UUID is observed for the first time, the element inside the array
is false, so the code will flip it to true and the filtering function
returns true. This means the object will not be discarded.</p>
<p>If at some point the stream receives another comment with the same UUID,
then the filtering function receives the state object where the Boolean
inside the array is already set to true. This means the filtering
function will return false, and the duplicated object will be discarded.</p>
<p>The first parameter in the <code>filterStateful()</code> method is time-to-live.
Event time is typically in milliseconds. This means each state object
will be retained for at least 10 seconds. We have to choose this
parameter to match the longest possible time window between two
duplicated elements.</p>
<h2><a class="anchor" aria-hidden="true" id="further-improvements"></a><a href="#further-improvements" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Further Improvements</h2>
<p>Let’s encapsulate the filtering logic into a reusable unit that can be
applied to an arbitrary pipeline. We are going to use the <code>apply()</code>
method to transform a pipeline. A utility class with this method is all
that’s needed:</p>
<pre><code class="hljs css language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> <span class="token class-name">FunctionEx</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">StreamStage</span><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">StreamStage</span><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span><span class="token punctuation">></span></span>
<span class="token function">deduplicationWindow</span><span class="token punctuation">(</span><span class="token keyword">long</span> window<span class="token punctuation">,</span> <span class="token class-name">FunctionEx</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">,</span> <span class="token operator">?</span><span class="token punctuation">></span></span> extractor<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">return</span> stage <span class="token operator">-></span> stage<span class="token punctuation">.</span><span class="token function">groupingKey</span><span class="token punctuation">(</span>extractor<span class="token punctuation">)</span>
                         <span class="token punctuation">.</span><span class="token function">filterStateful</span><span class="token punctuation">(</span>window<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token keyword">boolean</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>s<span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">{</span>
                             <span class="token keyword">boolean</span> res <span class="token operator">=</span> s<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
                             s<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
                             <span class="token keyword">return</span> <span class="token operator">!</span>res<span class="token punctuation">;</span>
                         <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre>
<p>Whenever you need to add deduplication into a pipeline, you can simply call:</p>
<pre><code class="hljs css language-java">pipelineStage<span class="token punctuation">.</span><span class="token function">apply</span><span class="token punctuation">(</span>
    <span class="token class-name">StreamUtils</span><span class="token punctuation">.</span><span class="token function">deduplicationWindow</span><span class="token punctuation">(</span>WINDOW_LENGTH<span class="token punctuation">,</span> ID_EXTRACTOR_FUNCTION<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
</code></pre>
<p>This makes the deduplication logic independent from your business logic
and you can reuse the same deduplication utility across all your
pipelines.</p>
<h2><a class="anchor" aria-hidden="true" id="summary"></a><a href="#summary" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Summary</h2>
<p>I have demonstrated the power of stateful stream processing and the
simplicity of the Jet API. It only takes a few lines of code to
implement custom stream deduplication. Visit the Hazelcast Jet page for
more info, or stop by our Gitter chat and let us know what you think!</p>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev" href="/blog/">← Prev</a></div></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div style="text-align:left"><a href="/" class="nav-home"><img src="/img/logo-light.svg" alt="Hazelcast Jet" width="200" height="40"/></a><div style="margin-left:12px"><a class="github-button" href="https://github.com/hazelcast/hazelcast-jet" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star On GitHub</a></div></div><div><h5>Docs</h5><a href="/docs/get-started/intro">Get Started</a><a href="/docs/concepts/dag">Concepts</a><a href="/docs/tutorials/kafka">Tutorials</a><a href="/docs/architecture/distributed-computing">Architecture</a><a href="/docs/operations/installation">Operations Guide</a><a href="/docs/enterprise">Enterprise Edition</a></div><div><h5>Community</h5><a href="https://groups.google.com/forum/#!forum/hazelcast-jet" target="_blank" rel="noreferrer noopener">Google Groups</a><a href="http://stackoverflow.com/questions/tagged/hazelcast-jet" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://slack.hazelcast.com">Slack</a></div><div><h5>Latest From the Blog</h5><a href="/blog/2020/10/23/jet-43-is-released">Jet 4.3 Released</a><a href="/blog/2020/10/06/enabling-full-text-search">Enabling Full-text Search with Change Data Capture in a Legacy Application</a><a href="/blog/2020/09/18/cdc-meets-stream-processing">Change Data Capture meets Stream Processing</a><a href="/blog/2020/08/05/gc-tuning-for-jet">Sub-10 ms Latency in Java: Concurrent GC with Green Threads</a><a href="/blog/2020/07/16/designing-evergreen-cache-cdc">Designing an Evergreen Cache with Change Data Capture</a></div><div><h5>More</h5><a href="https://github.com/hazelcast/hazelcast-jet">GitHub Project</a><a href="http://hazelcast.com/company/careers/">Work at Hazelcast</a><a href="/license">License</a></div></section><section class="copyright">Copyright © 2021 Hazelcast Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '79d1e4941621b9fd761d279d4d19ed69',
                indexName: 'hazelcast-jet',
                inputSelector: '#search_input_react',
                algoliaOptions: {"facetFilters":["language:en","version:4.3"]}
              });
            </script></body></html>